[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Rishabh Mondal",
    "section": "",
    "text": "Hi! I am Rishabh Mondal.As an enthusiastic learner, I am always eager to take up challenging tasks and push my limits to achieve excellence. My academic journey has give me a strong foundation in the concepts of computer science, and I have gained practical experience through various projects\n\n\nM.Tech in Information Technology\nIndian Institute of Engineering Science and Technology, Shibpur | Sept 2021 - June 2023\nB.Tech in Computer Science and Engineering\nThe Neotia University, Kolkata |Sept 2017 - June 2021\n\n\n\n\nAn LSTM-based Fall Detection System with ROC optimization technique: A step towards more accuracy\nBrain Tumor Detection using Convolution Neural Network.\nIndian currency detection through KNN and audio transfer for blind people.\n\n\n\n\nWinner of IBM ICE DAY (poster competition)|2019"
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Rishabh Mondal",
    "section": "",
    "text": "M.Tech in Information Technology\nIndian Institute of Engineering Science and Technology, Shibpur | Sept 2021 - June 2023\nB.Tech in Computer Science and Engineering\nThe Neotia University, Kolkata |Sept 2017 - June 2021"
  },
  {
    "objectID": "index.html#project",
    "href": "index.html#project",
    "title": "Rishabh Mondal",
    "section": "",
    "text": "An LSTM-based Fall Detection System with ROC optimization technique: A step towards more accuracy\nBrain Tumor Detection using Convolution Neural Network.\nIndian currency detection through KNN and audio transfer for blind people."
  },
  {
    "objectID": "index.html#awards",
    "href": "index.html#awards",
    "title": "Rishabh Mondal",
    "section": "",
    "text": "Winner of IBM ICE DAY (poster competition)|2019"
  },
  {
    "objectID": "taylor.html",
    "href": "taylor.html",
    "title": "Taylor Series",
    "section": "",
    "text": "\\[\\begin{equation}\nf(x) = \\sum_{n=0}^{\\infty}\\frac{f^{(n)}(a)}{n!}(x-a)^{n}\n\\end{equation}\\]\nLet \\(f(x)\\) be a function that is \\(n+1\\) times differentiable on an interval \\(I\\) containing \\(a\\) and let \\(P_n(x)\\) be the \\(n\\)th degree Taylor polynomial for \\(f(x)\\) about \\(a\\). Then, there exists a number \\(c\\) between \\(a\\) and \\(x\\) such that: \\[\\begin{equation}\nf(x)=P_n(x)+R_n(x),\n\\end{equation}\\] where the remainder \\(R_n(x)\\) is given by: \\[\\begin{equation}\nR_n(x)=\\frac{f^{(n+1)}(c)}{(n+1)!}(x-a)^{n+1}.\n\\end{equation}\\]\n\nDefine the function to be approximated\n\n\nCode\nimport torch\nimport math\nimport matplotlib.pyplot as plt\nimport numpy as np\n# Define the sine function to be approximated\ndef f(x):\n    return torch.sin(x)\n\nx = torch.linspace(-3.14, 3.14, 100)\ny = f(x)\nplt.plot(x, y)\nplt.xlabel('x')\nplt.ylabel('y')\nplt.title('Sine Function')\nplt.show()\n\n\n\n\n\n\n\nFirst order Taylor approximation for f(x) at x = 0\n\n\nCode\nx = torch.tensor([0.], requires_grad=True)\ny = f(x)\napprox = y + torch.autograd.grad(y, x, create_graph=True)[0] * x\nx_vals = torch.linspace(-np.pi, np.pi, 100)\ny_vals = f(x_vals)\napprox_vals = (approx.detach() + torch.autograd.grad(approx, x, create_graph=True)[0] * x_vals).detach()\nplt.plot(x_vals.numpy(), y_vals.numpy(), label='sin(x)')\nplt.plot(x_vals.numpy(), approx_vals.numpy(), label='approx')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\nFind the nth order Taylor approximation for f(x) at x = 0\n\n\nCode\ndef fact(n):\n    return math.factorial(n)\n\ndef nth_deriv(f, a, n):\n    if isinstance(a, (float, int)):\n        a = torch.tensor([a], dtype=torch.float, requires_grad=True)\n    else:\n        a = a.clone().detach().requires_grad_(True)\n    \n    y = f(a)\n    for i in range(n):\n        y = torch.autograd.grad(y, a, create_graph=True)[0]\n    return y\n\n\n\n# nth degree Taylor polynomial of f(x) around x=a\ndef taylor(f, x, n):\n    result = torch.zeros_like(x)\n    for i in range(n+1):\n        result += nth_deriv(f, 0, i) / torch.tensor(math.factorial(i), dtype=torch.float32) * (x**i)\n    return result\nx_vals = torch.linspace(-math.pi, math.pi, 200)\nplt.plot(x_vals.numpy(), f(x_vals).numpy(), label='f(x)', lw=5)\nplt.plot(x_vals.numpy(), taylor(f, x_vals, 1).detach().numpy(), label='Taylor approximation, n=1')\nplt.plot(x_vals.numpy(), taylor(f, x_vals, 3).detach().numpy(), label='Taylor approximation, n=3')\nplt.plot(x_vals.numpy(), taylor(f, x_vals, 5).detach().numpy(), label='Taylor approximation, n=5')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\nPlot of the function g(x) = x^2 and its Taylor approximations up to degree 1 and degree 2 centered at x=0.\n\n\nCode\nx_vals = torch.linspace(-4, 4, 100)\n\ndef g(x):\n    return x**2\n\ndef taylor(f, x, n):\n    x = x.unsqueeze(-1)\n    y = f(x)\n    for i in range(1, n+1):\n        y += (x - x[0])**i / torch.tensor([math.factorial(i)]).float() * f(x[0] + 0.0)\n    return y\n\n\nplt.plot(x_vals.numpy(), g(x_vals).numpy(), label='g(x)', lw=5)\nplt.plot(x_vals.numpy(), taylor(g, x_vals, 1).detach().numpy(), label='Taylor approximation, n=1')\nplt.plot(x_vals.numpy(), taylor(g, x_vals, 3).detach().numpy(), label='Taylor approximation, n=3')\nplt.plot(x_vals.numpy(), taylor(g, x_vals, 5).detach().numpy(), label='Taylor approximation, n=5')\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "workshop.html",
    "href": "workshop.html",
    "title": "Workshop",
    "section": "",
    "text": "Workshop on Cloud Computing organized by IIT Kharagpur,2019"
  },
  {
    "objectID": "Conference.html",
    "href": "Conference.html",
    "title": "Conference",
    "section": "",
    "text": "Workshop on Cloud Computing organized by IIT Kharagpur,2019"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blogs",
    "section": "",
    "text": "Spiking neural networks (SNNs)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProbailty Distribtion\n\n\n\n\n\n\nRishabh Mondal\n\n\nJun 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nDifferent Distribution Samples\n\n\n\n\n\n\nRishabh Mondal\n\n\nFeb 7, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nTaylor Series\n\n\n\nQuarto\n\n\nPython\n\n\n\ndesp\n\n\n\nRishab Mondal\n\n\nOct 24, 2022\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/index.html",
    "href": "posts/index.html",
    "title": "Taylor Series",
    "section": "",
    "text": "\\[\\begin{equation}\nf(x) = \\sum_{n=0}^{\\infty}\\frac{f^{(n)}(a)}{n!}(x-a)^{n}\n\\end{equation}\\]\nLet \\(f(x)\\) be a function that is \\(n+1\\) times differentiable on an interval \\(I\\) containing \\(a\\) and let \\(P_n(x)\\) be the \\(n\\)th degree Taylor polynomial for \\(f(x)\\) about \\(a\\). Then, there exists a number \\(c\\) between \\(a\\) and \\(x\\) such that: \\[\\begin{equation}\nf(x)=P_n(x)+R_n(x),\n\\end{equation}\\] where the remainder \\(R_n(x)\\) is given by: \\[\\begin{equation}\nR_n(x)=\\frac{f^{(n+1)}(c)}{(n+1)!}(x-a)^{n+1}.\n\\end{equation}\\]\n\nDefine the function to be approximated\n\n\nCode\nimport torch\nimport math\nimport matplotlib.pyplot as plt\nimport numpy as np\n# Define the sine function to be approximated\ndef f(x):\n    return torch.sin(x)\n\nx = torch.linspace(-3.14, 3.14, 100)\ny = f(x)\nplt.plot(x, y)\nplt.xlabel('x')\nplt.ylabel('y')\nplt.title('Sine Function')\nplt.show()\n\n\n\n\n\n\n\nFirst order Taylor approximation for f(x) at x = 0\n\n\nCode\nx = torch.tensor([0.], requires_grad=True)\ny = f(x)\napprox = y + torch.autograd.grad(y, x, create_graph=True)[0] * x\nx_vals = torch.linspace(-np.pi, np.pi, 100)\ny_vals = f(x_vals)\napprox_vals = (approx.detach() + torch.autograd.grad(approx, x, create_graph=True)[0] * x_vals).detach()\nplt.plot(x_vals.numpy(), y_vals.numpy(), label='sin(x)')\nplt.plot(x_vals.numpy(), approx_vals.numpy(), label='approx')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\nFind the nth order Taylor approximation for f(x) at x = 0\n\n\nCode\ndef fact(n):\n    return math.factorial(n)\n\ndef nth_deriv(f, a, n):\n    if isinstance(a, (float, int)):\n        a = torch.tensor([a], dtype=torch.float, requires_grad=True)\n    else:\n        a = a.clone().detach().requires_grad_(True)\n    \n    y = f(a)\n    for i in range(n):\n        y = torch.autograd.grad(y, a, create_graph=True)[0]\n    return y\n\n\n\n# nth degree Taylor polynomial of f(x) around x=a\ndef taylor(f, x, n):\n    result = torch.zeros_like(x)\n    for i in range(n+1):\n        result += nth_deriv(f, 0, i) / torch.tensor(math.factorial(i), dtype=torch.float32) * (x**i)\n    return result\nx_vals = torch.linspace(-math.pi, math.pi, 200)\nplt.plot(x_vals.numpy(), f(x_vals).numpy(), label='f(x)', lw=5)\nplt.plot(x_vals.numpy(), taylor(f, x_vals, 1).detach().numpy(), label='Taylor approximation, n=1')\nplt.plot(x_vals.numpy(), taylor(f, x_vals, 3).detach().numpy(), label='Taylor approximation, n=3')\nplt.plot(x_vals.numpy(), taylor(f, x_vals, 5).detach().numpy(), label='Taylor approximation, n=5')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\nPlot of the function g(x) = x^2 and its Taylor approximations up to degree 1 and degree 2 centered at x=0.\n\n\nCode\nx_vals = torch.linspace(-4, 4, 100)\n\ndef g(x):\n    return x**2\n\ndef taylor(f, x, n):\n    x = x.unsqueeze(-1)\n    y = f(x)\n    for i in range(1, n+1):\n        y += (x - x[0])**i / torch.tensor([math.factorial(i)]).float() * f(x[0] + 0.0)\n    return y\n\n\nplt.plot(x_vals.numpy(), g(x_vals).numpy(), label='g(x)', lw=5)\nplt.plot(x_vals.numpy(), taylor(g, x_vals, 1).detach().numpy(), label='Taylor approximation, n=1')\nplt.plot(x_vals.numpy(), taylor(g, x_vals, 3).detach().numpy(), label='Taylor approximation, n=3')\nplt.plot(x_vals.numpy(), taylor(g, x_vals, 5).detach().numpy(), label='Taylor approximation, n=5')\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Certification",
    "section": "",
    "text": "Deep Learning from GUVI Geek Network & IITM - 2021.\nSix weeks of Summer Training on ML from IIT Kanpur,2019.\nOnline Python Training from IIT Kanpur,2019."
  },
  {
    "objectID": "probablity_distribution.html",
    "href": "probablity_distribution.html",
    "title": "Probablity Distrubutions",
    "section": "",
    "text": "Bernoulli Distribution\nTypes of Distribution : Discrete Distribution\nIn Bernoulli Distribution the random variable takes the value \\(1\\) with probability \\(p\\) and the value \\(0\\) with probability \\(1-p\\), where \\(0 ≤ p ≤ 1\\).\nThe probability mass function (PMF): \\[\\begin{equation}\nP(X = x) = p^x \\cdot (1-p)^{1-x} \\tag{1}\n\\end{equation}\\]\nWhere \\((X)\\) is the random variable, \\((x)\\) can be either 0 or \\(1\\), and \\((p)\\) is the probability of success.\n\n\nCode\np=0.6 #success=0.6 failure=0.4\nimport numpy as np\nsample = np.random.choice([0, 1], p=[1 - p, p])\nprob = (p ** sample) * ((1 - p) ** (1 - sample))\nprint(\"Sample:\", sample)\nprint(\"Probability:\", prob)\n\n#Using PyTorch\nimport torch\nfrom torch.distributions import Bernoulli\ndist=Bernoulli(torch.tensor([p]))\nsample=dist.sample()\nprint(\"Sample:\", sample)\nprint(\"Probability:\", dist)\n\n#Set of Probablty of success\nprobs = torch.tensor([0.7, 0.4, 0.9])\nbernoulli_dist = Bernoulli(probs=probs,logits=None)\nsamples = bernoulli_dist.sample()\nprint(\"probablity distributions:\", bernoulli_dist)\nprint(\"Samples:\", samples)\n\n# Log-odds of success\nlogits = torch.tensor([0.847])\ndist = Bernoulli(probs=None,logits=logits)\nsample = dist.sample()\nprint(\"log odd prob :\", dist)\nprint(\"Sample:\", sample.item())\n\n\nSample: 0\nProbability: 0.4\nSample: tensor([0.])\nProbability: Bernoulli(probs: tensor([0.6000]))\nprobablity distributions: Bernoulli(probs: torch.Size([3]))\nSamples: tensor([0., 0., 1.])\nlog odd prob : Bernoulli(probs: tensor([0.6999]), logits: tensor([0.8470]))\nSample: 0.0\n\n\nLog probability of Bernoulli distribution\nTo obtain the log probability, we take the natural logarithm of the PMF: \\[\\begin{equation}\n\\log P(X=x) = \\log(p^x \\cdot (1-p)^{1-x}) \\tag{2}\n\\end{equation}\\]\n\\[\\begin{equation}\n\\log P(X=x) = x \\cdot \\log(p) + (1-x) \\cdot \\log(1-p) \\tag{3}\n\\end{equation}\\]\n\n\nCode\nimport math\nsample=1\nprob=0.6\nlog_probability = sample * math.log(p) + (1 - sample) * math.log(1 - p)\nprint(\"sample:\", sample)\nprint(\"Log Probability:\", log_probability)\n\n#using PyTorch\nsample = torch.tensor([1])\np = torch.tensor([0.6])\ndist = Bernoulli(probs=p,logits=None)\nsample=dist.sample()\nlog_prob=dist.log_prob(sample)\nprint(\"Sample:\", sample)\nprint(\"Log Probability:\", log_prob)\n\n\nsample: 1\nLog Probability: -0.5108256237659907\nSample: tensor([0.])\nLog Probability: tensor([-0.9163])\n\n\nMaximum Likelihood Estimations(MLE) for Bernoulli Distribution\nThe MLE is a method used to estimate the parameters of a probability distribution based on observed data.\nDerivation of MLE for Bernoulli Distribution\nWe have a dataset with n binary samples:\\(x1\\) , \\(x2\\) , ..,\\(xn\\), where each \\(xi\\) is 0 or 1.\nThe likelihood function for the Bernoulli distribution is given by: \\[\\begin{equation}\nL(p) = \\prod_{i=1}^{n} p^{x_i} \\cdot (1-p)^{1-x_i}\n\\end{equation}\\]\nTaking the log-likelihood function: \\[\\begin{equation}\n\\log L(p) = \\sum_{i=1}^{n} x_i \\log p + (1-x_i) \\log (1-p)\n\\end{equation}\\]\nDifferentiating the log-likelihood function and setting it equal to zero: \\[\\begin{equation}\n\\frac{{\\partial}}{{\\partial p}} \\log L(p) = \\sum_{i=1}^{n} \\left(\\frac{{x_i}}{{p}} - \\frac{{1-x_i}}{{1-p}}\\right) = 0\n\\end{equation}\\]\nSimplifying the equation: \\[\\begin{equation}\n\\frac{{\\sum_{i=1}^{n} x_i - np}}{{p(1-p)}} = 0\n\\end{equation}\\]\nSolving for \\(p\\): \\[\\begin{equation}\nnp = \\sum_{i=1}^{n} x_i\n\\end{equation}\\]\n\n\nCode\nsize = 100\ndataset = dist.sample(torch.Size([size]))\nnum_suc=dataset.float().sum()\np_estimate=num_suc.float()/dataset.size(0)\nprint(\"MLE Estimate:\", p_estimate.item())\n\n\nMLE Estimate: 0.550000011920929\n\n\nLoss v/s iteration curve\n\n\nCode\nfrom torch.optim import Adam\nimport matplotlib.pyplot as plt\ndataset_sizes = [10, 50, 100, 200, 500,1000,10000]\ndef negative_log_likelihood(p, dataset):\n    return -(dataset * torch.log(p) + (1 - dataset) * torch.log(1 - p)).mean()\n\nfor size in dataset_sizes:\n   \n    dataset = torch.randint(low=0, high=2, size=(size,))\n    p = torch.tensor(0.5, requires_grad=True)\n    optimizer = Adam([p], lr=0.1)\n    loss_values = []\n    iteration_values = []\n    for i in range(100):\n        optimizer.zero_grad()\n        loss = negative_log_likelihood(p, dataset)\n        loss.backward()\n        optimizer.step()\n        loss_values.append(loss.item())\n        iteration_values.append(i+1)\n    plt.plot(iteration_values, loss_values, label=f'Dataset Size: {size}')\nplt.xlabel('Iteration')\nplt.ylabel('Loss')\nplt.title('Loss vs. Iteration for Varying Dataset Sizes')\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "posts/probablity_distribution.html",
    "href": "posts/probablity_distribution.html",
    "title": "Probablity Distrubutions",
    "section": "",
    "text": "Bernoulli Distribution\nTypes of Distribution : Discrete Distribution\nIn Bernoulli Distribution the random variable takes the value \\(1\\) with probability \\(p\\) and the value \\(0\\) with probability \\(1-p\\), where \\(0 ≤ p ≤ 1\\).\nThe probability mass function (PMF): \\[\\begin{equation}\nP(X = x) = p^x \\cdot (1-p)^{1-x} \\tag{1}\n\\end{equation}\\]\nWhere \\((X)\\) is the random variable, \\((x)\\) can be either 0 or \\(1\\), and \\((p)\\) is the probability of success.\n\n\nCode\np=0.6 #success=0.6 failure=0.4\nimport numpy as np\nsample = np.random.choice([0, 1], p=[1 - p, p])\nprob = (p ** sample) * ((1 - p) ** (1 - sample))\nprint(\"Sample:\", sample)\nprint(\"Probability:\", prob)\n\n#Using PyTorch\nimport torch\nfrom torch.distributions import Bernoulli\ndist=Bernoulli(torch.tensor([p]))\nsample=dist.sample()\nprint(\"Sample:\", sample)\nprint(\"Probability:\", dist)\n\n#Set of Probablty of success\nprobs = torch.tensor([0.7, 0.4, 0.9])\nbernoulli_dist = Bernoulli(probs=probs,logits=None)\nsamples = bernoulli_dist.sample()\nprint(\"probablity distributions:\", bernoulli_dist)\nprint(\"Samples:\", samples)\n\n# Log-odds of success\nlogits = torch.tensor([0.847])\ndist = Bernoulli(probs=None,logits=logits)\nsample = dist.sample()\nprint(\"log odd prob :\", dist)\nprint(\"Sample:\", sample.item())\n\n\nSample: 0\nProbability: 0.4\nSample: tensor([1.])\nProbability: Bernoulli(probs: tensor([0.6000]))\nprobablity distributions: Bernoulli(probs: torch.Size([3]))\nSamples: tensor([0., 0., 1.])\nlog odd prob : Bernoulli(probs: tensor([0.6999]), logits: tensor([0.8470]))\nSample: 0.0\n\n\nLog probability of Bernoulli distribution\nTo obtain the log probability, we take the natural logarithm of the PMF: \\[\\begin{equation}\n\\log P(X=x) = \\log(p^x \\cdot (1-p)^{1-x}) \\tag{2}\n\\end{equation}\\]\n\\[\\begin{equation}\n\\log P(X=x) = x \\cdot \\log(p) + (1-x) \\cdot \\log(1-p) \\tag{3}\n\\end{equation}\\]\n\n\nCode\nimport math\nsample=1\nprob=0.6\nlog_probability = sample * math.log(p) + (1 - sample) * math.log(1 - p)\nprint(\"sample:\", sample)\nprint(\"Log Probability:\", log_probability)\n\n#using PyTorch\nsample = torch.tensor([1])\np = torch.tensor([0.6])\ndist = Bernoulli(probs=p,logits=None)\nsample=dist.sample()\nlog_prob=dist.log_prob(sample)\nprint(\"Sample:\", sample)\nprint(\"Log Probability:\", log_prob)\n\n\nsample: 1\nLog Probability: -0.5108256237659907\nSample: tensor([0.])\nLog Probability: tensor([-0.9163])\n\n\nMaximum Likelihood Estimations(MLE) for Bernoulli Distribution\nThe MLE is a method used to estimate the parameters of a probability distribution based on observed data.\nDerivation of MLE for Bernoulli Distribution\nWe have a dataset with n binary samples:\\(x1\\) , \\(x2\\) , ..,\\(xn\\), where each \\(xi\\) is 0 or 1.\nThe likelihood function for the Bernoulli distribution is given by: \\[\\begin{equation}\nL(p) = \\prod_{i=1}^{n} p^{x_i} \\cdot (1-p)^{1-x_i}\n\\end{equation}\\]\nTaking the log-likelihood function: \\[\\begin{equation}\n\\log L(p) = \\sum_{i=1}^{n} x_i \\log p + (1-x_i) \\log (1-p)\n\\end{equation}\\]\nDifferentiating the log-likelihood function and setting it equal to zero: \\[\\begin{equation}\n\\frac{{\\partial}}{{\\partial p}} \\log L(p) = \\sum_{i=1}^{n} \\left(\\frac{{x_i}}{{p}} - \\frac{{1-x_i}}{{1-p}}\\right) = 0\n\\end{equation}\\]\nSimplifying the equation: \\[\\begin{equation}\n\\frac{{\\sum_{i=1}^{n} x_i - np}}{{p(1-p)}} = 0\n\\end{equation}\\]\nSolving for \\(p\\): \\[\\begin{equation}\nnp = \\sum_{i=1}^{n} x_i\n\\end{equation}\\]\n\n\nCode\nsize = 100\ndataset = dist.sample(torch.Size([size]))\nnum_suc=dataset.float().sum()\np_estimate=num_suc.float()/dataset.size(0)\nprint(\"MLE Estimate:\", p_estimate.item())\n\n\nMLE Estimate: 0.5899999737739563\n\n\nLoss v/s iteration curve\n\n\nCode\nfrom torch.optim import Adam\nimport matplotlib.pyplot as plt\ndataset_sizes = [10, 50, 100, 200, 500,1000,10000]\ndef negative_log_likelihood(p, dataset):\n    return -(dataset * torch.log(p) + (1 - dataset) * torch.log(1 - p)).mean()\n\nfor size in dataset_sizes:\n   \n    dataset = torch.randint(low=0, high=2, size=(size,))\n    p = torch.tensor(0.5, requires_grad=True)\n    optimizer = Adam([p], lr=0.1)\n    loss_values = []\n    iteration_values = []\n    for i in range(100):\n        optimizer.zero_grad()\n        loss = negative_log_likelihood(p, dataset)\n        loss.backward()\n        optimizer.step()\n        loss_values.append(loss.item())\n        iteration_values.append(i+1)\n    plt.plot(iteration_values, loss_values, label=f'Dataset Size: {size}')\nplt.xlabel('Iteration')\nplt.ylabel('Loss')\nplt.title('Loss vs. Iteration for Varying Dataset Sizes')\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "posts/Probablity_distibution.html",
    "href": "posts/Probablity_distibution.html",
    "title": "Probailty Distribtion",
    "section": "",
    "text": "Bernoulli distribution\n\n\nBernoulli distribution is a discret univariate probability distribution. A Bernoulli trial or experiment results in binary outcomes: success or failure \\((0 or 1)\\). The trial’s success is denoted as $ p (x=1)$, and failure is expressed as \\(1-p ( x=0)\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\[\\begin{equation}\nP(X = x) = p^x \\cdot (1-p)^{1-x} \\tag{1}\n\\end{equation}\\]\nwhere \\((X)\\) is the random variable, \\((x)\\) can be either 0 or 1, and \\((p)\\) is the probability of success.\nSome imports\n\nimport numpy as np\nimport torch\nfrom torch.distributions import Bernoulli\nimport math\nfrom torch.optim import Adam\nimport matplotlib.pyplot as plt\n\nImplementation of PMF\n\np=0.6 #success=0.6 failure=0.4\nimport numpy as np\nsample = np.random.choice([0, 1], p=[1 - p, p])\nprob = (p ** sample) * ((1 - p) ** (1 - sample))\nprint(\"Sample:\", sample)\nprint(\"Probability:\", prob)\n\n#Using PyTorch\nimport torch\nfrom torch.distributions import Bernoulli\ndist=Bernoulli(torch.tensor([p]))\nsample=dist.sample()\nprint(\"Sample:\", sample)\nprint(\"Probability:\", dist)\n\n#Set of Probablty of success\nprobs = torch.tensor([0.7, 0.4, 0.9])\nbernoulli_dist = Bernoulli(probs=probs,logits=None)\nsamples = bernoulli_dist.sample()\nprint(\"probablity distributions:\", bernoulli_dist)\nprint(\"Samples:\", samples)\n\n# Log-odds of success\nlogits = torch.tensor([0.847])\ndist = Bernoulli(probs=None,logits=logits)\nsample = dist.sample()\nprint(\"log odd prob :\", dist)\nprint(\"Sample:\", sample.item())\n\nSample: 0\nProbability: 0.4\nSample: tensor([1.])\nProbability: Bernoulli(probs: tensor([0.6000]))\nprobablity distributions: Bernoulli(probs: torch.Size([3]))\nSamples: tensor([1., 0., 1.])\nlog odd prob : Bernoulli(probs: tensor([0.6999]), logits: tensor([0.8470]))\nSample: 1.0\n\n\nLog probability of Bernoulli distribution\nTo obtain the log probability, we take the natural logarithm of the PMF:\n\\[\\begin{equation}\n\\log P(X=x) = \\log(p^x \\cdot (1-p)^{1-x})\n\\end{equation}\\]\n\\[\\begin{equation}\n\\log P(X=x) = x \\cdot \\log(p) + (1-x) \\cdot \\log(1-p)\n\\end{equation}\\]\n\nsample=1\nprob=0.6\nlog_probability = sample * math.log(p) + (1 - sample) * math.log(1 - p)\nprint(\"sample:\", sample)\nprint(\"Log Probability:\", log_probability)\n\n#using PyTorch\nsample = torch.tensor([1])\np = torch.tensor([0.6])\ndist = Bernoulli(probs=p,logits=None)\nsample=dist.sample()\nlog_prob=dist.log_prob(sample)\nprint(\"Sample:\", sample)\nprint(\"Log Probability:\", log_prob)\n\nsample: 1\nLog Probability: -0.5108256237659907\nSample: tensor([1.])\nLog Probability: tensor([-0.5108])\n\n\nMaximum Likelihood Estimations(MLE) for Bernoulli Distribution\nTo derive the Maximum Likelihood Estimation (MLE) for the Bernoulli distribution, let’s assume we have a random sample of independent and identically distributed (i.i.d.) observations from a Bernoulli distribution with parameter p. Each observation can take a value of either 0 or 1.\nThe likelihood function for the Bernoulli distribution is given by:\n\\[ L(p) = \\prod_{i=1}^{n} p^{x_i} \\cdot (1-p)^{1-x_i} \\]\nwhere (x_i) is the i-th observation in the sample and n is the total number of observations.\nTo find the MLE for p, we want to find the value of p that maximizes the likelihood function L(p). It is often easier to work with the log-likelihood function, which is the natural logarithm of the likelihood function:\n\\[\n\\log L(p) = \\sum_{i=1}^{n} x_i \\cdot \\log(p) + (1-x_i) \\cdot \\log(1-p)\n\\]\nTo find the MLE, we differentiate the log-likelihood function with respect to p and set it equal to zero:\n\\[\n\\frac{d}{dp}(\\log L(p)) = \\frac{1}{p}\\sum_{i=1}^{n} x_i - \\frac{1}{1-p}\\sum_{i=1}^{n} (1-x_i) = 0\n\\]\nSimplifying the equation:\n\\[\n\\frac{1}{p}\\sum_{i=1}^{n} x_i - \\frac{n}{1-p} + \\frac{1}{1-p}\\sum_{i=1}^{n} x_i = 0\n\\]\nMultiplying through by p(1-p):\n\\[\n(1-p)\\sum_{i=1}^{n} x_i - np + p\\sum_{i=1}^{n} x_i = 0\n\\]\nRearranging the terms:\n\\[\n\\sum_{i=1}^{n} x_i - np = 0\n\\] Finally, solving for p:\n\\[\np = \\frac{1}{n}\\sum_{i=1}^{n} x_i\n\\]\nTherefore, the MLE for the parameter p in the Bernoulli distribution is the sample mean of the observed values.\nIt is important to note that this MLE is consistent, unbiased, and efficient for estimating the parameter p in the Bernoulli distribution.\n\nsize = 100\ndataset = dist.sample(torch.Size([size]))\nnum_suc=dataset.float().sum()\np_estimate=num_suc.float()/dataset.size(0)\nprint(\"MLE Estimate:\", p_estimate.item())\n\nMLE Estimate: 0.6299999952316284\n\n\nPerforming Maximum Likelihood Estimation (MLE) for the Bernoulli distribution with varying dataset sizes. It computes the negative log-likelihood loss for different dataset sizes and optimizes the parameter ‘p’ to minimize the loss using the Adam optimizer.\nThe resulting loss values are then plotted against the iterations to visualize the convergence of the MLE estimation.\n\ndataset_sizes = [10, 50, 100, 200, 500,1000,10000]\ndef negative_log_likelihood(p, dataset):\n    return -(dataset * torch.log(p) + (1 - dataset) * torch.log(1 - p)).mean()\n\nfor size in dataset_sizes:\n   \n    dataset = torch.randint(low=0, high=2, size=(size,))\n    p = torch.tensor(0.5, requires_grad=True)\n    optimizer = Adam([p], lr=0.1)\n    loss_values = []\n    iteration_values = []\n    for i in range(100):\n        optimizer.zero_grad()\n        loss = negative_log_likelihood(p, dataset)\n        loss.backward()\n        optimizer.step()\n        loss_values.append(loss.item())\n        iteration_values.append(i+1)\n    plt.plot(iteration_values, loss_values, label=f'Dataset Size: {size}')\nplt.xlabel('Iteration')\nplt.ylabel('Loss')\nplt.title('Loss vs. Iteration for Varying Dataset Sizes')\nplt.legend()\nplt.show()\n\n\n\n\nThe plot shows the relationship between the loss and the number of iterations for each dataset size.\nBy examining the plot, we can observe the following:\n\nAs the dataset size increases, the convergence to the optimal parameter value tends to be faster. This is because larger datasets provide more information, allowing for more accurate estimation.\nFor smaller dataset sizes (e.g., 10, 50, 100), the loss tends to fluctuate more initially. However, as the number of iterations increases, the loss converges to a stable value.\nFor larger dataset sizes (e.g., 1000, 10000), the loss tends to converge quickly and stabilize earlier compared to smaller dataset sizes."
  },
  {
    "objectID": "posts/Probablity_distibution.html#introduction",
    "href": "posts/Probablity_distibution.html#introduction",
    "title": "Bernoulli distribution",
    "section": "",
    "text": "Bernoulli distribution is a discret univariate probability distribution. A Bernoulli trial or experiment results in binary outcomes: success or failure \\((0 or 1)\\). The trial’s success is denoted as $ p (x=1)$, and failure is expressed as \\(1-p ( x=0)\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n$ \\[\\begin{equation}\nP(X = x) = p^x \\cdot (1-p)^{1-x} \\tag{1}\n\\end{equation}\\] $ where \\((X)\\) is the random variable, \\((x)\\) can be either 0 or 1, and \\((p)\\) is the probability of success.\nSome imports\n\nimport numpy as np\nimport torch\nfrom torch.distributions import Bernoulli\nimport math\nfrom torch.optim import Adam\nimport matplotlib.pyplot as plt\n\nImplementation of PMF\n\np=0.6 #success=0.6 failure=0.4\nimport numpy as np\nsample = np.random.choice([0, 1], p=[1 - p, p])\nprob = (p ** sample) * ((1 - p) ** (1 - sample))\nprint(\"Sample:\", sample)\nprint(\"Probability:\", prob)\n\n#Using PyTorch\nimport torch\nfrom torch.distributions import Bernoulli\ndist=Bernoulli(torch.tensor([p]))\nsample=dist.sample()\nprint(\"Sample:\", sample)\nprint(\"Probability:\", dist)\n\n#Set of Probablty of success\nprobs = torch.tensor([0.7, 0.4, 0.9])\nbernoulli_dist = Bernoulli(probs=probs,logits=None)\nsamples = bernoulli_dist.sample()\nprint(\"probablity distributions:\", bernoulli_dist)\nprint(\"Samples:\", samples)\n\n# Log-odds of success\nlogits = torch.tensor([0.847])\ndist = Bernoulli(probs=None,logits=logits)\nsample = dist.sample()\nprint(\"log odd prob :\", dist)\nprint(\"Sample:\", sample.item())\n\nSample: 1\nProbability: 0.6\nSample: tensor([0.])\nProbability: Bernoulli(probs: tensor([0.6000]))\nprobablity distributions: Bernoulli(probs: torch.Size([3]))\nSamples: tensor([0., 1., 0.])\nlog odd prob : Bernoulli(probs: tensor([0.6999]), logits: tensor([0.8470]))\nSample: 1.0\n\n\nLog probability of Bernoulli distribution\nTo obtain the log probability, we take the natural logarithm of the PMF: $ \\[\\begin{equation}\n\\log P(X=x) = \\log(p^x \\cdot (1-p)^{1-x})\n\\end{equation}\\] $ $ \\[\\begin{equation}\n\\log P(X=x) = x \\cdot \\log(p) + (1-x) \\cdot \\log(1-p)\n\\end{equation}\\] $\n\nsample=1\nprob=0.6\nlog_probability = sample * math.log(p) + (1 - sample) * math.log(1 - p)\nprint(\"sample:\", sample)\nprint(\"Log Probability:\", log_probability)\n\n#using PyTorch\nsample = torch.tensor([1])\np = torch.tensor([0.6])\ndist = Bernoulli(probs=p,logits=None)\nsample=dist.sample()\nlog_prob=dist.log_prob(sample)\nprint(\"Sample:\", sample)\nprint(\"Log Probability:\", log_prob)\n\nsample: 1\nLog Probability: -0.5108256237659907\nSample: tensor([1.])\nLog Probability: tensor([-0.5108])\n\n\nMaximum Likelihood Estimations(MLE) for Bernoulli Distribution\nTo derive the Maximum Likelihood Estimation (MLE) for the Bernoulli distribution, let’s assume we have a random sample of independent and identically distributed (i.i.d.) observations from a Bernoulli distribution with parameter p. Each observation can take a value of either 0 or 1.\nThe likelihood function for the Bernoulli distribution is given by:\n$ L(p) = _{i=1}^{n} p^{x_i} (1-p)^{1-x_i} $\nwhere (x_i) is the i-th observation in the sample and n is the total number of observations.\nTo find the MLE for p, we want to find the value of p that maximizes the likelihood function L(p). It is often easier to work with the log-likelihood function, which is the natural logarithm of the likelihood function:\n$ L(p) = _{i=1}^{n} x_i (p) + (1-x_i) (1-p) $\nTo find the MLE, we differentiate the log-likelihood function with respect to p and set it equal to zero:\n$ (L(p)) = {i=1}^{n} x_i - {i=1}^{n} (1-x_i) = 0 $\nSimplifying the equation:\n$ {i=1}^{n} x_i - + {i=1}^{n} x_i = 0 $\nMultiplying through by p(1-p):\n$ (1-p){i=1}^{n} x_i - np + p{i=1}^{n} x_i = 0 $\nRearranging the terms:\n$ _{i=1}^{n} x_i - np = 0 $ Finally, solving for p:\n$ p = _{i=1}^{n} x_i $\nTherefore, the MLE for the parameter p in the Bernoulli distribution is the sample mean of the observed values.\nIt is important to note that this MLE is consistent, unbiased, and efficient for estimating the parameter p in the Bernoulli distribution.\n\nsize = 100\ndataset = dist.sample(torch.Size([size]))\nnum_suc=dataset.float().sum()\np_estimate=num_suc.float()/dataset.size(0)\nprint(\"MLE Estimate:\", p_estimate.item())\n\nMLE Estimate: 0.6100000143051147\n\n\nPerforming Maximum Likelihood Estimation (MLE) for the Bernoulli distribution with varying dataset sizes. It computes the negative log-likelihood loss for different dataset sizes and optimizes the parameter ‘p’ to minimize the loss using the Adam optimizer.\nThe resulting loss values are then plotted against the iterations to visualize the convergence of the MLE estimation.\n\ndataset_sizes = [10, 50, 100, 200, 500,1000,10000]\ndef negative_log_likelihood(p, dataset):\n    return -(dataset * torch.log(p) + (1 - dataset) * torch.log(1 - p)).mean()\n\nfor size in dataset_sizes:\n   \n    dataset = torch.randint(low=0, high=2, size=(size,))\n    p = torch.tensor(0.5, requires_grad=True)\n    optimizer = Adam([p], lr=0.1)\n    loss_values = []\n    iteration_values = []\n    for i in range(100):\n        optimizer.zero_grad()\n        loss = negative_log_likelihood(p, dataset)\n        loss.backward()\n        optimizer.step()\n        loss_values.append(loss.item())\n        iteration_values.append(i+1)\n    plt.plot(iteration_values, loss_values, label=f'Dataset Size: {size}')\nplt.xlabel('Iteration')\nplt.ylabel('Loss')\nplt.title('Loss vs. Iteration for Varying Dataset Sizes')\nplt.legend()\nplt.show()\n\n\n\n\nThe plot shows the relationship between the loss and the number of iterations for each dataset size.\nBy examining the plot, we can observe the following:\n\nAs the dataset size increases, the convergence to the optimal parameter value tends to be faster. This is because larger datasets provide more information, allowing for more accurate estimation.\nFor smaller dataset sizes (e.g., 10, 50, 100), the loss tends to fluctuate more initially. However, as the number of iterations increases, the loss converges to a stable value.\nFor larger dataset sizes (e.g., 1000, 10000), the loss tends to converge quickly and stabilize earlier compared to smaller dataset sizes."
  },
  {
    "objectID": "posts/Probablity_distibution.html#probablity-distribution",
    "href": "posts/Probablity_distibution.html#probablity-distribution",
    "title": "Probailty Distribtion",
    "section": "",
    "text": "Bernoulli distribution\n\n\nBernoulli distribution is a discret univariate probability distribution. A Bernoulli trial or experiment results in binary outcomes: success or failure \\((0 or 1)\\). The trial’s success is denoted as $ p (x=1)$, and failure is expressed as \\(1-p ( x=0)\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\[\\begin{equation}\nP(X = x) = p^x \\cdot (1-p)^{1-x} \\tag{1}\n\\end{equation}\\]\nwhere \\((X)\\) is the random variable, \\((x)\\) can be either 0 or 1, and \\((p)\\) is the probability of success.\nSome imports\n\nimport numpy as np\nimport torch\nfrom torch.distributions import Bernoulli\nimport math\nfrom torch.optim import Adam\nimport matplotlib.pyplot as plt\n\nImplementation of PMF\n\np=0.6 #success=0.6 failure=0.4\nimport numpy as np\nsample = np.random.choice([0, 1], p=[1 - p, p])\nprob = (p ** sample) * ((1 - p) ** (1 - sample))\nprint(\"Sample:\", sample)\nprint(\"Probability:\", prob)\n\n#Using PyTorch\nimport torch\nfrom torch.distributions import Bernoulli\ndist=Bernoulli(torch.tensor([p]))\nsample=dist.sample()\nprint(\"Sample:\", sample)\nprint(\"Probability:\", dist)\n\n#Set of Probablty of success\nprobs = torch.tensor([0.7, 0.4, 0.9])\nbernoulli_dist = Bernoulli(probs=probs,logits=None)\nsamples = bernoulli_dist.sample()\nprint(\"probablity distributions:\", bernoulli_dist)\nprint(\"Samples:\", samples)\n\n# Log-odds of success\nlogits = torch.tensor([0.847])\ndist = Bernoulli(probs=None,logits=logits)\nsample = dist.sample()\nprint(\"log odd prob :\", dist)\nprint(\"Sample:\", sample.item())\n\nSample: 0\nProbability: 0.4\nSample: tensor([1.])\nProbability: Bernoulli(probs: tensor([0.6000]))\nprobablity distributions: Bernoulli(probs: torch.Size([3]))\nSamples: tensor([1., 0., 1.])\nlog odd prob : Bernoulli(probs: tensor([0.6999]), logits: tensor([0.8470]))\nSample: 1.0\n\n\nLog probability of Bernoulli distribution\nTo obtain the log probability, we take the natural logarithm of the PMF:\n\\[\\begin{equation}\n\\log P(X=x) = \\log(p^x \\cdot (1-p)^{1-x})\n\\end{equation}\\]\n\\[\\begin{equation}\n\\log P(X=x) = x \\cdot \\log(p) + (1-x) \\cdot \\log(1-p)\n\\end{equation}\\]\n\nsample=1\nprob=0.6\nlog_probability = sample * math.log(p) + (1 - sample) * math.log(1 - p)\nprint(\"sample:\", sample)\nprint(\"Log Probability:\", log_probability)\n\n#using PyTorch\nsample = torch.tensor([1])\np = torch.tensor([0.6])\ndist = Bernoulli(probs=p,logits=None)\nsample=dist.sample()\nlog_prob=dist.log_prob(sample)\nprint(\"Sample:\", sample)\nprint(\"Log Probability:\", log_prob)\n\nsample: 1\nLog Probability: -0.5108256237659907\nSample: tensor([1.])\nLog Probability: tensor([-0.5108])\n\n\nMaximum Likelihood Estimations(MLE) for Bernoulli Distribution\nTo derive the Maximum Likelihood Estimation (MLE) for the Bernoulli distribution, let’s assume we have a random sample of independent and identically distributed (i.i.d.) observations from a Bernoulli distribution with parameter p. Each observation can take a value of either 0 or 1.\nThe likelihood function for the Bernoulli distribution is given by:\n\\[ L(p) = \\prod_{i=1}^{n} p^{x_i} \\cdot (1-p)^{1-x_i} \\]\nwhere (x_i) is the i-th observation in the sample and n is the total number of observations.\nTo find the MLE for p, we want to find the value of p that maximizes the likelihood function L(p). It is often easier to work with the log-likelihood function, which is the natural logarithm of the likelihood function:\n\\[\n\\log L(p) = \\sum_{i=1}^{n} x_i \\cdot \\log(p) + (1-x_i) \\cdot \\log(1-p)\n\\]\nTo find the MLE, we differentiate the log-likelihood function with respect to p and set it equal to zero:\n\\[\n\\frac{d}{dp}(\\log L(p)) = \\frac{1}{p}\\sum_{i=1}^{n} x_i - \\frac{1}{1-p}\\sum_{i=1}^{n} (1-x_i) = 0\n\\]\nSimplifying the equation:\n\\[\n\\frac{1}{p}\\sum_{i=1}^{n} x_i - \\frac{n}{1-p} + \\frac{1}{1-p}\\sum_{i=1}^{n} x_i = 0\n\\]\nMultiplying through by p(1-p):\n\\[\n(1-p)\\sum_{i=1}^{n} x_i - np + p\\sum_{i=1}^{n} x_i = 0\n\\]\nRearranging the terms:\n\\[\n\\sum_{i=1}^{n} x_i - np = 0\n\\] Finally, solving for p:\n\\[\np = \\frac{1}{n}\\sum_{i=1}^{n} x_i\n\\]\nTherefore, the MLE for the parameter p in the Bernoulli distribution is the sample mean of the observed values.\nIt is important to note that this MLE is consistent, unbiased, and efficient for estimating the parameter p in the Bernoulli distribution.\n\nsize = 100\ndataset = dist.sample(torch.Size([size]))\nnum_suc=dataset.float().sum()\np_estimate=num_suc.float()/dataset.size(0)\nprint(\"MLE Estimate:\", p_estimate.item())\n\nMLE Estimate: 0.6299999952316284\n\n\nPerforming Maximum Likelihood Estimation (MLE) for the Bernoulli distribution with varying dataset sizes. It computes the negative log-likelihood loss for different dataset sizes and optimizes the parameter ‘p’ to minimize the loss using the Adam optimizer.\nThe resulting loss values are then plotted against the iterations to visualize the convergence of the MLE estimation.\n\ndataset_sizes = [10, 50, 100, 200, 500,1000,10000]\ndef negative_log_likelihood(p, dataset):\n    return -(dataset * torch.log(p) + (1 - dataset) * torch.log(1 - p)).mean()\n\nfor size in dataset_sizes:\n   \n    dataset = torch.randint(low=0, high=2, size=(size,))\n    p = torch.tensor(0.5, requires_grad=True)\n    optimizer = Adam([p], lr=0.1)\n    loss_values = []\n    iteration_values = []\n    for i in range(100):\n        optimizer.zero_grad()\n        loss = negative_log_likelihood(p, dataset)\n        loss.backward()\n        optimizer.step()\n        loss_values.append(loss.item())\n        iteration_values.append(i+1)\n    plt.plot(iteration_values, loss_values, label=f'Dataset Size: {size}')\nplt.xlabel('Iteration')\nplt.ylabel('Loss')\nplt.title('Loss vs. Iteration for Varying Dataset Sizes')\nplt.legend()\nplt.show()\n\n\n\n\nThe plot shows the relationship between the loss and the number of iterations for each dataset size.\nBy examining the plot, we can observe the following:\n\nAs the dataset size increases, the convergence to the optimal parameter value tends to be faster. This is because larger datasets provide more information, allowing for more accurate estimation.\nFor smaller dataset sizes (e.g., 10, 50, 100), the loss tends to fluctuate more initially. However, as the number of iterations increases, the loss converges to a stable value.\nFor larger dataset sizes (e.g., 1000, 10000), the loss tends to converge quickly and stabilize earlier compared to smaller dataset sizes."
  },
  {
    "objectID": "posts/Sampling_distributions.html",
    "href": "posts/Sampling_distributions.html",
    "title": "Different Distribution Samples",
    "section": "",
    "text": "Bernoulli, Categorical, Normal using Uniform sampling\n\n#Important libraries\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.distributions as dist\nimport math\nimport hamiltorch\nfrom tueplots import bundles\nplt.rcParams.update(bundles.beamer_moml())\n\n\n#pre-defined values\nn_samples=10000\nseed=42\np=0.4\n\nImplementing a pseudo-random number generator (PRNG) - Generates a sequence of numbers that exhibit properties of randomness\nLinear Congruential Generator (LCG) is a simple PRNG algorithm - The LCG algorithm is defined by the recurrence relation:\n\\(X_{n+1} = (a \\cdot X_n + c) \\mod m\\)\n\n\\(X_{n+1}\\) represents the next pseudo-random number in the sequence.\n\\(X_n\\) is the current pseudo-random number in the sequence.\n\\(a\\) is the multiplier, which determines the overall distribution and period of the generated sequence.\n\\(c\\) is the increment, which shifts the generated sequence.\n\\(m\\) is the modulus, which determines the range of values that the generated numbers can take.\n\n\n# Function for Linear Congruential Generator\ndef lcg(seed, n_samples):\n    \"\"\"\n    Generates a sequence of pseudo-random numbers using the Linear Congruential Generator (LCG) algorithm.\n\n    Args:\n        seed (int): The seed value for the LCG algorithm.\n        n_samples (int): The number of random numbers to generate.\n\n    Returns:\n        list: A list of pseudo-random numbers normalized to the range [0, 1].\n    \"\"\"\n    a = 1103515245\n    c = 12345\n    m = 2 ** 31\n    random_numbers = []\n\n    for _ in range(n_samples):\n        seed = (a * seed + c) % m\n        random_number = seed / m  # Normalize to range [0, 1]\n        random_numbers.append(random_number)\n\n    return random_numbers\n\nPlot histogram\n\n\n# Example usage:\nrandom_numbers = lcg(seed, n_samples )\n\nplt.hist(random_numbers, bins=20)\nplt.xlabel('Random Number')\nplt.ylabel('Frequency')\nplt.title('Histogram of Pseudo-random Numbers')\nplt.show()\n\n\n\n\nIn a uniform distribution, all values have an equal chance of occurring. The graph of this distribution shows bars or lines of equal height for each outcome, creating a rectangular shape. For example, when drawing from a standard deck, the probability of selecting a heart or a spade is 1/4 or 25%.\nUsing PyTorch\n\n\n# Generate random numbers using PyTorch distribution\ndistribution = torch.distributions.Uniform(0, 1)\nrandom_numbers = distribution.sample((n_samples,))\n\n# Plot the histogram\nplt.hist(random_numbers.numpy(), bins=20)\nplt.xlabel('Random Number')\nplt.ylabel('Frequency')\nplt.title('Histogram of Pseudo-random Numbers')\nplt.show()\n\n\n\n\nConvert Unifom Sampling to Bernoulli Sampling\nwe can use the probablity \\((p)\\) of outcome 1 and \\((1-p)\\) of outcome 0\n\n\ndef uniform_to_bernoulli(seed, n_samples, p):\n    \"\"\"\n    Generates a sequence of pseudo-random numbers from a uniform distribution and converts them to a Bernoulli distribution.\n\n    Args:\n        seed (int): The seed value for the random number generator.\n        n_samples (int): The number of random numbers to generate.\n        p (float): The probability of generating a 1 in the Bernoulli distribution.\n\n    Returns:\n        torch.Tensor: A tensor of pseudo-random numbers following the Bernoulli distribution.\n    \"\"\"\n    torch.manual_seed(seed)\n    bernoulli_dist = dist.bernoulli.Bernoulli(probs=p)\n    bernoulli_samples = bernoulli_dist.sample((n_samples,))\n    bernoulli_numbers = bernoulli_samples.int()\n\n    return bernoulli_numbers\n\n\n\n\n\nrandom_numbers = uniform_to_bernoulli(seed, n_samples, p)\n\n# Count the occurrences of each category\ncategory_counts = torch.bincount(random_numbers.long(), minlength=2)\n\n# Plot the categories with counts\ncategories = ['0', '1']\nplt.bar(categories, category_counts)\nplt.xlabel('Label')\nplt.ylabel('Count')\nplt.title('Bernoulli Distribution')\nplt.show()\n\n\n\n\nUniform Sampling Each element has an equal probability. Graphically, a rectangular distribution is formed with uniform bars or lines in case of Bernoulli Sampling Two outcomes, success and failure, with associated probabilities (p and (1-p)). Graphically, two bars or lines represent the distribution, one taller than the other.\nFunction for uniform to Categorical\n\ndef uniform_to_categorical(seed, n_samples, num_categories):\n    \"\"\"\n    Converts pseudo-random numbers from a uniform distribution to a categorical distribution.\n\n    Args:\n        seed (int): The seed value for the random number generator.\n        n_samples (int): The number of random numbers to generate.\n        num_categories (int): The number of categories for the categorical distribution.\n\n    Returns:\n        torch.Tensor: A tensor of pseudo-random numbers following the categorical distribution.\n    \"\"\"\n    torch.manual_seed(seed)\n    categorical_distribution = dist.Categorical(torch.ones(num_categories))\n    categorical_numbers = categorical_distribution.sample((n_samples,))\n\n    return categorical_numbers\n\n\n\n\n\nPlot of Uniform to Categorical distribution\n\nrandom_numbers = uniform_to_categorical(seed, n_samples, 5)\n\n# Count the occurrences of each category\ncategory_counts = torch.bincount(random_numbers)\nprint(category_counts)\n# Compute the probabilities\nprobabilities = category_counts.int() / random_numbers.size(0)\nprint(probabilities)\n# Plot the categories with probabilities\nplt.bar(range(len(probabilities)), probabilities)\nplt.xlabel('Category')\nplt.ylabel('Probability')\nplt.title('Categorical Distribution')\nplt.show()\n\ntensor([1990, 1971, 1985, 2005, 2049])\ntensor([0.1990, 0.1971, 0.1985, 0.2005, 0.2049])\n\n\n\n\n\nCategorical Distribution multiple outcomes with different probabilities. Example: A fruit survey with apple (P = 0.4), banana (P = 0.3), and orange (P = 0.3). Graphically, bars represent each fruit choice.\n\nUniform to Normal sampling\nBox Muller Method\n\ndef uniform_to_normal_boxmuller(n_samples):\n    \"\"\"\n    Generates a sequence of pseudo-random numbers from a standard normal distribution using the Box-Muller method.\n\n    Args:\n        n_samples (int): The number of random numbers to generate.\n\n    Returns:\n        torch.Tensor: A tensor of pseudo-random numbers following the standard normal distribution.\n    \"\"\"\n    uniform_distribution = dist.Uniform(0, 1)\n    random_numbers = []\n\n    for _ in range(n_samples // 2):\n        u1 = uniform_distribution.sample()\n        u2 = uniform_distribution.sample()\n\n        z1 = torch.sqrt(-2 * torch.log(u1)) * torch.cos(2 * math.pi * u2)\n        z2 = torch.sqrt(-2 * torch.log(u1)) * torch.sin(2 * math.pi * u2)\n\n        random_numbers.append(z1)\n        random_numbers.append(z2)\n\n    if n_samples % 2 != 0:\n        u = uniform_distribution.sample()\n        z = torch.sqrt(-2 * torch.log(u)) * torch.cos(2 * math.pi * uniform_distribution.sample())\n        random_numbers.append(z)\n\n    return torch.stack(random_numbers)\n\n\nrandom_numbers = uniform_to_normal_boxmuller(10000)\n\n# Plot the histogram of random numbers\nplt.hist(random_numbers, bins=50, density=True, alpha=0.7)\nplt.xlabel('Value')\nplt.ylabel('Frequency')\nplt.title('Histogram of Random Numbers (Standard Normal Distribution)')\nplt.show()\n\n\n\n\nIn Normal Distribution Values are symmetrically distributed around a central mean. For example, heights in a population follow a bell-shaped curve, with the most common values near the mean and fewer occurrences as we move away from it. Graphically, it is represented by a bell-shaped curve."
  },
  {
    "objectID": "posts/thuplots.html",
    "href": "posts/thuplots.html",
    "title": "",
    "section": "",
    "text": "import torch\nimport torch.autograd.functional as F\nimport torch.distributions as dist\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.rcParams['font.family'] = 'sans-serif'\nplt.rcParams['font.sans-serif'] = ['Liberation Sans']\n\n\n\nimport pandas as pd\n%matplotlib inline\n\n\nfrom tueplots import bundles\nplt.rcParams.update(bundles.beamer_moml())\n#plt.rcParams.update(bundles.icml2022())\n\n\n# Also add despine to the bundle using rcParams\nplt.rcParams['axes.spines.right'] = False\nplt.rcParams['axes.spines.top'] = False\n\n# Increase font size to match Beamer template\nplt.rcParams['font.size'] = 16\n# Make background transparent\nplt.rcParams['figure.facecolor'] = 'none'\n\n\ntry:\n    import hamiltorch\nexcept ImportError:\n    %pip install git+https://github.com/AdamCobb/hamiltorch\n\n\nhamiltorch.set_random_seed(123)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice\n\ndevice(type='cpu')\n\n\n\ngt_distribution = torch.distributions.Normal(0, 1)\n\n# Samples from the ground truth distribution\ndef sample_gt(n):\n    return gt_distribution.sample((n,))\n\nsamples = sample_gt(1000)\n\n\nx_lin = torch.linspace(-3, 3, 1000)\ny_lin = torch.exp(gt_distribution.log_prob(x_lin))\n\nplt.plot(x_lin, y_lin, label='Ground truth')\n\n\n\n\n\n# Logprob function to be passed to Hamiltorch sampler\ndef logprob(x):\n    return gt_distribution.log_prob(x).sum()\n\n# Initial state\nx0 = torch.tensor([0.0])\nnum_samples = 5000\nstep_size = 0.3\nnum_steps_per_sample = 5\nhamiltorch.set_random_seed(123)\n\n\nparams_hmc = hamiltorch.sample(log_prob_func=logprob, params_init=x0,  \n                               num_samples=num_samples, step_size=step_size, \n                               num_steps_per_sample=num_steps_per_sample)\n\nSampling (Sampler.HMC; Integrator.IMPLICIT)\nTime spent  | Time remain.| Progress             | Samples   | Samples/sec\n0d:00:00:16 | 0d:00:00:00 | #################### | 5000/5000 | 308.91       \nAcceptance Rate 0.99\n\n\n\nparams_hmc = torch.tensor(params_hmc)\n# Trace plot\nplt.plot(params_hmc, label='Trace')\nplt.xlabel('Iteration')\nplt.ylabel('Parameter value')\n\nText(0, 0.5, 'Parameter value')\n\n\n\n\n\n\n# Logprob function to be passed to Hamiltorch sampler\ndef logprob(x):\n    return gt_distribution.log_prob(x).sum()\n\n# Initial state\nx0 = torch.tensor([0.0])\nnum_samples = 5000\nstep_size = 0.3\nnum_steps_per_sample = 5\nhamiltorch.set_random_seed(123)\n\n\nparams_hmc = hamiltorch.sample(log_prob_func=logprob, params_init=x0,  \n                               num_samples=num_samples, step_size=step_size, \n                               num_steps_per_sample=num_steps_per_sample)\n\nSampling (Sampler.HMC; Integrator.IMPLICIT)\nTime spent  | Time remain.| Progress             | Samples   | Samples/sec\n0d:00:00:14 | 0d:00:00:00 | #################### | 5000/5000 | 338.09       \nAcceptance Rate 0.99\n\n\n\nparams_hmc = torch.tensor(params_hmc)\n# Trace plot\nplt.plot(params_hmc, label='Trace')\nplt.xlabel('Iteration')\nplt.ylabel('Parameter value')\n\n/tmp/ipykernel_18135/1433682485.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  params_hmc = torch.tensor(params_hmc)\n\n\nText(0, 0.5, 'Parameter value')\n\n\n\n\n\n\n# KDE plot\nimport seaborn as sns\nplt.figure()\nsns.kdeplot(params_hmc.detach().numpy(), label='Samples', shade=True, color='C1')\nplt.plot(x_lin, y_lin, label='Ground truth')\nplt.xlabel('Parameter value')\nplt.ylabel('Density')\nplt.legend()\n\n/tmp/ipykernel_18135/469715340.py:4: FutureWarning: \n\n`shade` is now deprecated in favor of `fill`; setting `fill=True`.\nThis will become an error in seaborn v0.14.0; please update your code.\n\n  sns.kdeplot(params_hmc.detach().numpy(), label='Samples', shade=True, color='C1')\n\n\n&lt;matplotlib.legend.Legend at 0x7f51dfedd4b0&gt;\n\n\n\n\n\n\n# Linear regression for 1 dimensional input using HMC\n\nx_lin = torch.linspace(-3, 3, 90)\ntheta_0_true = torch.tensor([2.0])\ntheta_1_true = torch.tensor([3.0])\nf = lambda x: theta_0_true + theta_1_true * x\neps = torch.randn_like(x_lin) *1.0\ny_lin = f(x_lin) + eps\n\nplt.scatter(x_lin, y_lin, label='Data', color='C0')\nplt.plot(x_lin, f(x_lin), label='Ground truth')\nplt.xlabel('x')\nplt.ylabel('y')\n\nText(0, 0.5, 'y')"
  },
  {
    "objectID": "posts/different_losses.html",
    "href": "posts/different_losses.html",
    "title": "",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.colors\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, mean_squared_error\nfrom tqdm import tqdm_notebook \n\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.datasets import make_blobs\n\nLoading Dataset\n\n'''\n# Load Dataset from Kaggle \n#pip install kaggle\nimport os\n\nimport kaggle\n# Set Kaggle API credentials\n\n\n# Download the dataset using Kaggle API\nkaggle.api.dataset_download_files('kaggle datasets download -d lava18/google-play-store-apps')\n\n# Unzip the downloaded dataset files if necessary\n\n# Load the dataset using pandas\ndf = pd.read_csv('path_to_dataset_file.csv')\n'''\n\n\"\\n# Load Dataset from Kaggle \\n#pip install kaggle\\nimport os\\n\\nimport kaggle\\n# Set Kaggle API credentials\\n\\n\\n# Download the dataset using Kaggle API\\nkaggle.api.dataset_download_files('kaggle datasets download -d lava18/google-play-store-apps')\\n\\n# Unzip the downloaded dataset files if necessary\\n\\n# Load the dataset using pandas\\ndf = pd.read_csv('path_to_dataset_file.csv')\\n\"\n\n\n\nclass SigmoidNeuron:\n    \n  def __init__(self):\n    self.W1 = None\n    self.b1 = None\n    self.W2 = None\n    self.b2 = None\n    \n  def perceptron(self, X, W, b):\n    return np.dot(X, W.T) + b\n  \n  def sigmoid(self, X):\n    return 1.0 / (1.0 + np.exp(-X))\n  \n  def grad_w_mse(self, X, Y, Y_pred):\n    m = X.shape[0]\n    return np.dot((Y_pred - Y) * Y_pred * (1 - Y_pred), X) / m\n  \n  def grad_b_mse(self, X, Y, Y_pred):\n    m = X.shape[0]\n    return np.sum((Y_pred - Y) * Y_pred * (1 - Y_pred)) / m\n  \n  def fit(self, X, Y, epochs=1, learning_rate=1, initialise=True, loss_fn=\"mse\", display_loss=False):\n    \n    # Initialise weights and biases\n    if initialise:\n      input_dim = X.shape[1]\n      hidden_dim = 2 * input_dim\n      output_dim = 1\n      self.W1 = np.random.randn(input_dim, hidden_dim)\n      self.b1 = np.zeros(hidden_dim)\n      self.W2 = np.random.randn(hidden_dim, output_dim)\n      self.b2 = np.zeros(output_dim)\n      \n    if display_loss:\n      loss = {}\n    \n    for epoch in range(epochs):\n      # Forward Propagation\n      hidden_output = self.sigmoid(self.perceptron(X, self.W1, self.b1))\n      Y_pred = self.sigmoid(self.perceptron(hidden_output, self.W2, self.b2))\n      \n      # Backpropagation\n      dw2 = self.grad_w_mse(hidden_output, Y, Y_pred)\n      db2 = self.grad_b_mse(hidden_output, Y, Y_pred)\n      \n      dw1 = np.dot((np.dot((Y_pred - Y) * Y_pred * (1 - Y_pred), self.W2.T) * hidden_output * (1 - hidden_output)).T, X)\n      db1 = np.sum((np.dot((Y_pred - Y) * Y_pred * (1 - Y_pred), self.W2.T) * hidden_output * (1 - hidden_output)).T, axis=1)\n      \n      # Update weights and biases\n      self.W2 -= learning_rate * dw2\n      self.b2 -= learning_rate * db2\n      self.W1 -= learning_rate * dw1\n      self.b1 -= learning_rate * db1\n      \n      if display_loss:\n        loss[epoch] = np.mean((Y_pred - Y) ** 2)\n    \n    if display_loss:\n      plt.plot(list(loss.values()))\n      plt.xlabel('Epochs')\n      plt.ylabel('Mean Squared Error')\n      plt.title('Loss vs Epochs')\n      plt.show()\n      \n  def predict(self, X):\n    hidden_output = self.sigmoid(self.perceptron(X, self.W1, self.b1))\n    Y_pred = self.sigmoid(self.perceptron(hidden_output, self.W2, self.b2))\n    return Y_pred"
  }
]