[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Rishabh Mondal",
    "section": "",
    "text": "Hi! I am Rishabh Mondal.As an enthusiastic learner, I am always eager to take up challenging tasks and push my limits to achieve excellence. My academic journey has give me a strong foundation in the concepts of computer science, and I have gained practical experience through various projects\n\n\nM.Tech in Information Technology\nIndian Institute of Engineering Science and Technology, Shibpur | Sept 2021 - June 2023\nB.Tech in Computer Science and Engineering\nThe Neotia University, Kolkata |Sept 2017 - June 2021\n\n\n\n\nAn LSTM-based Fall Detection System with ROC optimization technique: A step towards more accuracy\nBrain Tumor Detection using Convolution Neural Network.\nIndian currency detection through KNN and audio transfer for blind people.\n\n\n\n\nWinner of IBM ICE DAY (poster competition)|2019"
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Rishabh Mondal",
    "section": "",
    "text": "M.Tech in Information Technology\nIndian Institute of Engineering Science and Technology, Shibpur | Sept 2021 - June 2023\nB.Tech in Computer Science and Engineering\nThe Neotia University, Kolkata |Sept 2017 - June 2021"
  },
  {
    "objectID": "index.html#project",
    "href": "index.html#project",
    "title": "Rishabh Mondal",
    "section": "",
    "text": "An LSTM-based Fall Detection System with ROC optimization technique: A step towards more accuracy\nBrain Tumor Detection using Convolution Neural Network.\nIndian currency detection through KNN and audio transfer for blind people."
  },
  {
    "objectID": "index.html#awards",
    "href": "index.html#awards",
    "title": "Rishabh Mondal",
    "section": "",
    "text": "Winner of IBM ICE DAY (poster competition)|2019"
  },
  {
    "objectID": "taylor.html",
    "href": "taylor.html",
    "title": "Taylor Series",
    "section": "",
    "text": "\\[\\begin{equation}\nf(x) = \\sum_{n=0}^{\\infty}\\frac{f^{(n)}(a)}{n!}(x-a)^{n}\n\\end{equation}\\]\nLet \\(f(x)\\) be a function that is \\(n+1\\) times differentiable on an interval \\(I\\) containing \\(a\\) and let \\(P_n(x)\\) be the \\(n\\)th degree Taylor polynomial for \\(f(x)\\) about \\(a\\). Then, there exists a number \\(c\\) between \\(a\\) and \\(x\\) such that: \\[\\begin{equation}\nf(x)=P_n(x)+R_n(x),\n\\end{equation}\\] where the remainder \\(R_n(x)\\) is given by: \\[\\begin{equation}\nR_n(x)=\\frac{f^{(n+1)}(c)}{(n+1)!}(x-a)^{n+1}.\n\\end{equation}\\]\n\nDefine the function to be approximated\n\n\nCode\nimport torch\nimport math\nimport matplotlib.pyplot as plt\nimport numpy as np\n# Define the sine function to be approximated\ndef f(x):\n    return torch.sin(x)\n\nx = torch.linspace(-3.14, 3.14, 100)\ny = f(x)\nplt.plot(x, y)\nplt.xlabel('x')\nplt.ylabel('y')\nplt.title('Sine Function')\nplt.show()\n\n\n\n\n\n\n\nFirst order Taylor approximation for f(x) at x = 0\n\n\nCode\nx = torch.tensor([0.], requires_grad=True)\ny = f(x)\napprox = y + torch.autograd.grad(y, x, create_graph=True)[0] * x\nx_vals = torch.linspace(-np.pi, np.pi, 100)\ny_vals = f(x_vals)\napprox_vals = (approx.detach() + torch.autograd.grad(approx, x, create_graph=True)[0] * x_vals).detach()\nplt.plot(x_vals.numpy(), y_vals.numpy(), label='sin(x)')\nplt.plot(x_vals.numpy(), approx_vals.numpy(), label='approx')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\nFind the nth order Taylor approximation for f(x) at x = 0\n\n\nCode\ndef fact(n):\n    return math.factorial(n)\n\ndef nth_deriv(f, a, n):\n    if isinstance(a, (float, int)):\n        a = torch.tensor([a], dtype=torch.float, requires_grad=True)\n    else:\n        a = a.clone().detach().requires_grad_(True)\n    \n    y = f(a)\n    for i in range(n):\n        y = torch.autograd.grad(y, a, create_graph=True)[0]\n    return y\n\n\n\n# nth degree Taylor polynomial of f(x) around x=a\ndef taylor(f, x, n):\n    result = torch.zeros_like(x)\n    for i in range(n+1):\n        result += nth_deriv(f, 0, i) / torch.tensor(math.factorial(i), dtype=torch.float32) * (x**i)\n    return result\nx_vals = torch.linspace(-math.pi, math.pi, 200)\nplt.plot(x_vals.numpy(), f(x_vals).numpy(), label='f(x)', lw=5)\nplt.plot(x_vals.numpy(), taylor(f, x_vals, 1).detach().numpy(), label='Taylor approximation, n=1')\nplt.plot(x_vals.numpy(), taylor(f, x_vals, 3).detach().numpy(), label='Taylor approximation, n=3')\nplt.plot(x_vals.numpy(), taylor(f, x_vals, 5).detach().numpy(), label='Taylor approximation, n=5')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\nPlot of the function g(x) = x^2 and its Taylor approximations up to degree 1 and degree 2 centered at x=0.\n\n\nCode\nx_vals = torch.linspace(-4, 4, 100)\n\ndef g(x):\n    return x**2\n\ndef taylor(f, x, n):\n    x = x.unsqueeze(-1)\n    y = f(x)\n    for i in range(1, n+1):\n        y += (x - x[0])**i / torch.tensor([math.factorial(i)]).float() * f(x[0] + 0.0)\n    return y\n\n\nplt.plot(x_vals.numpy(), g(x_vals).numpy(), label='g(x)', lw=5)\nplt.plot(x_vals.numpy(), taylor(g, x_vals, 1).detach().numpy(), label='Taylor approximation, n=1')\nplt.plot(x_vals.numpy(), taylor(g, x_vals, 3).detach().numpy(), label='Taylor approximation, n=3')\nplt.plot(x_vals.numpy(), taylor(g, x_vals, 5).detach().numpy(), label='Taylor approximation, n=5')\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "workshop.html",
    "href": "workshop.html",
    "title": "Workshop",
    "section": "",
    "text": "Workshop on Cloud Computing organized by IIT Kharagpur,2019"
  },
  {
    "objectID": "Conference.html",
    "href": "Conference.html",
    "title": "Conference",
    "section": "",
    "text": "Workshop on Cloud Computing organized by IIT Kharagpur,2019"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blogs",
    "section": "",
    "text": "Spiking neural networks (SNNs)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProbailty Distribtion\n\n\n\n\n\n\nRishabh Mondal\n\n\nJun 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nDifferent Distribution Samples\n\n\n\n\n\n\nRishabh Mondal\n\n\nFeb 7, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nTaylor Series\n\n\n\nQuarto\n\n\nPython\n\n\n\ndesp\n\n\n\nRishab Mondal\n\n\nOct 24, 2022\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/index.html",
    "href": "posts/index.html",
    "title": "Taylor Series",
    "section": "",
    "text": "\\[\\begin{equation}\nf(x) = \\sum_{n=0}^{\\infty}\\frac{f^{(n)}(a)}{n!}(x-a)^{n}\n\\end{equation}\\]\nLet \\(f(x)\\) be a function that is \\(n+1\\) times differentiable on an interval \\(I\\) containing \\(a\\) and let \\(P_n(x)\\) be the \\(n\\)th degree Taylor polynomial for \\(f(x)\\) about \\(a\\). Then, there exists a number \\(c\\) between \\(a\\) and \\(x\\) such that: \\[\\begin{equation}\nf(x)=P_n(x)+R_n(x),\n\\end{equation}\\] where the remainder \\(R_n(x)\\) is given by: \\[\\begin{equation}\nR_n(x)=\\frac{f^{(n+1)}(c)}{(n+1)!}(x-a)^{n+1}.\n\\end{equation}\\]\n\nDefine the function to be approximated\n\n\nCode\nimport torch\nimport math\nimport matplotlib.pyplot as plt\nimport numpy as np\n# Define the sine function to be approximated\ndef f(x):\n    return torch.sin(x)\n\nx = torch.linspace(-3.14, 3.14, 100)\ny = f(x)\nplt.plot(x, y)\nplt.xlabel('x')\nplt.ylabel('y')\nplt.title('Sine Function')\nplt.show()\n\n\n\n\n\n\n\nFirst order Taylor approximation for f(x) at x = 0\n\n\nCode\nx = torch.tensor([0.], requires_grad=True)\ny = f(x)\napprox = y + torch.autograd.grad(y, x, create_graph=True)[0] * x\nx_vals = torch.linspace(-np.pi, np.pi, 100)\ny_vals = f(x_vals)\napprox_vals = (approx.detach() + torch.autograd.grad(approx, x, create_graph=True)[0] * x_vals).detach()\nplt.plot(x_vals.numpy(), y_vals.numpy(), label='sin(x)')\nplt.plot(x_vals.numpy(), approx_vals.numpy(), label='approx')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\nFind the nth order Taylor approximation for f(x) at x = 0\n\n\nCode\ndef fact(n):\n    return math.factorial(n)\n\ndef nth_deriv(f, a, n):\n    if isinstance(a, (float, int)):\n        a = torch.tensor([a], dtype=torch.float, requires_grad=True)\n    else:\n        a = a.clone().detach().requires_grad_(True)\n    \n    y = f(a)\n    for i in range(n):\n        y = torch.autograd.grad(y, a, create_graph=True)[0]\n    return y\n\n\n\n# nth degree Taylor polynomial of f(x) around x=a\ndef taylor(f, x, n):\n    result = torch.zeros_like(x)\n    for i in range(n+1):\n        result += nth_deriv(f, 0, i) / torch.tensor(math.factorial(i), dtype=torch.float32) * (x**i)\n    return result\nx_vals = torch.linspace(-math.pi, math.pi, 200)\nplt.plot(x_vals.numpy(), f(x_vals).numpy(), label='f(x)', lw=5)\nplt.plot(x_vals.numpy(), taylor(f, x_vals, 1).detach().numpy(), label='Taylor approximation, n=1')\nplt.plot(x_vals.numpy(), taylor(f, x_vals, 3).detach().numpy(), label='Taylor approximation, n=3')\nplt.plot(x_vals.numpy(), taylor(f, x_vals, 5).detach().numpy(), label='Taylor approximation, n=5')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\nPlot of the function g(x) = x^2 and its Taylor approximations up to degree 1 and degree 2 centered at x=0.\n\n\nCode\nx_vals = torch.linspace(-4, 4, 100)\n\ndef g(x):\n    return x**2\n\ndef taylor(f, x, n):\n    x = x.unsqueeze(-1)\n    y = f(x)\n    for i in range(1, n+1):\n        y += (x - x[0])**i / torch.tensor([math.factorial(i)]).float() * f(x[0] + 0.0)\n    return y\n\n\nplt.plot(x_vals.numpy(), g(x_vals).numpy(), label='g(x)', lw=5)\nplt.plot(x_vals.numpy(), taylor(g, x_vals, 1).detach().numpy(), label='Taylor approximation, n=1')\nplt.plot(x_vals.numpy(), taylor(g, x_vals, 3).detach().numpy(), label='Taylor approximation, n=3')\nplt.plot(x_vals.numpy(), taylor(g, x_vals, 5).detach().numpy(), label='Taylor approximation, n=5')\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Certification",
    "section": "",
    "text": "Deep Learning from GUVI Geek Network & IITM - 2021.\nSix weeks of Summer Training on ML from IIT Kanpur,2019.\nOnline Python Training from IIT Kanpur,2019."
  },
  {
    "objectID": "probablity_distribution.html",
    "href": "probablity_distribution.html",
    "title": "Probablity Distrubutions",
    "section": "",
    "text": "Bernoulli Distribution\nTypes of Distribution : Discrete Distribution\nIn Bernoulli Distribution the random variable takes the value \\(1\\) with probability \\(p\\) and the value \\(0\\) with probability \\(1-p\\), where \\(0 ≤ p ≤ 1\\).\nThe probability mass function (PMF): \\[\\begin{equation}\nP(X = x) = p^x \\cdot (1-p)^{1-x} \\tag{1}\n\\end{equation}\\]\nWhere \\((X)\\) is the random variable, \\((x)\\) can be either 0 or \\(1\\), and \\((p)\\) is the probability of success.\n\n\nCode\np=0.6 #success=0.6 failure=0.4\nimport numpy as np\nsample = np.random.choice([0, 1], p=[1 - p, p])\nprob = (p ** sample) * ((1 - p) ** (1 - sample))\nprint(\"Sample:\", sample)\nprint(\"Probability:\", prob)\n\n#Using PyTorch\nimport torch\nfrom torch.distributions import Bernoulli\ndist=Bernoulli(torch.tensor([p]))\nsample=dist.sample()\nprint(\"Sample:\", sample)\nprint(\"Probability:\", dist)\n\n#Set of Probablty of success\nprobs = torch.tensor([0.7, 0.4, 0.9])\nbernoulli_dist = Bernoulli(probs=probs,logits=None)\nsamples = bernoulli_dist.sample()\nprint(\"probablity distributions:\", bernoulli_dist)\nprint(\"Samples:\", samples)\n\n# Log-odds of success\nlogits = torch.tensor([0.847])\ndist = Bernoulli(probs=None,logits=logits)\nsample = dist.sample()\nprint(\"log odd prob :\", dist)\nprint(\"Sample:\", sample.item())\n\n\nSample: 0\nProbability: 0.4\nSample: tensor([0.])\nProbability: Bernoulli(probs: tensor([0.6000]))\nprobablity distributions: Bernoulli(probs: torch.Size([3]))\nSamples: tensor([0., 0., 1.])\nlog odd prob : Bernoulli(probs: tensor([0.6999]), logits: tensor([0.8470]))\nSample: 0.0\n\n\nLog probability of Bernoulli distribution\nTo obtain the log probability, we take the natural logarithm of the PMF: \\[\\begin{equation}\n\\log P(X=x) = \\log(p^x \\cdot (1-p)^{1-x}) \\tag{2}\n\\end{equation}\\]\n\\[\\begin{equation}\n\\log P(X=x) = x \\cdot \\log(p) + (1-x) \\cdot \\log(1-p) \\tag{3}\n\\end{equation}\\]\n\n\nCode\nimport math\nsample=1\nprob=0.6\nlog_probability = sample * math.log(p) + (1 - sample) * math.log(1 - p)\nprint(\"sample:\", sample)\nprint(\"Log Probability:\", log_probability)\n\n#using PyTorch\nsample = torch.tensor([1])\np = torch.tensor([0.6])\ndist = Bernoulli(probs=p,logits=None)\nsample=dist.sample()\nlog_prob=dist.log_prob(sample)\nprint(\"Sample:\", sample)\nprint(\"Log Probability:\", log_prob)\n\n\nsample: 1\nLog Probability: -0.5108256237659907\nSample: tensor([0.])\nLog Probability: tensor([-0.9163])\n\n\nMaximum Likelihood Estimations(MLE) for Bernoulli Distribution\nThe MLE is a method used to estimate the parameters of a probability distribution based on observed data.\nDerivation of MLE for Bernoulli Distribution\nWe have a dataset with n binary samples:\\(x1\\) , \\(x2\\) , ..,\\(xn\\), where each \\(xi\\) is 0 or 1.\nThe likelihood function for the Bernoulli distribution is given by: \\[\\begin{equation}\nL(p) = \\prod_{i=1}^{n} p^{x_i} \\cdot (1-p)^{1-x_i}\n\\end{equation}\\]\nTaking the log-likelihood function: \\[\\begin{equation}\n\\log L(p) = \\sum_{i=1}^{n} x_i \\log p + (1-x_i) \\log (1-p)\n\\end{equation}\\]\nDifferentiating the log-likelihood function and setting it equal to zero: \\[\\begin{equation}\n\\frac{{\\partial}}{{\\partial p}} \\log L(p) = \\sum_{i=1}^{n} \\left(\\frac{{x_i}}{{p}} - \\frac{{1-x_i}}{{1-p}}\\right) = 0\n\\end{equation}\\]\nSimplifying the equation: \\[\\begin{equation}\n\\frac{{\\sum_{i=1}^{n} x_i - np}}{{p(1-p)}} = 0\n\\end{equation}\\]\nSolving for \\(p\\): \\[\\begin{equation}\nnp = \\sum_{i=1}^{n} x_i\n\\end{equation}\\]\n\n\nCode\nsize = 100\ndataset = dist.sample(torch.Size([size]))\nnum_suc=dataset.float().sum()\np_estimate=num_suc.float()/dataset.size(0)\nprint(\"MLE Estimate:\", p_estimate.item())\n\n\nMLE Estimate: 0.550000011920929\n\n\nLoss v/s iteration curve\n\n\nCode\nfrom torch.optim import Adam\nimport matplotlib.pyplot as plt\ndataset_sizes = [10, 50, 100, 200, 500,1000,10000]\ndef negative_log_likelihood(p, dataset):\n    return -(dataset * torch.log(p) + (1 - dataset) * torch.log(1 - p)).mean()\n\nfor size in dataset_sizes:\n   \n    dataset = torch.randint(low=0, high=2, size=(size,))\n    p = torch.tensor(0.5, requires_grad=True)\n    optimizer = Adam([p], lr=0.1)\n    loss_values = []\n    iteration_values = []\n    for i in range(100):\n        optimizer.zero_grad()\n        loss = negative_log_likelihood(p, dataset)\n        loss.backward()\n        optimizer.step()\n        loss_values.append(loss.item())\n        iteration_values.append(i+1)\n    plt.plot(iteration_values, loss_values, label=f'Dataset Size: {size}')\nplt.xlabel('Iteration')\nplt.ylabel('Loss')\nplt.title('Loss vs. Iteration for Varying Dataset Sizes')\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "posts/probablity_distribution.html",
    "href": "posts/probablity_distribution.html",
    "title": "Probablity Distrubutions",
    "section": "",
    "text": "Bernoulli Distribution\nTypes of Distribution : Discrete Distribution\nIn Bernoulli Distribution the random variable takes the value \\(1\\) with probability \\(p\\) and the value \\(0\\) with probability \\(1-p\\), where \\(0 ≤ p ≤ 1\\).\nThe probability mass function (PMF): \\[\\begin{equation}\nP(X = x) = p^x \\cdot (1-p)^{1-x} \\tag{1}\n\\end{equation}\\]\nWhere \\((X)\\) is the random variable, \\((x)\\) can be either 0 or \\(1\\), and \\((p)\\) is the probability of success.\n\n\nCode\np=0.6 #success=0.6 failure=0.4\nimport numpy as np\nsample = np.random.choice([0, 1], p=[1 - p, p])\nprob = (p ** sample) * ((1 - p) ** (1 - sample))\nprint(\"Sample:\", sample)\nprint(\"Probability:\", prob)\n\n#Using PyTorch\nimport torch\nfrom torch.distributions import Bernoulli\ndist=Bernoulli(torch.tensor([p]))\nsample=dist.sample()\nprint(\"Sample:\", sample)\nprint(\"Probability:\", dist)\n\n#Set of Probablty of success\nprobs = torch.tensor([0.7, 0.4, 0.9])\nbernoulli_dist = Bernoulli(probs=probs,logits=None)\nsamples = bernoulli_dist.sample()\nprint(\"probablity distributions:\", bernoulli_dist)\nprint(\"Samples:\", samples)\n\n# Log-odds of success\nlogits = torch.tensor([0.847])\ndist = Bernoulli(probs=None,logits=logits)\nsample = dist.sample()\nprint(\"log odd prob :\", dist)\nprint(\"Sample:\", sample.item())\n\n\nSample: 0\nProbability: 0.4\nSample: tensor([1.])\nProbability: Bernoulli(probs: tensor([0.6000]))\nprobablity distributions: Bernoulli(probs: torch.Size([3]))\nSamples: tensor([0., 0., 1.])\nlog odd prob : Bernoulli(probs: tensor([0.6999]), logits: tensor([0.8470]))\nSample: 0.0\n\n\nLog probability of Bernoulli distribution\nTo obtain the log probability, we take the natural logarithm of the PMF: \\[\\begin{equation}\n\\log P(X=x) = \\log(p^x \\cdot (1-p)^{1-x}) \\tag{2}\n\\end{equation}\\]\n\\[\\begin{equation}\n\\log P(X=x) = x \\cdot \\log(p) + (1-x) \\cdot \\log(1-p) \\tag{3}\n\\end{equation}\\]\n\n\nCode\nimport math\nsample=1\nprob=0.6\nlog_probability = sample * math.log(p) + (1 - sample) * math.log(1 - p)\nprint(\"sample:\", sample)\nprint(\"Log Probability:\", log_probability)\n\n#using PyTorch\nsample = torch.tensor([1])\np = torch.tensor([0.6])\ndist = Bernoulli(probs=p,logits=None)\nsample=dist.sample()\nlog_prob=dist.log_prob(sample)\nprint(\"Sample:\", sample)\nprint(\"Log Probability:\", log_prob)\n\n\nsample: 1\nLog Probability: -0.5108256237659907\nSample: tensor([0.])\nLog Probability: tensor([-0.9163])\n\n\nMaximum Likelihood Estimations(MLE) for Bernoulli Distribution\nThe MLE is a method used to estimate the parameters of a probability distribution based on observed data.\nDerivation of MLE for Bernoulli Distribution\nWe have a dataset with n binary samples:\\(x1\\) , \\(x2\\) , ..,\\(xn\\), where each \\(xi\\) is 0 or 1.\nThe likelihood function for the Bernoulli distribution is given by: \\[\\begin{equation}\nL(p) = \\prod_{i=1}^{n} p^{x_i} \\cdot (1-p)^{1-x_i}\n\\end{equation}\\]\nTaking the log-likelihood function: \\[\\begin{equation}\n\\log L(p) = \\sum_{i=1}^{n} x_i \\log p + (1-x_i) \\log (1-p)\n\\end{equation}\\]\nDifferentiating the log-likelihood function and setting it equal to zero: \\[\\begin{equation}\n\\frac{{\\partial}}{{\\partial p}} \\log L(p) = \\sum_{i=1}^{n} \\left(\\frac{{x_i}}{{p}} - \\frac{{1-x_i}}{{1-p}}\\right) = 0\n\\end{equation}\\]\nSimplifying the equation: \\[\\begin{equation}\n\\frac{{\\sum_{i=1}^{n} x_i - np}}{{p(1-p)}} = 0\n\\end{equation}\\]\nSolving for \\(p\\): \\[\\begin{equation}\nnp = \\sum_{i=1}^{n} x_i\n\\end{equation}\\]\n\n\nCode\nsize = 100\ndataset = dist.sample(torch.Size([size]))\nnum_suc=dataset.float().sum()\np_estimate=num_suc.float()/dataset.size(0)\nprint(\"MLE Estimate:\", p_estimate.item())\n\n\nMLE Estimate: 0.5899999737739563\n\n\nLoss v/s iteration curve\n\n\nCode\nfrom torch.optim import Adam\nimport matplotlib.pyplot as plt\ndataset_sizes = [10, 50, 100, 200, 500,1000,10000]\ndef negative_log_likelihood(p, dataset):\n    return -(dataset * torch.log(p) + (1 - dataset) * torch.log(1 - p)).mean()\n\nfor size in dataset_sizes:\n   \n    dataset = torch.randint(low=0, high=2, size=(size,))\n    p = torch.tensor(0.5, requires_grad=True)\n    optimizer = Adam([p], lr=0.1)\n    loss_values = []\n    iteration_values = []\n    for i in range(100):\n        optimizer.zero_grad()\n        loss = negative_log_likelihood(p, dataset)\n        loss.backward()\n        optimizer.step()\n        loss_values.append(loss.item())\n        iteration_values.append(i+1)\n    plt.plot(iteration_values, loss_values, label=f'Dataset Size: {size}')\nplt.xlabel('Iteration')\nplt.ylabel('Loss')\nplt.title('Loss vs. Iteration for Varying Dataset Sizes')\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "posts/Probablity_distibution.html",
    "href": "posts/Probablity_distibution.html",
    "title": "Probailty Distribtion",
    "section": "",
    "text": "Bernoulli distribution\n\n\nBernoulli distribution is a discret univariate probability distribution. A Bernoulli trial or experiment results in binary outcomes: success or failure \\((0 or 1)\\). The trial’s success is denoted as $ p (x=1)$, and failure is expressed as \\(1-p ( x=0)\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\[\\begin{equation}\nP(X = x) = p^x \\cdot (1-p)^{1-x} \\tag{1}\n\\end{equation}\\]\nwhere \\((X)\\) is the random variable, \\((x)\\) can be either 0 or 1, and \\((p)\\) is the probability of success.\nSome imports\n\nimport numpy as np\nimport torch\nfrom torch.distributions import Bernoulli\nimport math\nfrom torch.optim import Adam\nimport matplotlib.pyplot as plt\n\nImplementation of PMF\n\np=0.6 #success=0.6 failure=0.4\nimport numpy as np\nsample = np.random.choice([0, 1], p=[1 - p, p])\nprob = (p ** sample) * ((1 - p) ** (1 - sample))\nprint(\"Sample:\", sample)\nprint(\"Probability:\", prob)\n\n#Using PyTorch\nimport torch\nfrom torch.distributions import Bernoulli\ndist=Bernoulli(torch.tensor([p]))\nsample=dist.sample()\nprint(\"Sample:\", sample)\nprint(\"Probability:\", dist)\n\n#Set of Probablty of success\nprobs = torch.tensor([0.7, 0.4, 0.9])\nbernoulli_dist = Bernoulli(probs=probs,logits=None)\nsamples = bernoulli_dist.sample()\nprint(\"probablity distributions:\", bernoulli_dist)\nprint(\"Samples:\", samples)\n\n# Log-odds of success\nlogits = torch.tensor([0.847])\ndist = Bernoulli(probs=None,logits=logits)\nsample = dist.sample()\nprint(\"log odd prob :\", dist)\nprint(\"Sample:\", sample.item())\n\nSample: 0\nProbability: 0.4\nSample: tensor([1.])\nProbability: Bernoulli(probs: tensor([0.6000]))\nprobablity distributions: Bernoulli(probs: torch.Size([3]))\nSamples: tensor([1., 0., 1.])\nlog odd prob : Bernoulli(probs: tensor([0.6999]), logits: tensor([0.8470]))\nSample: 1.0\n\n\nLog probability of Bernoulli distribution\nTo obtain the log probability, we take the natural logarithm of the PMF:\n\\[\\begin{equation}\n\\log P(X=x) = \\log(p^x \\cdot (1-p)^{1-x})\n\\end{equation}\\]\n\\[\\begin{equation}\n\\log P(X=x) = x \\cdot \\log(p) + (1-x) \\cdot \\log(1-p)\n\\end{equation}\\]\n\nsample=1\nprob=0.6\nlog_probability = sample * math.log(p) + (1 - sample) * math.log(1 - p)\nprint(\"sample:\", sample)\nprint(\"Log Probability:\", log_probability)\n\n#using PyTorch\nsample = torch.tensor([1])\np = torch.tensor([0.6])\ndist = Bernoulli(probs=p,logits=None)\nsample=dist.sample()\nlog_prob=dist.log_prob(sample)\nprint(\"Sample:\", sample)\nprint(\"Log Probability:\", log_prob)\n\nsample: 1\nLog Probability: -0.5108256237659907\nSample: tensor([1.])\nLog Probability: tensor([-0.5108])\n\n\nMaximum Likelihood Estimations(MLE) for Bernoulli Distribution\nTo derive the Maximum Likelihood Estimation (MLE) for the Bernoulli distribution, let’s assume we have a random sample of independent and identically distributed (i.i.d.) observations from a Bernoulli distribution with parameter p. Each observation can take a value of either 0 or 1.\nThe likelihood function for the Bernoulli distribution is given by:\n\\[ L(p) = \\prod_{i=1}^{n} p^{x_i} \\cdot (1-p)^{1-x_i} \\]\nwhere (x_i) is the i-th observation in the sample and n is the total number of observations.\nTo find the MLE for p, we want to find the value of p that maximizes the likelihood function L(p). It is often easier to work with the log-likelihood function, which is the natural logarithm of the likelihood function:\n\\[\n\\log L(p) = \\sum_{i=1}^{n} x_i \\cdot \\log(p) + (1-x_i) \\cdot \\log(1-p)\n\\]\nTo find the MLE, we differentiate the log-likelihood function with respect to p and set it equal to zero:\n\\[\n\\frac{d}{dp}(\\log L(p)) = \\frac{1}{p}\\sum_{i=1}^{n} x_i - \\frac{1}{1-p}\\sum_{i=1}^{n} (1-x_i) = 0\n\\]\nSimplifying the equation:\n\\[\n\\frac{1}{p}\\sum_{i=1}^{n} x_i - \\frac{n}{1-p} + \\frac{1}{1-p}\\sum_{i=1}^{n} x_i = 0\n\\]\nMultiplying through by p(1-p):\n\\[\n(1-p)\\sum_{i=1}^{n} x_i - np + p\\sum_{i=1}^{n} x_i = 0\n\\]\nRearranging the terms:\n\\[\n\\sum_{i=1}^{n} x_i - np = 0\n\\] Finally, solving for p:\n\\[\np = \\frac{1}{n}\\sum_{i=1}^{n} x_i\n\\]\nTherefore, the MLE for the parameter p in the Bernoulli distribution is the sample mean of the observed values.\nIt is important to note that this MLE is consistent, unbiased, and efficient for estimating the parameter p in the Bernoulli distribution.\n\nsize = 100\ndataset = dist.sample(torch.Size([size]))\nnum_suc=dataset.float().sum()\np_estimate=num_suc.float()/dataset.size(0)\nprint(\"MLE Estimate:\", p_estimate.item())\n\nMLE Estimate: 0.6299999952316284\n\n\nPerforming Maximum Likelihood Estimation (MLE) for the Bernoulli distribution with varying dataset sizes. It computes the negative log-likelihood loss for different dataset sizes and optimizes the parameter ‘p’ to minimize the loss using the Adam optimizer.\nThe resulting loss values are then plotted against the iterations to visualize the convergence of the MLE estimation.\n\ndataset_sizes = [10, 50, 100, 200, 500,1000,10000]\ndef negative_log_likelihood(p, dataset):\n    return -(dataset * torch.log(p) + (1 - dataset) * torch.log(1 - p)).mean()\n\nfor size in dataset_sizes:\n   \n    dataset = torch.randint(low=0, high=2, size=(size,))\n    p = torch.tensor(0.5, requires_grad=True)\n    optimizer = Adam([p], lr=0.1)\n    loss_values = []\n    iteration_values = []\n    for i in range(100):\n        optimizer.zero_grad()\n        loss = negative_log_likelihood(p, dataset)\n        loss.backward()\n        optimizer.step()\n        loss_values.append(loss.item())\n        iteration_values.append(i+1)\n    plt.plot(iteration_values, loss_values, label=f'Dataset Size: {size}')\nplt.xlabel('Iteration')\nplt.ylabel('Loss')\nplt.title('Loss vs. Iteration for Varying Dataset Sizes')\nplt.legend()\nplt.show()\n\n\n\n\nThe plot shows the relationship between the loss and the number of iterations for each dataset size.\nBy examining the plot, we can observe the following:\n\nAs the dataset size increases, the convergence to the optimal parameter value tends to be faster. This is because larger datasets provide more information, allowing for more accurate estimation.\nFor smaller dataset sizes (e.g., 10, 50, 100), the loss tends to fluctuate more initially. However, as the number of iterations increases, the loss converges to a stable value.\nFor larger dataset sizes (e.g., 1000, 10000), the loss tends to converge quickly and stabilize earlier compared to smaller dataset sizes."
  },
  {
    "objectID": "posts/Probablity_distibution.html#introduction",
    "href": "posts/Probablity_distibution.html#introduction",
    "title": "Bernoulli distribution",
    "section": "",
    "text": "Bernoulli distribution is a discret univariate probability distribution. A Bernoulli trial or experiment results in binary outcomes: success or failure \\((0 or 1)\\). The trial’s success is denoted as $ p (x=1)$, and failure is expressed as \\(1-p ( x=0)\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n$ \\[\\begin{equation}\nP(X = x) = p^x \\cdot (1-p)^{1-x} \\tag{1}\n\\end{equation}\\] $ where \\((X)\\) is the random variable, \\((x)\\) can be either 0 or 1, and \\((p)\\) is the probability of success.\nSome imports\n\nimport numpy as np\nimport torch\nfrom torch.distributions import Bernoulli\nimport math\nfrom torch.optim import Adam\nimport matplotlib.pyplot as plt\n\nImplementation of PMF\n\np=0.6 #success=0.6 failure=0.4\nimport numpy as np\nsample = np.random.choice([0, 1], p=[1 - p, p])\nprob = (p ** sample) * ((1 - p) ** (1 - sample))\nprint(\"Sample:\", sample)\nprint(\"Probability:\", prob)\n\n#Using PyTorch\nimport torch\nfrom torch.distributions import Bernoulli\ndist=Bernoulli(torch.tensor([p]))\nsample=dist.sample()\nprint(\"Sample:\", sample)\nprint(\"Probability:\", dist)\n\n#Set of Probablty of success\nprobs = torch.tensor([0.7, 0.4, 0.9])\nbernoulli_dist = Bernoulli(probs=probs,logits=None)\nsamples = bernoulli_dist.sample()\nprint(\"probablity distributions:\", bernoulli_dist)\nprint(\"Samples:\", samples)\n\n# Log-odds of success\nlogits = torch.tensor([0.847])\ndist = Bernoulli(probs=None,logits=logits)\nsample = dist.sample()\nprint(\"log odd prob :\", dist)\nprint(\"Sample:\", sample.item())\n\nSample: 1\nProbability: 0.6\nSample: tensor([0.])\nProbability: Bernoulli(probs: tensor([0.6000]))\nprobablity distributions: Bernoulli(probs: torch.Size([3]))\nSamples: tensor([0., 1., 0.])\nlog odd prob : Bernoulli(probs: tensor([0.6999]), logits: tensor([0.8470]))\nSample: 1.0\n\n\nLog probability of Bernoulli distribution\nTo obtain the log probability, we take the natural logarithm of the PMF: $ \\[\\begin{equation}\n\\log P(X=x) = \\log(p^x \\cdot (1-p)^{1-x})\n\\end{equation}\\] $ $ \\[\\begin{equation}\n\\log P(X=x) = x \\cdot \\log(p) + (1-x) \\cdot \\log(1-p)\n\\end{equation}\\] $\n\nsample=1\nprob=0.6\nlog_probability = sample * math.log(p) + (1 - sample) * math.log(1 - p)\nprint(\"sample:\", sample)\nprint(\"Log Probability:\", log_probability)\n\n#using PyTorch\nsample = torch.tensor([1])\np = torch.tensor([0.6])\ndist = Bernoulli(probs=p,logits=None)\nsample=dist.sample()\nlog_prob=dist.log_prob(sample)\nprint(\"Sample:\", sample)\nprint(\"Log Probability:\", log_prob)\n\nsample: 1\nLog Probability: -0.5108256237659907\nSample: tensor([1.])\nLog Probability: tensor([-0.5108])\n\n\nMaximum Likelihood Estimations(MLE) for Bernoulli Distribution\nTo derive the Maximum Likelihood Estimation (MLE) for the Bernoulli distribution, let’s assume we have a random sample of independent and identically distributed (i.i.d.) observations from a Bernoulli distribution with parameter p. Each observation can take a value of either 0 or 1.\nThe likelihood function for the Bernoulli distribution is given by:\n$ L(p) = _{i=1}^{n} p^{x_i} (1-p)^{1-x_i} $\nwhere (x_i) is the i-th observation in the sample and n is the total number of observations.\nTo find the MLE for p, we want to find the value of p that maximizes the likelihood function L(p). It is often easier to work with the log-likelihood function, which is the natural logarithm of the likelihood function:\n$ L(p) = _{i=1}^{n} x_i (p) + (1-x_i) (1-p) $\nTo find the MLE, we differentiate the log-likelihood function with respect to p and set it equal to zero:\n$ (L(p)) = {i=1}^{n} x_i - {i=1}^{n} (1-x_i) = 0 $\nSimplifying the equation:\n$ {i=1}^{n} x_i - + {i=1}^{n} x_i = 0 $\nMultiplying through by p(1-p):\n$ (1-p){i=1}^{n} x_i - np + p{i=1}^{n} x_i = 0 $\nRearranging the terms:\n$ _{i=1}^{n} x_i - np = 0 $ Finally, solving for p:\n$ p = _{i=1}^{n} x_i $\nTherefore, the MLE for the parameter p in the Bernoulli distribution is the sample mean of the observed values.\nIt is important to note that this MLE is consistent, unbiased, and efficient for estimating the parameter p in the Bernoulli distribution.\n\nsize = 100\ndataset = dist.sample(torch.Size([size]))\nnum_suc=dataset.float().sum()\np_estimate=num_suc.float()/dataset.size(0)\nprint(\"MLE Estimate:\", p_estimate.item())\n\nMLE Estimate: 0.6100000143051147\n\n\nPerforming Maximum Likelihood Estimation (MLE) for the Bernoulli distribution with varying dataset sizes. It computes the negative log-likelihood loss for different dataset sizes and optimizes the parameter ‘p’ to minimize the loss using the Adam optimizer.\nThe resulting loss values are then plotted against the iterations to visualize the convergence of the MLE estimation.\n\ndataset_sizes = [10, 50, 100, 200, 500,1000,10000]\ndef negative_log_likelihood(p, dataset):\n    return -(dataset * torch.log(p) + (1 - dataset) * torch.log(1 - p)).mean()\n\nfor size in dataset_sizes:\n   \n    dataset = torch.randint(low=0, high=2, size=(size,))\n    p = torch.tensor(0.5, requires_grad=True)\n    optimizer = Adam([p], lr=0.1)\n    loss_values = []\n    iteration_values = []\n    for i in range(100):\n        optimizer.zero_grad()\n        loss = negative_log_likelihood(p, dataset)\n        loss.backward()\n        optimizer.step()\n        loss_values.append(loss.item())\n        iteration_values.append(i+1)\n    plt.plot(iteration_values, loss_values, label=f'Dataset Size: {size}')\nplt.xlabel('Iteration')\nplt.ylabel('Loss')\nplt.title('Loss vs. Iteration for Varying Dataset Sizes')\nplt.legend()\nplt.show()\n\n\n\n\nThe plot shows the relationship between the loss and the number of iterations for each dataset size.\nBy examining the plot, we can observe the following:\n\nAs the dataset size increases, the convergence to the optimal parameter value tends to be faster. This is because larger datasets provide more information, allowing for more accurate estimation.\nFor smaller dataset sizes (e.g., 10, 50, 100), the loss tends to fluctuate more initially. However, as the number of iterations increases, the loss converges to a stable value.\nFor larger dataset sizes (e.g., 1000, 10000), the loss tends to converge quickly and stabilize earlier compared to smaller dataset sizes."
  },
  {
    "objectID": "posts/Probablity_distibution.html#probablity-distribution",
    "href": "posts/Probablity_distibution.html#probablity-distribution",
    "title": "Probailty Distribtion",
    "section": "",
    "text": "Bernoulli distribution\n\n\nBernoulli distribution is a discret univariate probability distribution. A Bernoulli trial or experiment results in binary outcomes: success or failure \\((0 or 1)\\). The trial’s success is denoted as $ p (x=1)$, and failure is expressed as \\(1-p ( x=0)\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\[\\begin{equation}\nP(X = x) = p^x \\cdot (1-p)^{1-x} \\tag{1}\n\\end{equation}\\]\nwhere \\((X)\\) is the random variable, \\((x)\\) can be either 0 or 1, and \\((p)\\) is the probability of success.\nSome imports\n\nimport numpy as np\nimport torch\nfrom torch.distributions import Bernoulli\nimport math\nfrom torch.optim import Adam\nimport matplotlib.pyplot as plt\n\nImplementation of PMF\n\np=0.6 #success=0.6 failure=0.4\nimport numpy as np\nsample = np.random.choice([0, 1], p=[1 - p, p])\nprob = (p ** sample) * ((1 - p) ** (1 - sample))\nprint(\"Sample:\", sample)\nprint(\"Probability:\", prob)\n\n#Using PyTorch\nimport torch\nfrom torch.distributions import Bernoulli\ndist=Bernoulli(torch.tensor([p]))\nsample=dist.sample()\nprint(\"Sample:\", sample)\nprint(\"Probability:\", dist)\n\n#Set of Probablty of success\nprobs = torch.tensor([0.7, 0.4, 0.9])\nbernoulli_dist = Bernoulli(probs=probs,logits=None)\nsamples = bernoulli_dist.sample()\nprint(\"probablity distributions:\", bernoulli_dist)\nprint(\"Samples:\", samples)\n\n# Log-odds of success\nlogits = torch.tensor([0.847])\ndist = Bernoulli(probs=None,logits=logits)\nsample = dist.sample()\nprint(\"log odd prob :\", dist)\nprint(\"Sample:\", sample.item())\n\nSample: 0\nProbability: 0.4\nSample: tensor([1.])\nProbability: Bernoulli(probs: tensor([0.6000]))\nprobablity distributions: Bernoulli(probs: torch.Size([3]))\nSamples: tensor([1., 0., 1.])\nlog odd prob : Bernoulli(probs: tensor([0.6999]), logits: tensor([0.8470]))\nSample: 1.0\n\n\nLog probability of Bernoulli distribution\nTo obtain the log probability, we take the natural logarithm of the PMF:\n\\[\\begin{equation}\n\\log P(X=x) = \\log(p^x \\cdot (1-p)^{1-x})\n\\end{equation}\\]\n\\[\\begin{equation}\n\\log P(X=x) = x \\cdot \\log(p) + (1-x) \\cdot \\log(1-p)\n\\end{equation}\\]\n\nsample=1\nprob=0.6\nlog_probability = sample * math.log(p) + (1 - sample) * math.log(1 - p)\nprint(\"sample:\", sample)\nprint(\"Log Probability:\", log_probability)\n\n#using PyTorch\nsample = torch.tensor([1])\np = torch.tensor([0.6])\ndist = Bernoulli(probs=p,logits=None)\nsample=dist.sample()\nlog_prob=dist.log_prob(sample)\nprint(\"Sample:\", sample)\nprint(\"Log Probability:\", log_prob)\n\nsample: 1\nLog Probability: -0.5108256237659907\nSample: tensor([1.])\nLog Probability: tensor([-0.5108])\n\n\nMaximum Likelihood Estimations(MLE) for Bernoulli Distribution\nTo derive the Maximum Likelihood Estimation (MLE) for the Bernoulli distribution, let’s assume we have a random sample of independent and identically distributed (i.i.d.) observations from a Bernoulli distribution with parameter p. Each observation can take a value of either 0 or 1.\nThe likelihood function for the Bernoulli distribution is given by:\n\\[ L(p) = \\prod_{i=1}^{n} p^{x_i} \\cdot (1-p)^{1-x_i} \\]\nwhere (x_i) is the i-th observation in the sample and n is the total number of observations.\nTo find the MLE for p, we want to find the value of p that maximizes the likelihood function L(p). It is often easier to work with the log-likelihood function, which is the natural logarithm of the likelihood function:\n\\[\n\\log L(p) = \\sum_{i=1}^{n} x_i \\cdot \\log(p) + (1-x_i) \\cdot \\log(1-p)\n\\]\nTo find the MLE, we differentiate the log-likelihood function with respect to p and set it equal to zero:\n\\[\n\\frac{d}{dp}(\\log L(p)) = \\frac{1}{p}\\sum_{i=1}^{n} x_i - \\frac{1}{1-p}\\sum_{i=1}^{n} (1-x_i) = 0\n\\]\nSimplifying the equation:\n\\[\n\\frac{1}{p}\\sum_{i=1}^{n} x_i - \\frac{n}{1-p} + \\frac{1}{1-p}\\sum_{i=1}^{n} x_i = 0\n\\]\nMultiplying through by p(1-p):\n\\[\n(1-p)\\sum_{i=1}^{n} x_i - np + p\\sum_{i=1}^{n} x_i = 0\n\\]\nRearranging the terms:\n\\[\n\\sum_{i=1}^{n} x_i - np = 0\n\\] Finally, solving for p:\n\\[\np = \\frac{1}{n}\\sum_{i=1}^{n} x_i\n\\]\nTherefore, the MLE for the parameter p in the Bernoulli distribution is the sample mean of the observed values.\nIt is important to note that this MLE is consistent, unbiased, and efficient for estimating the parameter p in the Bernoulli distribution.\n\nsize = 100\ndataset = dist.sample(torch.Size([size]))\nnum_suc=dataset.float().sum()\np_estimate=num_suc.float()/dataset.size(0)\nprint(\"MLE Estimate:\", p_estimate.item())\n\nMLE Estimate: 0.6299999952316284\n\n\nPerforming Maximum Likelihood Estimation (MLE) for the Bernoulli distribution with varying dataset sizes. It computes the negative log-likelihood loss for different dataset sizes and optimizes the parameter ‘p’ to minimize the loss using the Adam optimizer.\nThe resulting loss values are then plotted against the iterations to visualize the convergence of the MLE estimation.\n\ndataset_sizes = [10, 50, 100, 200, 500,1000,10000]\ndef negative_log_likelihood(p, dataset):\n    return -(dataset * torch.log(p) + (1 - dataset) * torch.log(1 - p)).mean()\n\nfor size in dataset_sizes:\n   \n    dataset = torch.randint(low=0, high=2, size=(size,))\n    p = torch.tensor(0.5, requires_grad=True)\n    optimizer = Adam([p], lr=0.1)\n    loss_values = []\n    iteration_values = []\n    for i in range(100):\n        optimizer.zero_grad()\n        loss = negative_log_likelihood(p, dataset)\n        loss.backward()\n        optimizer.step()\n        loss_values.append(loss.item())\n        iteration_values.append(i+1)\n    plt.plot(iteration_values, loss_values, label=f'Dataset Size: {size}')\nplt.xlabel('Iteration')\nplt.ylabel('Loss')\nplt.title('Loss vs. Iteration for Varying Dataset Sizes')\nplt.legend()\nplt.show()\n\n\n\n\nThe plot shows the relationship between the loss and the number of iterations for each dataset size.\nBy examining the plot, we can observe the following:\n\nAs the dataset size increases, the convergence to the optimal parameter value tends to be faster. This is because larger datasets provide more information, allowing for more accurate estimation.\nFor smaller dataset sizes (e.g., 10, 50, 100), the loss tends to fluctuate more initially. However, as the number of iterations increases, the loss converges to a stable value.\nFor larger dataset sizes (e.g., 1000, 10000), the loss tends to converge quickly and stabilize earlier compared to smaller dataset sizes."
  },
  {
    "objectID": "posts/Sampling_distributions.html",
    "href": "posts/Sampling_distributions.html",
    "title": "Different Distribution Samples",
    "section": "",
    "text": "Bernoulli, Categorical, Uniform, Normal, Beta and Gamma distributions\n\n\nSome imports\n\n#Important libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.distributions as dist\nimport math\nfrom tueplots import bundles\nplt.rcParams.update(bundles.beamer_moml())\nfrom IPython.display import Image\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline\n\nNotes\nTUEplots: Extend matplotlib for scientific publications\n\n\nA function to make the Matplotlib plots prettier\n\nSPINE_COLOR = 'red'\n\ndef format_axes(ax):\n    for spine in ['top', 'right']:\n        ax.spines[spine].set_visible(False)\n\n    for spine in ['left', 'bottom']:\n        ax.spines[spine].set_color(SPINE_COLOR)\n        ax.spines[spine].set_linewidth(0.5)\n\n    ax.xaxis.set_ticks_position('bottom')\n    ax.yaxis.set_ticks_position('left')\n\n    for axis in [ax.xaxis, ax.yaxis]:\n        axis.set_tick_params(direction='out', color=SPINE_COLOR)\n\n    return ax\n\n\n\nPre-defined values\n\n\nn_samples=10000\nseed=42\np=0.4\nnum_categories=5\n\n\n\nUniform distribution\nA continuous random variable X is said to have a Uniform distribution over the interval [a,b] , shown as X∼Uniform(a,b) , if its PDF is given by \\[\nX(x) = \\begin{cases}\n1 & \\text{if } a &lt; x &lt; b \\\\\n0 & \\text{if } b \\leq x &lt; a \\\\\n\\end{cases}\n\\]\nWe can also plot and visualise the same phenomenon using a histogram shown below.\n\ndistribution = torch.distributions.Uniform(0, 1)\nrandom_numbers = distribution.sample((n_samples,))\nplt.hist(random_numbers.numpy(), bins=20)\nformat_axes(plt.gca())\n\n&lt;Axes: &gt;\n\n\n\n\n\nWe can notice that all outcomes within a given range are equally likely , ploted as a rectangular graph.\n\n\nBernoulli distribution\nBernoulli Distribution is a discrete probability distribution used for experiments with yes/no outcomes. It represents a single trial with two possible outcomes: success (1) with probability p or failure (0) with probability (1 - p).\n\\[\nf(x, p) = \\begin{cases}\np & \\text{if } x = 1 \\\\\n1 - p & \\text{if } x = 0 \\\\\n\\end{cases}\n\\]\nWe can also express this formula as: \\[\nPMF = f(x, p) = px(1 - p)^{1 - x}, \\text{ where } x \\in \\{0, 1\\}\n\\]\n\nfrom torch.distributions import Bernoulli\np=torch.tensor(p)\nBernoulli_samples = Bernoulli(probs=p,logits=None).sample((n_samples,))\nplt.hist(Bernoulli_samples.numpy(), bins=3)\nplt.xticks([0, 1], ['0', '1'])\nformat_axes(plt.gca())\n\n&lt;Axes: &gt;\n\n\n\n\n\nImportant things to note\nprobs: Directly known probability values (0-1), providing a direct interpretation of probabilities.\nlogits: Log-odds or transformed probabilities (using sigmoid) useful for like LR or NN models outputting logits.\n\n\nCategorical distribution\nStory - In a set of discrete outcomes, each outcome is assigned a probability.\nExample - The student has a \\(p_{a}\\) probability of studying, a \\(p_{b}\\) probability of going out with friends, and a \\(p_{c}\\) probability of watching a movie.\n\\[\nf(x; p_1, p_2, ..., p_k) =\n\\begin{cases}\np_1 & \\text{if } x = 1 \\\\\np_2 & \\text{if } x = 2 \\\\\n\\vdots \\\\\np_k & \\text{if } x = k \\\\\n\\end{cases}\n\\]\n\nfrom torch.distributions import Categorical\ncategorical_distribution = Categorical(torch.ones(num_categories))\ncategorical_numbers = categorical_distribution.sample((n_samples,))\ncategory_counts = torch.bincount(categorical_numbers)\n# Compute the probabilities\nprobabilities = category_counts / n_samples\nplt.bar(range(len(probabilities)), probabilities)\nformat_axes(plt.gca())\n\n&lt;Axes: &gt;\n\n\n\n\n\nSupport - If we index the categories with sequential integers from 1 to N, the distribution is supported for integers 1 to N, inclusive when described using the indices of the categories.\n\n\nNormal distribution\nStory - The normal distribution arises when many small factors contribute to a quantity without any extreme variations, resulting in a bell-shaped curve.\nExample - When measuring the heights of a large population, we typically find that the distribution follows a bell-shaped curve, with the majority of individuals clustering around the average height and fewer individuals at the extremes (very tall or very short)\n\\[\nf(x|\\mu, \\sigma) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}\n\\]\nMoments\nMean: \\(\\mu\\) , Variance: \\(\\sigma\\)\n\nfrom torch.distributions import Normal\nmean = torch.tensor([0.0])\nstddev = torch.tensor([1.0])\ndist = Normal(mean, stddev)\nx = np.linspace(-5, 5, 100)\n# Calculate the corresponding probability density for each x\npdf = torch.exp(dist.log_prob(torch.tensor(x))).numpy()\n\n# Plot the normal distribution\nplt.plot(x, pdf)\nformat_axes(plt.gca())\n\n&lt;Axes: &gt;\n\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Set the mean and standard deviation of the original normal distribution\nmu = 0\nsigma = 1\n\n# Set the desired mean and standard deviation of the converted normal distribution\na = 5\nb = 2\n\n# Generate random samples from the standard normal distribution\nx = np.random.normal(mu, sigma, 1000)\n\n# Apply the transformation to convert to the desired normal distribution\ny = a + b * x\n\n# Plot the histogram of the converted normal distribution\nplt.hist(y, bins=20, density=True, alpha=0.5)\nplt.xlabel('Value')\nplt.ylabel('Density')\nplt.title(f'Normal Distribution: μ = {a}, σ = {b}')\nplt.show()\n\n\n\n\n\n\nBeta distributions\nStory : Let’s say you have two processes, each consisting of multiple steps. Both processes occur at the same rate, but the first process requires \\(\\alpha\\) step and the second process \\(\\beta\\) ,the fraction of the total waiting time taken by the first process is Beta distributed .\nExample : Include the Click-Through Rate (CTR) of an advertisement, the conversion rate of customers purchasing on your website.\n\\[f(x; \\alpha, \\beta) = \\frac{x^{\\alpha-1} (1-x)^{\\beta-1}}{B(\\alpha, \\beta)}\\]\nwhere\n\\[B(\\alpha, \\beta) = \\int_0^1 x^{\\alpha-1} (1-x)^{\\beta-1} dx\\]\nSupport : The Beta distribution has support on the interval [0, 1].\nMoments :\n\\(\\mu = \\frac{\\alpha}{\\alpha + \\beta}\\)\n\\(\\sigma^2 = \\frac{\\alpha \\beta}{(\\alpha + \\beta)^2 (\\alpha + \\beta + 1)}\\)\n\nalpha = 2\nbeta = 7\n# Create a Beta distribution object\nbeta_dist = torch.distributions.Beta(alpha, beta)\nsamples = beta_dist.sample((n_samples,))\nsamples_np = samples.numpy()\nplt.hist(samples_np, bins=30, density=True)\n\n# Plot the probability density function (PDF)\nx = torch.linspace(0, 1, n_samples)\npdf = beta_dist.log_prob(x).exp()\nplt.plot(x.numpy(), pdf.numpy(), 'r-', linewidth=2)\nformat_axes(plt.gca())\n\n&lt;Axes: &gt;\n\n\n\n\n\n\n\nGamma distrubution\n\nimport torch\nimport matplotlib.pyplot as plt\n\n# Set the parameters for the Gamma distribution\nalpha = 2.0\nbeta = 1.0\n\n# Create a Gamma distribution object\ngamma_dist = torch.distributions.Gamma(alpha, beta)\n\n# Generate samples from the distribution\nsamples = gamma_dist.sample((n_samples,))\n\n# Convert samples to numpy array\nsamples_np = samples.numpy()\n\n# Plot the histogram of samples\nplt.hist(samples_np, bins=30, density=True)\n\n# Plot the probability density function (PDF)\nx = torch.linspace(0, 10, 1000)\npdf = gamma_dist.log_prob(x).exp()\nplt.plot(x.numpy(), pdf.numpy(), 'r-', linewidth=2)\n\n# Add labels and title\nplt.xlabel('X')\nplt.ylabel('Probability Density')\nplt.title('Gamma Distribution')\n\n# Display the plot\nplt.show()\n\n\n\n\n\n\nImplementing a pseudo-random number generator (PRNG)\nImplementing a pseudo-random number generator (PRNG) - Generates a sequence of numbers that exhibit properties of randomness\nLinear Congruential Generator (LCG) is a simple PRNG algorithm - The LCG algorithm is defined by the recurrence relation:\n\\(X_{n+1} = (a \\cdot X_n + c) \\mod m\\)\n\n\\(X_{n+1}\\) is the Next pseudo-random number.\n\\(X_n\\) is the current pseudo-random number.\n\\(a\\) is the multiplier , determines the period of the generated number.\n\\(c\\) is the increment, shifts the generated sequence.\n\\(m\\) is the modulus, determines the range of values .\n\nInteger Constant\n\\(m,{0&lt;m}\\) — The modulus\n\\(a,0&lt;a&lt;m\\) — The multiplier\n\\(c,0&lt;=c&lt;m\\) — The increment\n\\(X_{0},0&lt;X_{0}&lt;m\\) — The seed / start value\n\n# Function for Linear Congruential Generator\ndef lcg(seed, n_samples):\n    \"\"\"\n    Generates a sequence of pseudo-random numbers using the Linear Congruential Generator (LCG) algorithm.\n\n    Args:\n        seed (int): The seed value for the LCG algorithm.\n        n_samples (int): The number of random numbers to generate.\n\n    Returns:\n        list: A list of pseudo-random numbers normalized to the range [0, 1].\n    \"\"\"\n    a = 1103515245\n    c = 12345\n    m = 2 ** 31\n    random_numbers = []\n\n    for _ in range(n_samples):\n        seed = (a * seed + c) % m\n        random_number = seed / m  # Normalize to range [0, 1]\n        random_numbers.append(random_number)\n\n    return random_numbers\n\nPlot histogram\n\n\n# Example usage:\nrandom_numbers = lcg(seed, n_samples )\n\nplt.hist(random_numbers, bins=20)\nplt.xlabel('Random Number')\nplt.ylabel('Frequency')\nplt.title('Histogram of Pseudo-random Numbers')\nplt.show()\n\n\n\n\n\n\nUniform to Normal sampling\nBox Muller Method\n\ndef uniform_to_normal_boxmuller(n_samples):\n    \"\"\"\n    Generates a sequence of pseudo-random numbers from a standard normal distribution using the Box-Muller method.\n\n    Args:\n        n_samples (int): The number of random numbers to generate.\n\n    Returns:\n        torch.Tensor: A tensor of pseudo-random numbers following the standard normal distribution.\n    \"\"\"\n    uniform_distribution = dist.Uniform(0, 1)\n    random_numbers = []\n\n    for _ in range(n_samples // 2):\n        u1 = uniform_distribution.sample()\n        u2 = uniform_distribution.sample()\n\n        z1 = torch.sqrt(-2 * torch.log(u1)) * torch.cos(2 * math.pi * u2)\n        z2 = torch.sqrt(-2 * torch.log(u1)) * torch.sin(2 * math.pi * u2)\n\n        random_numbers.append(z1)\n        random_numbers.append(z2)\n\n    if n_samples % 2 != 0:\n        u = uniform_distribution.sample()\n        z = torch.sqrt(-2 * torch.log(u)) * torch.cos(2 * math.pi * uniform_distribution.sample())\n        random_numbers.append(z)\n\n    return torch.stack(random_numbers)\n\nIn Normal Distribution Values are symmetrically distributed around a central mean. For example, heights in a population follow a bell-shaped curve, with the most common values near the mean and fewer occurrences as we move away from it. Graphically, it is represented by a bell-shaped curve."
  },
  {
    "objectID": "posts/thuplots.html",
    "href": "posts/thuplots.html",
    "title": "",
    "section": "",
    "text": "import torch\nimport torch.autograd.functional as F\nimport torch.distributions as dist\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.rcParams['font.family'] = 'sans-serif'\nplt.rcParams['font.sans-serif'] = ['Liberation Sans']\n\n\n\nimport pandas as pd\n%matplotlib inline\n\n\nfrom tueplots import bundles\nplt.rcParams.update(bundles.beamer_moml())\n#plt.rcParams.update(bundles.icml2022())\n\n\n# Also add despine to the bundle using rcParams\nplt.rcParams['axes.spines.right'] = False\nplt.rcParams['axes.spines.top'] = False\n\n# Increase font size to match Beamer template\nplt.rcParams['font.size'] = 16\n# Make background transparent\nplt.rcParams['figure.facecolor'] = 'none'\n\n\ntry:\n    import hamiltorch\nexcept ImportError:\n    %pip install git+https://github.com/AdamCobb/hamiltorch\n\n\nhamiltorch.set_random_seed(123)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice\n\ndevice(type='cpu')\n\n\n\ngt_distribution = torch.distributions.Normal(0, 1)\n\n# Samples from the ground truth distribution\ndef sample_gt(n):\n    return gt_distribution.sample((n,))\n\nsamples = sample_gt(1000)\n\n\nx_lin = torch.linspace(-3, 3, 1000)\ny_lin = torch.exp(gt_distribution.log_prob(x_lin))\n\nplt.plot(x_lin, y_lin, label='Ground truth')\n\n\n\n\n\n# Logprob function to be passed to Hamiltorch sampler\ndef logprob(x):\n    return gt_distribution.log_prob(x).sum()\n\n# Initial state\nx0 = torch.tensor([0.0])\nnum_samples = 5000\nstep_size = 0.3\nnum_steps_per_sample = 5\nhamiltorch.set_random_seed(123)\n\n\nparams_hmc = hamiltorch.sample(log_prob_func=logprob, params_init=x0,  \n                               num_samples=num_samples, step_size=step_size, \n                               num_steps_per_sample=num_steps_per_sample)\n\nSampling (Sampler.HMC; Integrator.IMPLICIT)\nTime spent  | Time remain.| Progress             | Samples   | Samples/sec\n0d:00:00:16 | 0d:00:00:00 | #################### | 5000/5000 | 308.91       \nAcceptance Rate 0.99\n\n\n\nparams_hmc = torch.tensor(params_hmc)\n# Trace plot\nplt.plot(params_hmc, label='Trace')\nplt.xlabel('Iteration')\nplt.ylabel('Parameter value')\n\nText(0, 0.5, 'Parameter value')\n\n\n\n\n\n\n# Logprob function to be passed to Hamiltorch sampler\ndef logprob(x):\n    return gt_distribution.log_prob(x).sum()\n\n# Initial state\nx0 = torch.tensor([0.0])\nnum_samples = 5000\nstep_size = 0.3\nnum_steps_per_sample = 5\nhamiltorch.set_random_seed(123)\n\n\nparams_hmc = hamiltorch.sample(log_prob_func=logprob, params_init=x0,  \n                               num_samples=num_samples, step_size=step_size, \n                               num_steps_per_sample=num_steps_per_sample)\n\nSampling (Sampler.HMC; Integrator.IMPLICIT)\nTime spent  | Time remain.| Progress             | Samples   | Samples/sec\n0d:00:00:14 | 0d:00:00:00 | #################### | 5000/5000 | 338.09       \nAcceptance Rate 0.99\n\n\n\nparams_hmc = torch.tensor(params_hmc)\n# Trace plot\nplt.plot(params_hmc, label='Trace')\nplt.xlabel('Iteration')\nplt.ylabel('Parameter value')\n\n/tmp/ipykernel_18135/1433682485.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  params_hmc = torch.tensor(params_hmc)\n\n\nText(0, 0.5, 'Parameter value')\n\n\n\n\n\n\n# KDE plot\nimport seaborn as sns\nplt.figure()\nsns.kdeplot(params_hmc.detach().numpy(), label='Samples', shade=True, color='C1')\nplt.plot(x_lin, y_lin, label='Ground truth')\nplt.xlabel('Parameter value')\nplt.ylabel('Density')\nplt.legend()\n\n/tmp/ipykernel_18135/469715340.py:4: FutureWarning: \n\n`shade` is now deprecated in favor of `fill`; setting `fill=True`.\nThis will become an error in seaborn v0.14.0; please update your code.\n\n  sns.kdeplot(params_hmc.detach().numpy(), label='Samples', shade=True, color='C1')\n\n\n&lt;matplotlib.legend.Legend at 0x7f51dfedd4b0&gt;\n\n\n\n\n\n\n# Linear regression for 1 dimensional input using HMC\n\nx_lin = torch.linspace(-3, 3, 90)\ntheta_0_true = torch.tensor([2.0])\ntheta_1_true = torch.tensor([3.0])\nf = lambda x: theta_0_true + theta_1_true * x\neps = torch.randn_like(x_lin) *1.0\ny_lin = f(x_lin) + eps\n\nplt.scatter(x_lin, y_lin, label='Data', color='C0')\nplt.plot(x_lin, f(x_lin), label='Ground truth')\nplt.xlabel('x')\nplt.ylabel('y')\n\nText(0, 0.5, 'y')"
  },
  {
    "objectID": "posts/different_losses.html",
    "href": "posts/different_losses.html",
    "title": "",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.colors\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, mean_squared_error\nfrom tqdm import tqdm_notebook \n\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.datasets import make_blobs\n\nLoading Dataset\n\n'''\n# Load Dataset from Kaggle \n#pip install kaggle\nimport os\n\nimport kaggle\n# Set Kaggle API credentials\n\n\n# Download the dataset using Kaggle API\nkaggle.api.dataset_download_files('kaggle datasets download -d lava18/google-play-store-apps')\n\n# Unzip the downloaded dataset files if necessary\n\n# Load the dataset using pandas\ndf = pd.read_csv('path_to_dataset_file.csv')\n'''\n\n\"\\n# Load Dataset from Kaggle \\n#pip install kaggle\\nimport os\\n\\nimport kaggle\\n# Set Kaggle API credentials\\n\\n\\n# Download the dataset using Kaggle API\\nkaggle.api.dataset_download_files('kaggle datasets download -d lava18/google-play-store-apps')\\n\\n# Unzip the downloaded dataset files if necessary\\n\\n# Load the dataset using pandas\\ndf = pd.read_csv('path_to_dataset_file.csv')\\n\"\n\n\n\nclass SigmoidNeuron:\n    \n  def __init__(self):\n    self.W1 = None\n    self.b1 = None\n    self.W2 = None\n    self.b2 = None\n    \n  def perceptron(self, X, W, b):\n    return np.dot(X, W.T) + b\n  \n  def sigmoid(self, X):\n    return 1.0 / (1.0 + np.exp(-X))\n  \n  def grad_w_mse(self, X, Y, Y_pred):\n    m = X.shape[0]\n    return np.dot((Y_pred - Y) * Y_pred * (1 - Y_pred), X) / m\n  \n  def grad_b_mse(self, X, Y, Y_pred):\n    m = X.shape[0]\n    return np.sum((Y_pred - Y) * Y_pred * (1 - Y_pred)) / m\n  \n  def fit(self, X, Y, epochs=1, learning_rate=1, initialise=True, loss_fn=\"mse\", display_loss=False):\n    \n    # Initialise weights and biases\n    if initialise:\n      input_dim = X.shape[1]\n      hidden_dim = 2 * input_dim\n      output_dim = 1\n      self.W1 = np.random.randn(input_dim, hidden_dim)\n      self.b1 = np.zeros(hidden_dim)\n      self.W2 = np.random.randn(hidden_dim, output_dim)\n      self.b2 = np.zeros(output_dim)\n      \n    if display_loss:\n      loss = {}\n    \n    for epoch in range(epochs):\n      # Forward Propagation\n      hidden_output = self.sigmoid(self.perceptron(X, self.W1, self.b1))\n      Y_pred = self.sigmoid(self.perceptron(hidden_output, self.W2, self.b2))\n      \n      # Backpropagation\n      dw2 = self.grad_w_mse(hidden_output, Y, Y_pred)\n      db2 = self.grad_b_mse(hidden_output, Y, Y_pred)\n      \n      dw1 = np.dot((np.dot((Y_pred - Y) * Y_pred * (1 - Y_pred), self.W2.T) * hidden_output * (1 - hidden_output)).T, X)\n      db1 = np.sum((np.dot((Y_pred - Y) * Y_pred * (1 - Y_pred), self.W2.T) * hidden_output * (1 - hidden_output)).T, axis=1)\n      \n      # Update weights and biases\n      self.W2 -= learning_rate * dw2\n      self.b2 -= learning_rate * db2\n      self.W1 -= learning_rate * dw1\n      self.b1 -= learning_rate * db1\n      \n      if display_loss:\n        loss[epoch] = np.mean((Y_pred - Y) ** 2)\n    \n    if display_loss:\n      plt.plot(list(loss.values()))\n      plt.xlabel('Epochs')\n      plt.ylabel('Mean Squared Error')\n      plt.title('Loss vs Epochs')\n      plt.show()\n      \n  def predict(self, X):\n    hidden_output = self.sigmoid(self.perceptron(X, self.W1, self.b1))\n    Y_pred = self.sigmoid(self.perceptron(hidden_output, self.W2, self.b2))\n    return Y_pred"
  },
  {
    "objectID": "posts/log-sum-exp.html",
    "href": "posts/log-sum-exp.html",
    "title": "",
    "section": "",
    "text": "import numpy as np\n\nThe log1p function is a useful tool for calculating the logarithm of 1 + p, particularly when p is a small value. It helps avoid numerical instability issues that can arise when directly computing np.log(1 + p) when p is close to zero. By using log1p, you can achieve a more accurate and stable calculation of the logarithm.\n\nx = np.array([1, 2, 3, 4, 5])\np = 1e-10\nresult = np.log(1 + p)  # Direct computation, can be unstable for small p\nresult_log1p = np.log1p(p)  # More stable computation using log1p\nprint(result)\nprint(result_log1p)\n\n1.000000082690371e-10\n9.999999999500001e-11\n\n\nWhen dealing with small values like 1e-5, using the expression exp(p) - 1 can result in a loss of precision. In such cases, the function expm1(p) is a better alternative as it provides a more accurate result that preserves the precision of the small input value p.\n\nresult1 = np.exp(p) - 1\nresult2 = np.expm1(p)\n\nprint(\"Using exp(p) - 1:\")\nprint(result1)\n\nprint(\"Using expm1(p):\")\nprint(result2)\n\nUsing exp(p) - 1:\n1.000000082740371e-10\nUsing expm1(p):\n1.00000000005e-10\n\n\nUsing np.log1p to compute log(1 + p) provides a numerically stable and accurate result of 1e-10, even for small values of p.\n\nx = 0\ny = 10\n\nresult = np.multiply(x, np.log(y))\n\nprint(result)\n\n0.0\n\n\nTo avoid numerical instability when computing x log(1 + p) with small values of x and p, it is advisable to use np.log1p instead of directly calculating np.log(1 + p). This ensures better accuracy and stability by preserving the precision of the small input p.\n\nfrom scipy.special import xlog1py\nfrom scipy.special import xlogy\n\n\nx = 1\np = 1e-10\n\nresult = xlogy(x, 1 + p)\nresult1 = xlog1py(x, p)\n\nprint(result)\nprint(result1)\n\n1.000000082690371e-10\n9.999999999500001e-11"
  },
  {
    "objectID": "posts/spiking_nn.html",
    "href": "posts/spiking_nn.html",
    "title": "Spiking neural networks (SNNs)",
    "section": "",
    "text": "Spiking neural networks (SNNs) are artificial neural networks that closely resemble natural neural networks. It mimic natural neural networks, incorporating time and thresholds for neuron activation."
  }
]