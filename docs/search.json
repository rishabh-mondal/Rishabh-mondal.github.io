[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Rishabh Mondal",
    "section": "",
    "text": "Hi! I am Rishabh Mondal.As an enthusiastic learner, I am always eager to take up challenging tasks and push my limits to achieve excellence. My academic journey has give me a strong foundation in the concepts of computer science, and I have gained practical experience through various projects\n\n\nM.Tech in Information Technology\nIndian Institute of Engineering Science and Technology, Shibpur | Sept 2021 - June 2023\nB.Tech in Computer Science and Engineering\nThe Neotia University, Kolkata |Sept 2017 - June 2021\n\n\n\n\nAn LSTM-based Fall Detection System with ROC optimization technique: A step towards more accuracy\nBrain Tumor Detection using Convolution Neural Network.\nIndian currency detection through KNN and audio transfer for blind people.\n\n\n\n\nWinner of IBM ICE DAY (poster competition)|2019"
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Rishabh Mondal",
    "section": "",
    "text": "M.Tech in Information Technology\nIndian Institute of Engineering Science and Technology, Shibpur | Sept 2021 - June 2023\nB.Tech in Computer Science and Engineering\nThe Neotia University, Kolkata |Sept 2017 - June 2021"
  },
  {
    "objectID": "index.html#project",
    "href": "index.html#project",
    "title": "Rishabh Mondal",
    "section": "",
    "text": "An LSTM-based Fall Detection System with ROC optimization technique: A step towards more accuracy\nBrain Tumor Detection using Convolution Neural Network.\nIndian currency detection through KNN and audio transfer for blind people."
  },
  {
    "objectID": "index.html#awards",
    "href": "index.html#awards",
    "title": "Rishabh Mondal",
    "section": "",
    "text": "Winner of IBM ICE DAY (poster competition)|2019"
  },
  {
    "objectID": "taylor.html",
    "href": "taylor.html",
    "title": "Taylor Series",
    "section": "",
    "text": "\\[\\begin{equation}\nf(x) = \\sum_{n=0}^{\\infty}\\frac{f^{(n)}(a)}{n!}(x-a)^{n}\n\\end{equation}\\]\nLet \\(f(x)\\) be a function that is \\(n+1\\) times differentiable on an interval \\(I\\) containing \\(a\\) and let \\(P_n(x)\\) be the \\(n\\)th degree Taylor polynomial for \\(f(x)\\) about \\(a\\). Then, there exists a number \\(c\\) between \\(a\\) and \\(x\\) such that: \\[\\begin{equation}\nf(x)=P_n(x)+R_n(x),\n\\end{equation}\\] where the remainder \\(R_n(x)\\) is given by: \\[\\begin{equation}\nR_n(x)=\\frac{f^{(n+1)}(c)}{(n+1)!}(x-a)^{n+1}.\n\\end{equation}\\]\n\nDefine the function to be approximated\n\n\nCode\nimport torch\nimport math\nimport matplotlib.pyplot as plt\nimport numpy as np\n# Define the sine function to be approximated\ndef f(x):\n    return torch.sin(x)\n\nx = torch.linspace(-3.14, 3.14, 100)\ny = f(x)\nplt.plot(x, y)\nplt.xlabel('x')\nplt.ylabel('y')\nplt.title('Sine Function')\nplt.show()\n\n\n\n\n\n\n\nFirst order Taylor approximation for f(x) at x = 0\n\n\nCode\nx = torch.tensor([0.], requires_grad=True)\ny = f(x)\napprox = y + torch.autograd.grad(y, x, create_graph=True)[0] * x\nx_vals = torch.linspace(-np.pi, np.pi, 100)\ny_vals = f(x_vals)\napprox_vals = (approx.detach() + torch.autograd.grad(approx, x, create_graph=True)[0] * x_vals).detach()\nplt.plot(x_vals.numpy(), y_vals.numpy(), label='sin(x)')\nplt.plot(x_vals.numpy(), approx_vals.numpy(), label='approx')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\nFind the nth order Taylor approximation for f(x) at x = 0\n\n\nCode\ndef fact(n):\n    return math.factorial(n)\n\ndef nth_deriv(f, a, n):\n    if isinstance(a, (float, int)):\n        a = torch.tensor([a], dtype=torch.float, requires_grad=True)\n    else:\n        a = a.clone().detach().requires_grad_(True)\n    \n    y = f(a)\n    for i in range(n):\n        y = torch.autograd.grad(y, a, create_graph=True)[0]\n    return y\n\n\n\n# nth degree Taylor polynomial of f(x) around x=a\ndef taylor(f, x, n):\n    result = torch.zeros_like(x)\n    for i in range(n+1):\n        result += nth_deriv(f, 0, i) / torch.tensor(math.factorial(i), dtype=torch.float32) * (x**i)\n    return result\nx_vals = torch.linspace(-math.pi, math.pi, 200)\nplt.plot(x_vals.numpy(), f(x_vals).numpy(), label='f(x)', lw=5)\nplt.plot(x_vals.numpy(), taylor(f, x_vals, 1).detach().numpy(), label='Taylor approximation, n=1')\nplt.plot(x_vals.numpy(), taylor(f, x_vals, 3).detach().numpy(), label='Taylor approximation, n=3')\nplt.plot(x_vals.numpy(), taylor(f, x_vals, 5).detach().numpy(), label='Taylor approximation, n=5')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\nPlot of the function g(x) = x^2 and its Taylor approximations up to degree 1 and degree 2 centered at x=0.\n\n\nCode\nx_vals = torch.linspace(-4, 4, 100)\n\ndef g(x):\n    return x**2\n\ndef taylor(f, x, n):\n    x = x.unsqueeze(-1)\n    y = f(x)\n    for i in range(1, n+1):\n        y += (x - x[0])**i / torch.tensor([math.factorial(i)]).float() * f(x[0] + 0.0)\n    return y\n\n\nplt.plot(x_vals.numpy(), g(x_vals).numpy(), label='g(x)', lw=5)\nplt.plot(x_vals.numpy(), taylor(g, x_vals, 1).detach().numpy(), label='Taylor approximation, n=1')\nplt.plot(x_vals.numpy(), taylor(g, x_vals, 3).detach().numpy(), label='Taylor approximation, n=3')\nplt.plot(x_vals.numpy(), taylor(g, x_vals, 5).detach().numpy(), label='Taylor approximation, n=5')\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "workshop.html",
    "href": "workshop.html",
    "title": "Workshop",
    "section": "",
    "text": "Workshop on Cloud Computing organized by IIT Kharagpur,2019"
  },
  {
    "objectID": "Conference.html",
    "href": "Conference.html",
    "title": "Conference",
    "section": "",
    "text": "Workshop on Cloud Computing organized by IIT Kharagpur,2019"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blogs",
    "section": "",
    "text": "Spiking neural networks (SNNs)\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nProbailty Distribtion\n\n\n\n\n\n\n\n\n\n\n\n\nJun 23, 2024\n\n\nRishabh Mondal\n\n\n\n\n\n\n  \n\n\n\n\nTypes of Losses and optimisation\n\n\n\n\n\n\n\nMachine Learning\n\n\nOptimisation\n\n\n\n\n\n\n\n\n\n\n\nJul 3, 2023\n\n\nKhush Shah\n\n\n\n\n\n\n  \n\n\n\n\nIntroduction to Univariate sampling\n\n\n\n\n\n\n\n\n\n\n\n\nFeb 7, 2023\n\n\nRishabh Mondal\n\n\n\n\n\n\n  \n\n\n\n\nTaylor Series\n\n\n\n\n\n\n\nQuarto\n\n\nPython\n\n\n\n\ndesp\n\n\n\n\n\n\nOct 24, 2022\n\n\nRishab Mondal\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/index.html",
    "href": "posts/index.html",
    "title": "Taylor Series",
    "section": "",
    "text": "\\[\\begin{equation}\nf(x) = \\sum_{n=0}^{\\infty}\\frac{f^{(n)}(a)}{n!}(x-a)^{n}\n\\end{equation}\\]\nLet \\(f(x)\\) be a function that is \\(n+1\\) times differentiable on an interval \\(I\\) containing \\(a\\) and let \\(P_n(x)\\) be the \\(n\\)th degree Taylor polynomial for \\(f(x)\\) about \\(a\\). Then, there exists a number \\(c\\) between \\(a\\) and \\(x\\) such that: \\[\\begin{equation}\nf(x)=P_n(x)+R_n(x),\n\\end{equation}\\] where the remainder \\(R_n(x)\\) is given by: \\[\\begin{equation}\nR_n(x)=\\frac{f^{(n+1)}(c)}{(n+1)!}(x-a)^{n+1}.\n\\end{equation}\\]\n\nDefine the function to be approximated\n\n\nCode\nimport torch\nimport math\nimport matplotlib.pyplot as plt\nimport numpy as np\n# Define the sine function to be approximated\ndef f(x):\n    return torch.sin(x)\n\nx = torch.linspace(-3.14, 3.14, 100)\ny = f(x)\nplt.plot(x, y)\nplt.xlabel('x')\nplt.ylabel('y')\nplt.title('Sine Function')\nplt.show()\n\n\n\n\n\n\n\nFirst order Taylor approximation for f(x) at x = 0\n\n\nCode\nx = torch.tensor([0.], requires_grad=True)\ny = f(x)\napprox = y + torch.autograd.grad(y, x, create_graph=True)[0] * x\nx_vals = torch.linspace(-np.pi, np.pi, 100)\ny_vals = f(x_vals)\napprox_vals = (approx.detach() + torch.autograd.grad(approx, x, create_graph=True)[0] * x_vals).detach()\nplt.plot(x_vals.numpy(), y_vals.numpy(), label='sin(x)')\nplt.plot(x_vals.numpy(), approx_vals.numpy(), label='approx')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\nFind the nth order Taylor approximation for f(x) at x = 0\n\n\nCode\ndef fact(n):\n    return math.factorial(n)\n\ndef nth_deriv(f, a, n):\n    if isinstance(a, (float, int)):\n        a = torch.tensor([a], dtype=torch.float, requires_grad=True)\n    else:\n        a = a.clone().detach().requires_grad_(True)\n    \n    y = f(a)\n    for i in range(n):\n        y = torch.autograd.grad(y, a, create_graph=True)[0]\n    return y\n\n\n\n# nth degree Taylor polynomial of f(x) around x=a\ndef taylor(f, x, n):\n    result = torch.zeros_like(x)\n    for i in range(n+1):\n        result += nth_deriv(f, 0, i) / torch.tensor(math.factorial(i), dtype=torch.float32) * (x**i)\n    return result\nx_vals = torch.linspace(-math.pi, math.pi, 200)\nplt.plot(x_vals.numpy(), f(x_vals).numpy(), label='f(x)', lw=5)\nplt.plot(x_vals.numpy(), taylor(f, x_vals, 1).detach().numpy(), label='Taylor approximation, n=1')\nplt.plot(x_vals.numpy(), taylor(f, x_vals, 3).detach().numpy(), label='Taylor approximation, n=3')\nplt.plot(x_vals.numpy(), taylor(f, x_vals, 5).detach().numpy(), label='Taylor approximation, n=5')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\nPlot of the function g(x) = x^2 and its Taylor approximations up to degree 1 and degree 2 centered at x=0.\n\n\nCode\nx_vals = torch.linspace(-4, 4, 100)\n\ndef g(x):\n    return x**2\n\ndef taylor(f, x, n):\n    x = x.unsqueeze(-1)\n    y = f(x)\n    for i in range(1, n+1):\n        y += (x - x[0])**i / torch.tensor([math.factorial(i)]).float() * f(x[0] + 0.0)\n    return y\n\n\nplt.plot(x_vals.numpy(), g(x_vals).numpy(), label='g(x)', lw=5)\nplt.plot(x_vals.numpy(), taylor(g, x_vals, 1).detach().numpy(), label='Taylor approximation, n=1')\nplt.plot(x_vals.numpy(), taylor(g, x_vals, 3).detach().numpy(), label='Taylor approximation, n=3')\nplt.plot(x_vals.numpy(), taylor(g, x_vals, 5).detach().numpy(), label='Taylor approximation, n=5')\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Certification",
    "section": "",
    "text": "Deep Learning from GUVI Geek Network & IITM - 2021.\nSix weeks of Summer Training on ML from IIT Kanpur,2019.\nOnline Python Training from IIT Kanpur,2019."
  },
  {
    "objectID": "probablity_distribution.html",
    "href": "probablity_distribution.html",
    "title": "Probablity Distrubutions",
    "section": "",
    "text": "Bernoulli Distribution\nTypes of Distribution : Discrete Distribution\nIn Bernoulli Distribution the random variable takes the value \\(1\\) with probability \\(p\\) and the value \\(0\\) with probability \\(1-p\\), where \\(0 ≤ p ≤ 1\\).\nThe probability mass function (PMF): \\[\\begin{equation}\nP(X = x) = p^x \\cdot (1-p)^{1-x} \\tag{1}\n\\end{equation}\\]\nWhere \\((X)\\) is the random variable, \\((x)\\) can be either 0 or \\(1\\), and \\((p)\\) is the probability of success.\n\n\nCode\np=0.6 #success=0.6 failure=0.4\nimport numpy as np\nsample = np.random.choice([0, 1], p=[1 - p, p])\nprob = (p ** sample) * ((1 - p) ** (1 - sample))\nprint(\"Sample:\", sample)\nprint(\"Probability:\", prob)\n\n#Using PyTorch\nimport torch\nfrom torch.distributions import Bernoulli\ndist=Bernoulli(torch.tensor([p]))\nsample=dist.sample()\nprint(\"Sample:\", sample)\nprint(\"Probability:\", dist)\n\n#Set of Probablty of success\nprobs = torch.tensor([0.7, 0.4, 0.9])\nbernoulli_dist = Bernoulli(probs=probs,logits=None)\nsamples = bernoulli_dist.sample()\nprint(\"probablity distributions:\", bernoulli_dist)\nprint(\"Samples:\", samples)\n\n# Log-odds of success\nlogits = torch.tensor([0.847])\ndist = Bernoulli(probs=None,logits=logits)\nsample = dist.sample()\nprint(\"log odd prob :\", dist)\nprint(\"Sample:\", sample.item())\n\n\nSample: 0\nProbability: 0.4\nSample: tensor([0.])\nProbability: Bernoulli(probs: tensor([0.6000]))\nprobablity distributions: Bernoulli(probs: torch.Size([3]))\nSamples: tensor([0., 0., 1.])\nlog odd prob : Bernoulli(probs: tensor([0.6999]), logits: tensor([0.8470]))\nSample: 0.0\n\n\nLog probability of Bernoulli distribution\nTo obtain the log probability, we take the natural logarithm of the PMF: \\[\\begin{equation}\n\\log P(X=x) = \\log(p^x \\cdot (1-p)^{1-x}) \\tag{2}\n\\end{equation}\\]\n\\[\\begin{equation}\n\\log P(X=x) = x \\cdot \\log(p) + (1-x) \\cdot \\log(1-p) \\tag{3}\n\\end{equation}\\]\n\n\nCode\nimport math\nsample=1\nprob=0.6\nlog_probability = sample * math.log(p) + (1 - sample) * math.log(1 - p)\nprint(\"sample:\", sample)\nprint(\"Log Probability:\", log_probability)\n\n#using PyTorch\nsample = torch.tensor([1])\np = torch.tensor([0.6])\ndist = Bernoulli(probs=p,logits=None)\nsample=dist.sample()\nlog_prob=dist.log_prob(sample)\nprint(\"Sample:\", sample)\nprint(\"Log Probability:\", log_prob)\n\n\nsample: 1\nLog Probability: -0.5108256237659907\nSample: tensor([0.])\nLog Probability: tensor([-0.9163])\n\n\nMaximum Likelihood Estimations(MLE) for Bernoulli Distribution\nThe MLE is a method used to estimate the parameters of a probability distribution based on observed data.\nDerivation of MLE for Bernoulli Distribution\nWe have a dataset with n binary samples:\\(x1\\) , \\(x2\\) , ..,\\(xn\\), where each \\(xi\\) is 0 or 1.\nThe likelihood function for the Bernoulli distribution is given by: \\[\\begin{equation}\nL(p) = \\prod_{i=1}^{n} p^{x_i} \\cdot (1-p)^{1-x_i}\n\\end{equation}\\]\nTaking the log-likelihood function: \\[\\begin{equation}\n\\log L(p) = \\sum_{i=1}^{n} x_i \\log p + (1-x_i) \\log (1-p)\n\\end{equation}\\]\nDifferentiating the log-likelihood function and setting it equal to zero: \\[\\begin{equation}\n\\frac{{\\partial}}{{\\partial p}} \\log L(p) = \\sum_{i=1}^{n} \\left(\\frac{{x_i}}{{p}} - \\frac{{1-x_i}}{{1-p}}\\right) = 0\n\\end{equation}\\]\nSimplifying the equation: \\[\\begin{equation}\n\\frac{{\\sum_{i=1}^{n} x_i - np}}{{p(1-p)}} = 0\n\\end{equation}\\]\nSolving for \\(p\\): \\[\\begin{equation}\nnp = \\sum_{i=1}^{n} x_i\n\\end{equation}\\]\n\n\nCode\nsize = 100\ndataset = dist.sample(torch.Size([size]))\nnum_suc=dataset.float().sum()\np_estimate=num_suc.float()/dataset.size(0)\nprint(\"MLE Estimate:\", p_estimate.item())\n\n\nMLE Estimate: 0.550000011920929\n\n\nLoss v/s iteration curve\n\n\nCode\nfrom torch.optim import Adam\nimport matplotlib.pyplot as plt\ndataset_sizes = [10, 50, 100, 200, 500,1000,10000]\ndef negative_log_likelihood(p, dataset):\n    return -(dataset * torch.log(p) + (1 - dataset) * torch.log(1 - p)).mean()\n\nfor size in dataset_sizes:\n   \n    dataset = torch.randint(low=0, high=2, size=(size,))\n    p = torch.tensor(0.5, requires_grad=True)\n    optimizer = Adam([p], lr=0.1)\n    loss_values = []\n    iteration_values = []\n    for i in range(100):\n        optimizer.zero_grad()\n        loss = negative_log_likelihood(p, dataset)\n        loss.backward()\n        optimizer.step()\n        loss_values.append(loss.item())\n        iteration_values.append(i+1)\n    plt.plot(iteration_values, loss_values, label=f'Dataset Size: {size}')\nplt.xlabel('Iteration')\nplt.ylabel('Loss')\nplt.title('Loss vs. Iteration for Varying Dataset Sizes')\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "posts/probablity_distribution.html",
    "href": "posts/probablity_distribution.html",
    "title": "Probablity Distrubutions",
    "section": "",
    "text": "Bernoulli Distribution\nTypes of Distribution : Discrete Distribution\nIn Bernoulli Distribution the random variable takes the value \\(1\\) with probability \\(p\\) and the value \\(0\\) with probability \\(1-p\\), where \\(0 ≤ p ≤ 1\\).\nThe probability mass function (PMF): \\[\\begin{equation}\nP(X = x) = p^x \\cdot (1-p)^{1-x} \\tag{1}\n\\end{equation}\\]\nWhere \\((X)\\) is the random variable, \\((x)\\) can be either 0 or \\(1\\), and \\((p)\\) is the probability of success.\n\n\nCode\np=0.6 #success=0.6 failure=0.4\nimport numpy as np\nsample = np.random.choice([0, 1], p=[1 - p, p])\nprob = (p ** sample) * ((1 - p) ** (1 - sample))\nprint(\"Sample:\", sample)\nprint(\"Probability:\", prob)\n\n#Using PyTorch\nimport torch\nfrom torch.distributions import Bernoulli\ndist=Bernoulli(torch.tensor([p]))\nsample=dist.sample()\nprint(\"Sample:\", sample)\nprint(\"Probability:\", dist)\n\n#Set of Probablty of success\nprobs = torch.tensor([0.7, 0.4, 0.9])\nbernoulli_dist = Bernoulli(probs=probs,logits=None)\nsamples = bernoulli_dist.sample()\nprint(\"probablity distributions:\", bernoulli_dist)\nprint(\"Samples:\", samples)\n\n# Log-odds of success\nlogits = torch.tensor([0.847])\ndist = Bernoulli(probs=None,logits=logits)\nsample = dist.sample()\nprint(\"log odd prob :\", dist)\nprint(\"Sample:\", sample.item())\n\n\nSample: 0\nProbability: 0.4\nSample: tensor([1.])\nProbability: Bernoulli(probs: tensor([0.6000]))\nprobablity distributions: Bernoulli(probs: torch.Size([3]))\nSamples: tensor([0., 0., 1.])\nlog odd prob : Bernoulli(probs: tensor([0.6999]), logits: tensor([0.8470]))\nSample: 0.0\n\n\nLog probability of Bernoulli distribution\nTo obtain the log probability, we take the natural logarithm of the PMF: \\[\\begin{equation}\n\\log P(X=x) = \\log(p^x \\cdot (1-p)^{1-x}) \\tag{2}\n\\end{equation}\\]\n\\[\\begin{equation}\n\\log P(X=x) = x \\cdot \\log(p) + (1-x) \\cdot \\log(1-p) \\tag{3}\n\\end{equation}\\]\n\n\nCode\nimport math\nsample=1\nprob=0.6\nlog_probability = sample * math.log(p) + (1 - sample) * math.log(1 - p)\nprint(\"sample:\", sample)\nprint(\"Log Probability:\", log_probability)\n\n#using PyTorch\nsample = torch.tensor([1])\np = torch.tensor([0.6])\ndist = Bernoulli(probs=p,logits=None)\nsample=dist.sample()\nlog_prob=dist.log_prob(sample)\nprint(\"Sample:\", sample)\nprint(\"Log Probability:\", log_prob)\n\n\nsample: 1\nLog Probability: -0.5108256237659907\nSample: tensor([0.])\nLog Probability: tensor([-0.9163])\n\n\nMaximum Likelihood Estimations(MLE) for Bernoulli Distribution\nThe MLE is a method used to estimate the parameters of a probability distribution based on observed data.\nDerivation of MLE for Bernoulli Distribution\nWe have a dataset with n binary samples:\\(x1\\) , \\(x2\\) , ..,\\(xn\\), where each \\(xi\\) is 0 or 1.\nThe likelihood function for the Bernoulli distribution is given by: \\[\\begin{equation}\nL(p) = \\prod_{i=1}^{n} p^{x_i} \\cdot (1-p)^{1-x_i}\n\\end{equation}\\]\nTaking the log-likelihood function: \\[\\begin{equation}\n\\log L(p) = \\sum_{i=1}^{n} x_i \\log p + (1-x_i) \\log (1-p)\n\\end{equation}\\]\nDifferentiating the log-likelihood function and setting it equal to zero: \\[\\begin{equation}\n\\frac{{\\partial}}{{\\partial p}} \\log L(p) = \\sum_{i=1}^{n} \\left(\\frac{{x_i}}{{p}} - \\frac{{1-x_i}}{{1-p}}\\right) = 0\n\\end{equation}\\]\nSimplifying the equation: \\[\\begin{equation}\n\\frac{{\\sum_{i=1}^{n} x_i - np}}{{p(1-p)}} = 0\n\\end{equation}\\]\nSolving for \\(p\\): \\[\\begin{equation}\nnp = \\sum_{i=1}^{n} x_i\n\\end{equation}\\]\n\n\nCode\nsize = 100\ndataset = dist.sample(torch.Size([size]))\nnum_suc=dataset.float().sum()\np_estimate=num_suc.float()/dataset.size(0)\nprint(\"MLE Estimate:\", p_estimate.item())\n\n\nMLE Estimate: 0.5899999737739563\n\n\nLoss v/s iteration curve\n\n\nCode\nfrom torch.optim import Adam\nimport matplotlib.pyplot as plt\ndataset_sizes = [10, 50, 100, 200, 500,1000,10000]\ndef negative_log_likelihood(p, dataset):\n    return -(dataset * torch.log(p) + (1 - dataset) * torch.log(1 - p)).mean()\n\nfor size in dataset_sizes:\n   \n    dataset = torch.randint(low=0, high=2, size=(size,))\n    p = torch.tensor(0.5, requires_grad=True)\n    optimizer = Adam([p], lr=0.1)\n    loss_values = []\n    iteration_values = []\n    for i in range(100):\n        optimizer.zero_grad()\n        loss = negative_log_likelihood(p, dataset)\n        loss.backward()\n        optimizer.step()\n        loss_values.append(loss.item())\n        iteration_values.append(i+1)\n    plt.plot(iteration_values, loss_values, label=f'Dataset Size: {size}')\nplt.xlabel('Iteration')\nplt.ylabel('Loss')\nplt.title('Loss vs. Iteration for Varying Dataset Sizes')\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "posts/Probablity_distibution.html",
    "href": "posts/Probablity_distibution.html",
    "title": "Probailty Distribtion",
    "section": "",
    "text": "Bernoulli distribution\n\n\nBernoulli distribution is a discret univariate probability distribution. A Bernoulli trial or experiment results in binary outcomes: success or failure \\((0 or 1)\\). The trial’s success is denoted as $ p (x=1)$, and failure is expressed as \\(1-p ( x=0)\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\[\\begin{equation}\nP(X = x) = p^x \\cdot (1-p)^{1-x} \\tag{1}\n\\end{equation}\\]\nwhere \\((X)\\) is the random variable, \\((x)\\) can be either 0 or 1, and \\((p)\\) is the probability of success.\nSome imports\n\nimport numpy as np\nimport torch\nfrom torch.distributions import Bernoulli\nimport math\nfrom torch.optim import Adam\nimport matplotlib.pyplot as plt\n\nImplementation of PMF\n\np=0.6 #success=0.6 failure=0.4\nimport numpy as np\nsample = np.random.choice([0, 1], p=[1 - p, p])\nprob = (p ** sample) * ((1 - p) ** (1 - sample))\nprint(\"Sample:\", sample)\nprint(\"Probability:\", prob)\n\n#Using PyTorch\nimport torch\nfrom torch.distributions import Bernoulli\ndist=Bernoulli(torch.tensor([p]))\nsample=dist.sample()\nprint(\"Sample:\", sample)\nprint(\"Probability:\", dist)\n\n#Set of Probablty of success\nprobs = torch.tensor([0.7, 0.4, 0.9])\nbernoulli_dist = Bernoulli(probs=probs,logits=None)\nsamples = bernoulli_dist.sample()\nprint(\"probablity distributions:\", bernoulli_dist)\nprint(\"Samples:\", samples)\n\n# Log-odds of success\nlogits = torch.tensor([0.847])\ndist = Bernoulli(probs=None,logits=logits)\nsample = dist.sample()\nprint(\"log odd prob :\", dist)\nprint(\"Sample:\", sample.item())\n\nSample: 0\nProbability: 0.4\nSample: tensor([1.])\nProbability: Bernoulli(probs: tensor([0.6000]))\nprobablity distributions: Bernoulli(probs: torch.Size([3]))\nSamples: tensor([1., 0., 1.])\nlog odd prob : Bernoulli(probs: tensor([0.6999]), logits: tensor([0.8470]))\nSample: 1.0\n\n\nLog probability of Bernoulli distribution\nTo obtain the log probability, we take the natural logarithm of the PMF:\n\\[\\begin{equation}\n\\log P(X=x) = \\log(p^x \\cdot (1-p)^{1-x})\n\\end{equation}\\]\n\\[\\begin{equation}\n\\log P(X=x) = x \\cdot \\log(p) + (1-x) \\cdot \\log(1-p)\n\\end{equation}\\]\n\nsample=1\nprob=0.6\nlog_probability = sample * math.log(p) + (1 - sample) * math.log(1 - p)\nprint(\"sample:\", sample)\nprint(\"Log Probability:\", log_probability)\n\n#using PyTorch\nsample = torch.tensor([1])\np = torch.tensor([0.6])\ndist = Bernoulli(probs=p,logits=None)\nsample=dist.sample()\nlog_prob=dist.log_prob(sample)\nprint(\"Sample:\", sample)\nprint(\"Log Probability:\", log_prob)\n\nsample: 1\nLog Probability: -0.5108256237659907\nSample: tensor([1.])\nLog Probability: tensor([-0.5108])\n\n\nMaximum Likelihood Estimations(MLE) for Bernoulli Distribution\nTo derive the Maximum Likelihood Estimation (MLE) for the Bernoulli distribution, let’s assume we have a random sample of independent and identically distributed (i.i.d.) observations from a Bernoulli distribution with parameter p. Each observation can take a value of either 0 or 1.\nThe likelihood function for the Bernoulli distribution is given by:\n\\[ L(p) = \\prod_{i=1}^{n} p^{x_i} \\cdot (1-p)^{1-x_i} \\]\nwhere (x_i) is the i-th observation in the sample and n is the total number of observations.\nTo find the MLE for p, we want to find the value of p that maximizes the likelihood function L(p). It is often easier to work with the log-likelihood function, which is the natural logarithm of the likelihood function:\n\\[\n\\log L(p) = \\sum_{i=1}^{n} x_i \\cdot \\log(p) + (1-x_i) \\cdot \\log(1-p)\n\\]\nTo find the MLE, we differentiate the log-likelihood function with respect to p and set it equal to zero:\n\\[\n\\frac{d}{dp}(\\log L(p)) = \\frac{1}{p}\\sum_{i=1}^{n} x_i - \\frac{1}{1-p}\\sum_{i=1}^{n} (1-x_i) = 0\n\\]\nSimplifying the equation:\n\\[\n\\frac{1}{p}\\sum_{i=1}^{n} x_i - \\frac{n}{1-p} + \\frac{1}{1-p}\\sum_{i=1}^{n} x_i = 0\n\\]\nMultiplying through by p(1-p):\n\\[\n(1-p)\\sum_{i=1}^{n} x_i - np + p\\sum_{i=1}^{n} x_i = 0\n\\]\nRearranging the terms:\n\\[\n\\sum_{i=1}^{n} x_i - np = 0\n\\] Finally, solving for p:\n\\[\np = \\frac{1}{n}\\sum_{i=1}^{n} x_i\n\\]\nTherefore, the MLE for the parameter p in the Bernoulli distribution is the sample mean of the observed values.\nIt is important to note that this MLE is consistent, unbiased, and efficient for estimating the parameter p in the Bernoulli distribution.\n\nsize = 100\ndataset = dist.sample(torch.Size([size]))\nnum_suc=dataset.float().sum()\np_estimate=num_suc.float()/dataset.size(0)\nprint(\"MLE Estimate:\", p_estimate.item())\n\nMLE Estimate: 0.6299999952316284\n\n\nPerforming Maximum Likelihood Estimation (MLE) for the Bernoulli distribution with varying dataset sizes. It computes the negative log-likelihood loss for different dataset sizes and optimizes the parameter ‘p’ to minimize the loss using the Adam optimizer.\nThe resulting loss values are then plotted against the iterations to visualize the convergence of the MLE estimation.\n\ndataset_sizes = [10, 50, 100, 200, 500,1000,10000]\ndef negative_log_likelihood(p, dataset):\n    return -(dataset * torch.log(p) + (1 - dataset) * torch.log(1 - p)).mean()\n\nfor size in dataset_sizes:\n   \n    dataset = torch.randint(low=0, high=2, size=(size,))\n    p = torch.tensor(0.5, requires_grad=True)\n    optimizer = Adam([p], lr=0.1)\n    loss_values = []\n    iteration_values = []\n    for i in range(100):\n        optimizer.zero_grad()\n        loss = negative_log_likelihood(p, dataset)\n        loss.backward()\n        optimizer.step()\n        loss_values.append(loss.item())\n        iteration_values.append(i+1)\n    plt.plot(iteration_values, loss_values, label=f'Dataset Size: {size}')\nplt.xlabel('Iteration')\nplt.ylabel('Loss')\nplt.title('Loss vs. Iteration for Varying Dataset Sizes')\nplt.legend()\nplt.show()\n\n\n\n\nThe plot shows the relationship between the loss and the number of iterations for each dataset size.\nBy examining the plot, we can observe the following:\n\nAs the dataset size increases, the convergence to the optimal parameter value tends to be faster. This is because larger datasets provide more information, allowing for more accurate estimation.\nFor smaller dataset sizes (e.g., 10, 50, 100), the loss tends to fluctuate more initially. However, as the number of iterations increases, the loss converges to a stable value.\nFor larger dataset sizes (e.g., 1000, 10000), the loss tends to converge quickly and stabilize earlier compared to smaller dataset sizes."
  },
  {
    "objectID": "posts/Probablity_distibution.html#introduction",
    "href": "posts/Probablity_distibution.html#introduction",
    "title": "Bernoulli distribution",
    "section": "",
    "text": "Bernoulli distribution is a discret univariate probability distribution. A Bernoulli trial or experiment results in binary outcomes: success or failure \\((0 or 1)\\). The trial’s success is denoted as $ p (x=1)$, and failure is expressed as \\(1-p ( x=0)\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n$ \\[\\begin{equation}\nP(X = x) = p^x \\cdot (1-p)^{1-x} \\tag{1}\n\\end{equation}\\] $ where \\((X)\\) is the random variable, \\((x)\\) can be either 0 or 1, and \\((p)\\) is the probability of success.\nSome imports\n\nimport numpy as np\nimport torch\nfrom torch.distributions import Bernoulli\nimport math\nfrom torch.optim import Adam\nimport matplotlib.pyplot as plt\n\nImplementation of PMF\n\np=0.6 #success=0.6 failure=0.4\nimport numpy as np\nsample = np.random.choice([0, 1], p=[1 - p, p])\nprob = (p ** sample) * ((1 - p) ** (1 - sample))\nprint(\"Sample:\", sample)\nprint(\"Probability:\", prob)\n\n#Using PyTorch\nimport torch\nfrom torch.distributions import Bernoulli\ndist=Bernoulli(torch.tensor([p]))\nsample=dist.sample()\nprint(\"Sample:\", sample)\nprint(\"Probability:\", dist)\n\n#Set of Probablty of success\nprobs = torch.tensor([0.7, 0.4, 0.9])\nbernoulli_dist = Bernoulli(probs=probs,logits=None)\nsamples = bernoulli_dist.sample()\nprint(\"probablity distributions:\", bernoulli_dist)\nprint(\"Samples:\", samples)\n\n# Log-odds of success\nlogits = torch.tensor([0.847])\ndist = Bernoulli(probs=None,logits=logits)\nsample = dist.sample()\nprint(\"log odd prob :\", dist)\nprint(\"Sample:\", sample.item())\n\nSample: 1\nProbability: 0.6\nSample: tensor([0.])\nProbability: Bernoulli(probs: tensor([0.6000]))\nprobablity distributions: Bernoulli(probs: torch.Size([3]))\nSamples: tensor([0., 1., 0.])\nlog odd prob : Bernoulli(probs: tensor([0.6999]), logits: tensor([0.8470]))\nSample: 1.0\n\n\nLog probability of Bernoulli distribution\nTo obtain the log probability, we take the natural logarithm of the PMF: $ \\[\\begin{equation}\n\\log P(X=x) = \\log(p^x \\cdot (1-p)^{1-x})\n\\end{equation}\\] $ $ \\[\\begin{equation}\n\\log P(X=x) = x \\cdot \\log(p) + (1-x) \\cdot \\log(1-p)\n\\end{equation}\\] $\n\nsample=1\nprob=0.6\nlog_probability = sample * math.log(p) + (1 - sample) * math.log(1 - p)\nprint(\"sample:\", sample)\nprint(\"Log Probability:\", log_probability)\n\n#using PyTorch\nsample = torch.tensor([1])\np = torch.tensor([0.6])\ndist = Bernoulli(probs=p,logits=None)\nsample=dist.sample()\nlog_prob=dist.log_prob(sample)\nprint(\"Sample:\", sample)\nprint(\"Log Probability:\", log_prob)\n\nsample: 1\nLog Probability: -0.5108256237659907\nSample: tensor([1.])\nLog Probability: tensor([-0.5108])\n\n\nMaximum Likelihood Estimations(MLE) for Bernoulli Distribution\nTo derive the Maximum Likelihood Estimation (MLE) for the Bernoulli distribution, let’s assume we have a random sample of independent and identically distributed (i.i.d.) observations from a Bernoulli distribution with parameter p. Each observation can take a value of either 0 or 1.\nThe likelihood function for the Bernoulli distribution is given by:\n$ L(p) = _{i=1}^{n} p^{x_i} (1-p)^{1-x_i} $\nwhere (x_i) is the i-th observation in the sample and n is the total number of observations.\nTo find the MLE for p, we want to find the value of p that maximizes the likelihood function L(p). It is often easier to work with the log-likelihood function, which is the natural logarithm of the likelihood function:\n$ L(p) = _{i=1}^{n} x_i (p) + (1-x_i) (1-p) $\nTo find the MLE, we differentiate the log-likelihood function with respect to p and set it equal to zero:\n$ (L(p)) = {i=1}^{n} x_i - {i=1}^{n} (1-x_i) = 0 $\nSimplifying the equation:\n$ {i=1}^{n} x_i - + {i=1}^{n} x_i = 0 $\nMultiplying through by p(1-p):\n$ (1-p){i=1}^{n} x_i - np + p{i=1}^{n} x_i = 0 $\nRearranging the terms:\n$ _{i=1}^{n} x_i - np = 0 $ Finally, solving for p:\n$ p = _{i=1}^{n} x_i $\nTherefore, the MLE for the parameter p in the Bernoulli distribution is the sample mean of the observed values.\nIt is important to note that this MLE is consistent, unbiased, and efficient for estimating the parameter p in the Bernoulli distribution.\n\nsize = 100\ndataset = dist.sample(torch.Size([size]))\nnum_suc=dataset.float().sum()\np_estimate=num_suc.float()/dataset.size(0)\nprint(\"MLE Estimate:\", p_estimate.item())\n\nMLE Estimate: 0.6100000143051147\n\n\nPerforming Maximum Likelihood Estimation (MLE) for the Bernoulli distribution with varying dataset sizes. It computes the negative log-likelihood loss for different dataset sizes and optimizes the parameter ‘p’ to minimize the loss using the Adam optimizer.\nThe resulting loss values are then plotted against the iterations to visualize the convergence of the MLE estimation.\n\ndataset_sizes = [10, 50, 100, 200, 500,1000,10000]\ndef negative_log_likelihood(p, dataset):\n    return -(dataset * torch.log(p) + (1 - dataset) * torch.log(1 - p)).mean()\n\nfor size in dataset_sizes:\n   \n    dataset = torch.randint(low=0, high=2, size=(size,))\n    p = torch.tensor(0.5, requires_grad=True)\n    optimizer = Adam([p], lr=0.1)\n    loss_values = []\n    iteration_values = []\n    for i in range(100):\n        optimizer.zero_grad()\n        loss = negative_log_likelihood(p, dataset)\n        loss.backward()\n        optimizer.step()\n        loss_values.append(loss.item())\n        iteration_values.append(i+1)\n    plt.plot(iteration_values, loss_values, label=f'Dataset Size: {size}')\nplt.xlabel('Iteration')\nplt.ylabel('Loss')\nplt.title('Loss vs. Iteration for Varying Dataset Sizes')\nplt.legend()\nplt.show()\n\n\n\n\nThe plot shows the relationship between the loss and the number of iterations for each dataset size.\nBy examining the plot, we can observe the following:\n\nAs the dataset size increases, the convergence to the optimal parameter value tends to be faster. This is because larger datasets provide more information, allowing for more accurate estimation.\nFor smaller dataset sizes (e.g., 10, 50, 100), the loss tends to fluctuate more initially. However, as the number of iterations increases, the loss converges to a stable value.\nFor larger dataset sizes (e.g., 1000, 10000), the loss tends to converge quickly and stabilize earlier compared to smaller dataset sizes."
  },
  {
    "objectID": "posts/Probablity_distibution.html#probablity-distribution",
    "href": "posts/Probablity_distibution.html#probablity-distribution",
    "title": "Probailty Distribtion",
    "section": "",
    "text": "Bernoulli distribution\n\n\nBernoulli distribution is a discret univariate probability distribution. A Bernoulli trial or experiment results in binary outcomes: success or failure \\((0 or 1)\\). The trial’s success is denoted as $ p (x=1)$, and failure is expressed as \\(1-p ( x=0)\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\[\\begin{equation}\nP(X = x) = p^x \\cdot (1-p)^{1-x} \\tag{1}\n\\end{equation}\\]\nwhere \\((X)\\) is the random variable, \\((x)\\) can be either 0 or 1, and \\((p)\\) is the probability of success.\nSome imports\n\nimport numpy as np\nimport torch\nfrom torch.distributions import Bernoulli\nimport math\nfrom torch.optim import Adam\nimport matplotlib.pyplot as plt\n\nImplementation of PMF\n\np=0.6 #success=0.6 failure=0.4\nimport numpy as np\nsample = np.random.choice([0, 1], p=[1 - p, p])\nprob = (p ** sample) * ((1 - p) ** (1 - sample))\nprint(\"Sample:\", sample)\nprint(\"Probability:\", prob)\n\n#Using PyTorch\nimport torch\nfrom torch.distributions import Bernoulli\ndist=Bernoulli(torch.tensor([p]))\nsample=dist.sample()\nprint(\"Sample:\", sample)\nprint(\"Probability:\", dist)\n\n#Set of Probablty of success\nprobs = torch.tensor([0.7, 0.4, 0.9])\nbernoulli_dist = Bernoulli(probs=probs,logits=None)\nsamples = bernoulli_dist.sample()\nprint(\"probablity distributions:\", bernoulli_dist)\nprint(\"Samples:\", samples)\n\n# Log-odds of success\nlogits = torch.tensor([0.847])\ndist = Bernoulli(probs=None,logits=logits)\nsample = dist.sample()\nprint(\"log odd prob :\", dist)\nprint(\"Sample:\", sample.item())\n\nSample: 0\nProbability: 0.4\nSample: tensor([1.])\nProbability: Bernoulli(probs: tensor([0.6000]))\nprobablity distributions: Bernoulli(probs: torch.Size([3]))\nSamples: tensor([1., 0., 1.])\nlog odd prob : Bernoulli(probs: tensor([0.6999]), logits: tensor([0.8470]))\nSample: 1.0\n\n\nLog probability of Bernoulli distribution\nTo obtain the log probability, we take the natural logarithm of the PMF:\n\\[\\begin{equation}\n\\log P(X=x) = \\log(p^x \\cdot (1-p)^{1-x})\n\\end{equation}\\]\n\\[\\begin{equation}\n\\log P(X=x) = x \\cdot \\log(p) + (1-x) \\cdot \\log(1-p)\n\\end{equation}\\]\n\nsample=1\nprob=0.6\nlog_probability = sample * math.log(p) + (1 - sample) * math.log(1 - p)\nprint(\"sample:\", sample)\nprint(\"Log Probability:\", log_probability)\n\n#using PyTorch\nsample = torch.tensor([1])\np = torch.tensor([0.6])\ndist = Bernoulli(probs=p,logits=None)\nsample=dist.sample()\nlog_prob=dist.log_prob(sample)\nprint(\"Sample:\", sample)\nprint(\"Log Probability:\", log_prob)\n\nsample: 1\nLog Probability: -0.5108256237659907\nSample: tensor([1.])\nLog Probability: tensor([-0.5108])\n\n\nMaximum Likelihood Estimations(MLE) for Bernoulli Distribution\nTo derive the Maximum Likelihood Estimation (MLE) for the Bernoulli distribution, let’s assume we have a random sample of independent and identically distributed (i.i.d.) observations from a Bernoulli distribution with parameter p. Each observation can take a value of either 0 or 1.\nThe likelihood function for the Bernoulli distribution is given by:\n\\[ L(p) = \\prod_{i=1}^{n} p^{x_i} \\cdot (1-p)^{1-x_i} \\]\nwhere (x_i) is the i-th observation in the sample and n is the total number of observations.\nTo find the MLE for p, we want to find the value of p that maximizes the likelihood function L(p). It is often easier to work with the log-likelihood function, which is the natural logarithm of the likelihood function:\n\\[\n\\log L(p) = \\sum_{i=1}^{n} x_i \\cdot \\log(p) + (1-x_i) \\cdot \\log(1-p)\n\\]\nTo find the MLE, we differentiate the log-likelihood function with respect to p and set it equal to zero:\n\\[\n\\frac{d}{dp}(\\log L(p)) = \\frac{1}{p}\\sum_{i=1}^{n} x_i - \\frac{1}{1-p}\\sum_{i=1}^{n} (1-x_i) = 0\n\\]\nSimplifying the equation:\n\\[\n\\frac{1}{p}\\sum_{i=1}^{n} x_i - \\frac{n}{1-p} + \\frac{1}{1-p}\\sum_{i=1}^{n} x_i = 0\n\\]\nMultiplying through by p(1-p):\n\\[\n(1-p)\\sum_{i=1}^{n} x_i - np + p\\sum_{i=1}^{n} x_i = 0\n\\]\nRearranging the terms:\n\\[\n\\sum_{i=1}^{n} x_i - np = 0\n\\] Finally, solving for p:\n\\[\np = \\frac{1}{n}\\sum_{i=1}^{n} x_i\n\\]\nTherefore, the MLE for the parameter p in the Bernoulli distribution is the sample mean of the observed values.\nIt is important to note that this MLE is consistent, unbiased, and efficient for estimating the parameter p in the Bernoulli distribution.\n\nsize = 100\ndataset = dist.sample(torch.Size([size]))\nnum_suc=dataset.float().sum()\np_estimate=num_suc.float()/dataset.size(0)\nprint(\"MLE Estimate:\", p_estimate.item())\n\nMLE Estimate: 0.6299999952316284\n\n\nPerforming Maximum Likelihood Estimation (MLE) for the Bernoulli distribution with varying dataset sizes. It computes the negative log-likelihood loss for different dataset sizes and optimizes the parameter ‘p’ to minimize the loss using the Adam optimizer.\nThe resulting loss values are then plotted against the iterations to visualize the convergence of the MLE estimation.\n\ndataset_sizes = [10, 50, 100, 200, 500,1000,10000]\ndef negative_log_likelihood(p, dataset):\n    return -(dataset * torch.log(p) + (1 - dataset) * torch.log(1 - p)).mean()\n\nfor size in dataset_sizes:\n   \n    dataset = torch.randint(low=0, high=2, size=(size,))\n    p = torch.tensor(0.5, requires_grad=True)\n    optimizer = Adam([p], lr=0.1)\n    loss_values = []\n    iteration_values = []\n    for i in range(100):\n        optimizer.zero_grad()\n        loss = negative_log_likelihood(p, dataset)\n        loss.backward()\n        optimizer.step()\n        loss_values.append(loss.item())\n        iteration_values.append(i+1)\n    plt.plot(iteration_values, loss_values, label=f'Dataset Size: {size}')\nplt.xlabel('Iteration')\nplt.ylabel('Loss')\nplt.title('Loss vs. Iteration for Varying Dataset Sizes')\nplt.legend()\nplt.show()\n\n\n\n\nThe plot shows the relationship between the loss and the number of iterations for each dataset size.\nBy examining the plot, we can observe the following:\n\nAs the dataset size increases, the convergence to the optimal parameter value tends to be faster. This is because larger datasets provide more information, allowing for more accurate estimation.\nFor smaller dataset sizes (e.g., 10, 50, 100), the loss tends to fluctuate more initially. However, as the number of iterations increases, the loss converges to a stable value.\nFor larger dataset sizes (e.g., 1000, 10000), the loss tends to converge quickly and stabilize earlier compared to smaller dataset sizes."
  },
  {
    "objectID": "posts/Sampling_distributions.html",
    "href": "posts/Sampling_distributions.html",
    "title": "Introduction to Univariate sampling",
    "section": "",
    "text": "This blog is your gateway to delve into various commonly used univariate sampling. Here, you will find intriguing insights into the stories behind these distributions. For example, you will discover that the outcome of a coin flip follows a Bernoulli distribution. We provide comprehensive information about each distribution, including their probability mass or probability density functions, moments, and more. Additionally, we offer implementations of these distributions using PyTorch, allowing you to explore and experiment with different flavors and variations of each distribution.\n\nSome imports\n\n#Important libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.distributions as dist\nimport math\nfrom IPython.display import Image\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline\n\n\n\nPre-defined values\n\n\nn_samples=10000\np=0.4\n\n\n\nRandom variables\nIf the value of X is unknown and/or could change, we call it a random variable or rv. The set of possible values, denoted X, is known as the sample space.\nDiscrete rv : If the sample space X is finite or countably infinite, then X is called a discrete random variable.\nContinuous rv: If \\(X \\in \\mathbb{R}\\) is a real-valued quantity, it is called a continuous random variable.\nProbability mass function or pmf : Function which computes the probability of events which setting the rv to each possible value: \\(p(x) = \\Pr(X = x)\\).\nThe PMF satisfies the properties \\(0 \\leq p(x) \\leq 1\\) and \\(\\sum_{x \\in X} p(x) = 1\\).\n\n\nUniform distribution\nStory : A continuous random variable X is said to have a Uniform distribution over the interval [a,b] , shown as X∼Uniform(a,b).\nExample : Anything in which all possibilities are equally likely.\nSupport : The Uniform distribution is supported on the interval \\([\\alpha,\\beta]\\).\nPDF : \\[\nf(x) = \\begin{cases}\n\\frac{1}{b - a} & \\text{for } a \\leq x \\leq b \\\\\n0 & \\text{otherwise}\n\\end{cases}\n\\]\n\ndistribution = torch.distributions.Uniform(0, 1)\nprint(distribution)\nrandom_numbers = distribution.sample((1000,))\n#print(random_numbers)\nsample = torch.arange(1,len(random_numbers)+1)\nplt.bar(sample,random_numbers)\nplt.xlabel(\"sample\")\nplt.ylabel(\"probability distribution\")\n\n\nUniform(low: 0.0, high: 1.0)\n\n\nText(0, 0.5, 'probability distribution')\n\n\n\n\n\n\n\nBernoulli distribution\nStory : Bernoulli Distribution is a discrete probability distribution used for experiments with yes/no outcomes. It represents a single trial with two possible outcomes: success (1) with probability p or failure (0) with probability \\((1 - p)\\).\npmf: \\[\nf(x, p) = \\begin{cases}\np & \\text{if } x = 1 \\\\\n1 - p & \\text{if } x = 0 \\\\\n\\end{cases}\n\\] Example : Flipping a coin.\n\nfrom torch.distributions import Bernoulli\np=torch.tensor(0.4)\nbernoulli=Bernoulli(probs=p)\nbernoulli_samples = bernoulli.sample((n_samples,))\nx=[0,1]\nf=[]\ns=[]\nfor i in bernoulli_samples:\n    if i == 1:\n        s.append(i)\n    else:\n        f.append(i)   \nprint(len(s))   \ncategories=['0','1']\nplt.bar(categories,[len(s),len(f)])\nplt.ylabel(\"No of samples\")\nplt.xlabel(\"categories\")\n\n4115\n\n\nText(0.5, 0, 'categories')\n\n\n\n\n\n\n\nCategorical distribution\nStory - In a set of discrete outcomes, each outcome is assigned a probability.\nExample - The student has a \\(p_{a}\\) probability of studying, a \\(p_{b}\\) probability of going out with friends, and a \\(p_{c}\\) probability of watching a movie.\npmf : \\[\nf(x; p_1, p_2, ..., p_k) =\n\\begin{cases}\np_1 & \\text{if } x = 1 \\\\\np_2 & \\text{if } x = 2 \\\\\n\\vdots \\\\\np_k & \\text{if } x = k \\\\\n\\end{cases}\n\\]\n\nfrom torch.distributions import Categorical\nprobs=torch.tensor([0.20,0.30,0.50])\ncategorical_distribution = Categorical(probs)\ncategorical_numbers = categorical_distribution.sample((n_samples,))\nprint(categorical_numbers)\ncategory_counts = torch.bincount(categorical_numbers) #Bincount:count the number of occurrences of each value                                                       #of occurrences of each value\nprobabilities = category_counts / n_samples\nprint(category_counts)\nprint(len(probabilities))\ncategories = torch.arange(1,len(probabilities)+1)\n#print(categories)\nplt.bar(categories, probabilities)\nplt.ylabel(\"probabilities\")\nplt.xlabel(\"categories\")\n\n\ntensor([1, 2, 2,  ..., 2, 1, 1])\ntensor([2013, 3051, 4936])\n3\n\n\nText(0.5, 0, 'categories')\n\n\n\n\n\n\n\nNormal distribution\nStory - The normal distribution arises when many small factors contribute to a quantity without any extreme variations, resulting in a bell-shaped curve.\nExample - When measuring the heights of a large population, we typically find that the distribution follows a bell-shaped curve, with the majority of individuals clustering around the average height and fewer individuals at the extremes (very tall or very short)\n\\[\nf(x;\\mu, \\sigma) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}\n\\]\nMoments\nMean: \\(\\mu\\)\nVariance: \\(\\sigma^2\\)\n\nfrom torch.distributions import Normal\nmean = torch.tensor([0.0])\nstddev = torch.tensor([1.0])\ndist = Normal(mean, stddev)\nx = np.linspace(-5, 5, 100)\npdf = torch.exp(dist.log_prob(torch.tensor(x))).numpy()\n\n# Plot the normal distribution\nplt.plot(x, pdf)\nplt.ylabel(\"probability density\")\nplt.xlabel(\"x\")\n\nText(0.5, 0, 'x')\n\n\n\n\n\n\n\nBeta distribution\nStory : Let’s say you have two processes, each consisting of multiple steps. Both processes occur at the same rate, but the first process requires \\(\\alpha\\) step and the second process \\(\\beta\\) ,the fraction of the total waiting time taken by the first process is Beta distributed .\nExample : Include the Click-Through Rate (CTR) of an advertisement, the conversion rate of customers purchasing on your website.\n\\[f(x; \\alpha, \\beta) = \\frac{x^{\\alpha-1} (1-x)^{\\beta-1}}{B(\\alpha, \\beta)}\\]\nwhere\n\\[B(\\alpha, \\beta) = \\int_0^1 x^{\\alpha-1} (1-x)^{\\beta-1} dx\\]\nSupport : The Beta distribution has support on the interval [0, 1].\nMoments :\n\\(\\mu = \\frac{\\alpha}{\\alpha + \\beta}\\)\n\\(\\sigma^2 = \\frac{\\alpha \\beta}{(\\alpha + \\beta)^2 (\\alpha + \\beta + 1)}\\)\n\nalpha = 2\nbeta = 7\n# Create a Beta distribution object\nbeta_dist = torch.distributions.Beta(alpha, beta)\nx = np.linspace(0, 1, 1000)\npdf = beta_dist.log_prob(torch.tensor(x)).exp()\nplt.plot(x, pdf)\nplt.xlabel(\"x\")\nplt.ylabel(\"pdf\")\n\nText(0, 0.5, 'pdf')\n\n\n\n\n\n\n\nGamma distrubution\n\nalpha = 2.0\nbeta = 1.0\ngamma_dist = torch.distributions.Gamma(alpha, beta)\nx = torch.linspace(0, 10, 1000)\npdf = gamma_dist.log_prob(x).exp()\nplt.plot(x,pdf)\nplt.xlabel(\"x\")\nplt.ylabel(\"pdf\")\n\nText(0, 0.5, 'pdf')\n\n\n\n\n\n\n\nCumulative Distribution Function (CDF)\nStory : The Cumulative Distribution Function or the CDF is the probability that a real-valued random variable X with a given probability distribution is less than or equal to a quantity x . It is often denoted by \\(F(x)=P(X≤x)\\)\nProperties :\n1.The CDF is a non-decreasing function.\n2.\\(\\lim_{{x \\to \\infty}} F(x) = 1\\) (An upper bound and horizontal asymptote at \\(F(x)=1\\) if x approaches \\(∞\\) .)\n3.\\(\\lim_{{x \\to \\infty}} F(x) = 0\\) (A lower bound and horizontal asymptote at \\(F(x)=0\\) if x approaches \\(-∞\\).)\n$ F(x) =\n\\[\\begin{cases}\n0 & \\text{if } x &lt; a \\\\\n\\frac{{x - a}}{{b - a}} & \\text{if } a \\leq x &lt; b \\\\\n1 & \\text{if } x \\geq b \\\\\n\\end{cases}\\]\n$\n\n\nCDF of Uniform distribution\n\na=2\nb=6\nx=np.linspace(a,b,10000)\ncdf = np.where(x &lt; a, 0, np.where(x &gt; b, 1, (x - a) / (b - a)))\n#print(cdf)\nplt.plot(x,cdf)\nplt.xlabel(\"x\")\nplt.ylabel(\"cdf\")\n\nText(0, 0.5, 'cdf')\n\n\n\n\n\n\n\nCDF of Bernoulli distribution\n\nprobs=torch.tensor([.20,.40,.40])\ncdf = torch.cumsum((probs),dim=0)\nprint(cdf)\n#print(1+len(probabilities))\ncategories = torch.arange(1,len(probabilities)+1)\nplt.plot(categories,cdf)\nplt.ylabel(\"cdf\")\nplt.xlabel(\"categories\")\n\ntensor([0.2000, 0.6000, 1.0000])\n\n\nText(0.5, 0, 'categories')\n\n\n\n\n\n\n\nCDF of Normal distribution\n\n## cdf\nfrom scipy.stats import norm\nsample=np.linspace(-5,5,10000)\n#print(distribution)\ncdf=norm.cdf(sample,loc=0, scale=1)\nplt.plot(sample,cdf)\n\n\n\n\n\n\nThe Inverse CDF Method\nStory : We have discovered that the standard uniform random variable takes on values between 0 and 1 inclusive. The CDF of a (continuous) distribution also takes on values between 0 and 1 inclusive. In addition, the inverse CDF \\(F^{-1}(x)\\) is also an increasing function (of \\(x\\) ).\nAlgorithm : Obtain or generate a draw \\(u\\) from the standard uniform distribution \\(U \\sim \\text{Unif}(0,1)\\).\nThe draw \\(x\\) from the CDF \\(F(x)\\) is given by \\(x = F^{-1}(u)\\).\nExample : Suppose we only know how to generate or sample \\(Unif(0,1)\\) random variables. We want to generate \\(Unif(a,b)\\) random variables. The Inverse CDF Method follows -\nThe CDF of \\(Unif(a,b)\\) is \\(F(x)= U =\\frac{x - a}{b - a}\\) for any \\(x\\) in the open interval \\((a,b)\\).\nThe resulting inverse CDF : \\(F^{-1}(u) = a + (b - a)u\\)\n\n\nInverse CDF of Uniform distribution\n\na=2\nb=3\nprobabilities=np.linspace(0,1,1000)\ninv_cdf=a+(b-a)*probabilities\n#print(inv_cdf)\nplt.plot(probabilities,inv_cdf)\nplt.xlabel(\"probability\")\nplt.ylabel(\"samples\")\n\nText(0, 0.5, 'samples')\n\n\n\n\n\n\n\nInverse CDF of Categorical distribution\n\n#Inverse cdf\nprobs=torch.tensor([.20,.40,.40])\ncategories=['1','2','3']\ncategorical_dist = dist.Categorical(probs)\nprint(categorical_dist)\nsample=categorical_dist.sample()\nprint(sample.item()) # for value\nplt.plot(categories, probs)\nplt.xlabel('Categories')\nplt.ylabel('Probability')\n\nAttributeError: 'Normal' object has no attribute 'Categorical'\n\n\n\n\nInverse CDF of Normal distribution\n\ndistribution = np.linspace(0.01, 0.99, 1000)\ninv_cdf = norm.ppf(distribution, loc=0, scale=1)\nplt.plot(distribution, inv_cdf)\nplt.xlabel('Probability')\nplt.ylabel('Inverse CDF')\n\nText(0, 0.5, 'Inverse CDF')\n\n\n\n\n\n\n\nImplementing a pseudo-random number generator (PRNG)\nImplementing a pseudo-random number generator (PRNG) - Generates a sequence of numbers that exhibit properties of randomness\nLinear Congruential Generator (LCG) is a simple PRNG algorithm - The LCG algorithm is defined by the recurrence relation:\n\\(X_{n+1} = (a \\cdot X_n + c) \\mod m\\)\n\n\\(X_{n+1}\\) is the Next pseudo-random number.\n\\(X_n\\) is the current pseudo-random number.\n\\(a\\) is the multiplier , determines the period of the generated number.\n\\(c\\) is the increment, shifts the generated sequence.\n\\(m\\) is the modulus, determines the range of values .\n\nInteger Constant\n\\(m,{0&lt;m}\\) — The modulus\n\\(a,0&lt;a&lt;m\\) — The multiplier\n\\(c,0&lt;=c&lt;m\\) — The increment\n\\(X_{0},0&lt;X_{0}&lt;m\\) — The seed / start value\n\n# Function for Linear Congruential Generator\ndef lcg(seed, n_samples):\n    \"\"\"\n    Generates a sequence of pseudo-random numbers using the Linear Congruential Generator (LCG) algorithm.\n\n    Args:\n        seed (int): The seed value for the LCG algorithm.\n        n_samples (int): The number of random numbers to generate.\n\n    Returns:\n        list: A list of pseudo-random numbers normalized to the range [0, 1].\n    \"\"\"\n    a = 1103515245\n    c = 12345\n    m = 2 ** 31\n    random_numbers = []\n\n    for _ in range(n_samples):\n        seed = (a * seed + c) % m\n        random_number = seed / m  # Normalize to range [0, 1]\n        random_numbers.append(random_number)\n\n    return random_numbers\n\nPlot histogram\n\n\n# Example usage:\nrandom_numbers = lcg(seed, n_samples )\n\nplt.hist(random_numbers, bins=20)\nplt.xlabel('Random Number')\nplt.ylabel('Frequency')\nplt.title('Histogram of Pseudo-random Numbers')\nplt.show()\n\n\n\n\n\n\nUniform to Normal sampling\n\n\nBox Muller Method\n\ndef uniform_to_normal_boxmuller(n_samples):\n    \"\"\"\n    Generates a sequence of pseudo-random numbers from a standard normal distribution using the Box-Muller method.\n\n    Args:\n        n_samples (int): The number of random numbers to generate.\n\n    Returns:\n        torch.Tensor: A tensor of pseudo-random numbers following the standard normal distribution.\n    \"\"\"\n    uniform_distribution = dist.Uniform(0, 1)\n    random_numbers = []\n\n    for _ in range(n_samples // 2):\n        u1 = uniform_distribution.sample()\n        u2 = uniform_distribution.sample()\n\n        z1 = torch.sqrt(-2 * torch.log(u1)) * torch.cos(2 * math.pi * u2)\n        z2 = torch.sqrt(-2 * torch.log(u1)) * torch.sin(2 * math.pi * u2)\n\n        random_numbers.append(z1)\n        random_numbers.append(z2)\n\n    if n_samples % 2 != 0:\n        u = uniform_distribution.sample()\n        z = torch.sqrt(-2 * torch.log(u)) * torch.cos(2 * math.pi * uniform_distribution.sample())\n        random_numbers.append(z)\n\n    return torch.stack(random_numbers)\n\nIn Normal Distribution Values are symmetrically distributed around a central mean. For example, heights in a population follow a bell-shaped curve, with the most common values near the mean and fewer occurrences as we move away from it. Graphically, it is represented by a bell-shaped curve.\n\n\n(0,1) -&gt; (a,b)\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Set the mean and standard deviation of the original normal distribution\nmu = 0\nsigma = 1\n\n# Set the desired mean and standard deviation of the converted normal distribution\na = 5\nb = 2\n\n# Generate random samples from the standard normal distribution\nx = np.random.normal(mu, sigma, 1000)\n\n# Apply the transformation to convert to the desired normal distribution\ny = a + b * x\n\n# Plot the histogram of the converted normal distribution\nplt.hist(y, bins=20, density=True, alpha=0.5)\nplt.xlabel('Value')\nplt.ylabel('Density')\nplt.title(f'Normal Distribution: μ = {a}, σ = {b}')\nplt.show()\n\n\nmu = 0\nsigma = 1\n\n# Set the desired mean and standard deviation of the converted normal distribution\na = 5\nb = 2\n\n# Create a normal distribution with the original mean and standard deviation\noriginal_dist = torch.distributions.Normal(mu, sigma)\n\n# Generate random samples from the original normal distribution\nsamples = original_dist.sample((10000,))\n\n# Apply the transformation to convert to the desired normal distribution\nconverted_samples = a + b * samples\n\n# Create a normal distribution with the desired mean and standard deviation\nconverted_dist = torch.distributions.Normal(a, b)\n\n# Plot the histogram of the converted normal distribution\nplt.hist(converted_samples.numpy(), bins=20, density=True, alpha=0.5)\nplt.xlabel('Value')\nplt.ylabel('Density')\nplt.title(f'Normal Distribution: μ = {a}, σ = {b}')\nplt.show()"
  },
  {
    "objectID": "posts/thuplots.html",
    "href": "posts/thuplots.html",
    "title": "",
    "section": "",
    "text": "import torch\nimport torch.autograd.functional as F\nimport torch.distributions as dist\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.rcParams['font.family'] = 'sans-serif'\nplt.rcParams['font.sans-serif'] = ['Liberation Sans']\n\n\n\nimport pandas as pd\n%matplotlib inline\n\n\nfrom tueplots import bundles\nplt.rcParams.update(bundles.beamer_moml())\n#plt.rcParams.update(bundles.icml2022())\n\n\n# Also add despine to the bundle using rcParams\nplt.rcParams['axes.spines.right'] = False\nplt.rcParams['axes.spines.top'] = False\n\n# Increase font size to match Beamer template\nplt.rcParams['font.size'] = 16\n# Make background transparent\nplt.rcParams['figure.facecolor'] = 'none'\n\n\ntry:\n    import hamiltorch\nexcept ImportError:\n    %pip install git+https://github.com/AdamCobb/hamiltorch\n\n\nhamiltorch.set_random_seed(123)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice\n\ndevice(type='cpu')\n\n\n\ngt_distribution = torch.distributions.Normal(0, 1)\n\n# Samples from the ground truth distribution\ndef sample_gt(n):\n    return gt_distribution.sample((n,))\n\nsamples = sample_gt(1000)\n\n\nx_lin = torch.linspace(-3, 3, 1000)\ny_lin = torch.exp(gt_distribution.log_prob(x_lin))\n\nplt.plot(x_lin, y_lin, label='Ground truth')\n\n\n\n\n\n# Logprob function to be passed to Hamiltorch sampler\ndef logprob(x):\n    return gt_distribution.log_prob(x).sum()\n\n# Initial state\nx0 = torch.tensor([0.0])\nnum_samples = 5000\nstep_size = 0.3\nnum_steps_per_sample = 5\nhamiltorch.set_random_seed(123)\n\n\nparams_hmc = hamiltorch.sample(log_prob_func=logprob, params_init=x0,  \n                               num_samples=num_samples, step_size=step_size, \n                               num_steps_per_sample=num_steps_per_sample)\n\nSampling (Sampler.HMC; Integrator.IMPLICIT)\nTime spent  | Time remain.| Progress             | Samples   | Samples/sec\n0d:00:00:16 | 0d:00:00:00 | #################### | 5000/5000 | 308.91       \nAcceptance Rate 0.99\n\n\n\nparams_hmc = torch.tensor(params_hmc)\n# Trace plot\nplt.plot(params_hmc, label='Trace')\nplt.xlabel('Iteration')\nplt.ylabel('Parameter value')\n\nText(0, 0.5, 'Parameter value')\n\n\n\n\n\n\n# Logprob function to be passed to Hamiltorch sampler\ndef logprob(x):\n    return gt_distribution.log_prob(x).sum()\n\n# Initial state\nx0 = torch.tensor([0.0])\nnum_samples = 5000\nstep_size = 0.3\nnum_steps_per_sample = 5\nhamiltorch.set_random_seed(123)\n\n\nparams_hmc = hamiltorch.sample(log_prob_func=logprob, params_init=x0,  \n                               num_samples=num_samples, step_size=step_size, \n                               num_steps_per_sample=num_steps_per_sample)\n\nSampling (Sampler.HMC; Integrator.IMPLICIT)\nTime spent  | Time remain.| Progress             | Samples   | Samples/sec\n0d:00:00:14 | 0d:00:00:00 | #################### | 5000/5000 | 338.09       \nAcceptance Rate 0.99\n\n\n\nparams_hmc = torch.tensor(params_hmc)\n# Trace plot\nplt.plot(params_hmc, label='Trace')\nplt.xlabel('Iteration')\nplt.ylabel('Parameter value')\n\n/tmp/ipykernel_18135/1433682485.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  params_hmc = torch.tensor(params_hmc)\n\n\nText(0, 0.5, 'Parameter value')\n\n\n\n\n\n\n# KDE plot\nimport seaborn as sns\nplt.figure()\nsns.kdeplot(params_hmc.detach().numpy(), label='Samples', shade=True, color='C1')\nplt.plot(x_lin, y_lin, label='Ground truth')\nplt.xlabel('Parameter value')\nplt.ylabel('Density')\nplt.legend()\n\n/tmp/ipykernel_18135/469715340.py:4: FutureWarning: \n\n`shade` is now deprecated in favor of `fill`; setting `fill=True`.\nThis will become an error in seaborn v0.14.0; please update your code.\n\n  sns.kdeplot(params_hmc.detach().numpy(), label='Samples', shade=True, color='C1')\n\n\n&lt;matplotlib.legend.Legend at 0x7f51dfedd4b0&gt;\n\n\n\n\n\n\n# Linear regression for 1 dimensional input using HMC\n\nx_lin = torch.linspace(-3, 3, 90)\ntheta_0_true = torch.tensor([2.0])\ntheta_1_true = torch.tensor([3.0])\nf = lambda x: theta_0_true + theta_1_true * x\neps = torch.randn_like(x_lin) *1.0\ny_lin = f(x_lin) + eps\n\nplt.scatter(x_lin, y_lin, label='Data', color='C0')\nplt.plot(x_lin, f(x_lin), label='Ground truth')\nplt.xlabel('x')\nplt.ylabel('y')\n\nText(0, 0.5, 'y')"
  },
  {
    "objectID": "posts/different_losses.html",
    "href": "posts/different_losses.html",
    "title": "",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.colors\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, mean_squared_error\nfrom tqdm import tqdm_notebook \n\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.datasets import make_blobs\n\nLoading Dataset\n\n'''\n# Load Dataset from Kaggle \n#pip install kaggle\nimport os\n\nimport kaggle\n# Set Kaggle API credentials\n\n\n# Download the dataset using Kaggle API\nkaggle.api.dataset_download_files('kaggle datasets download -d lava18/google-play-store-apps')\n\n# Unzip the downloaded dataset files if necessary\n\n# Load the dataset using pandas\ndf = pd.read_csv('path_to_dataset_file.csv')\n'''\n\n\"\\n# Load Dataset from Kaggle \\n#pip install kaggle\\nimport os\\n\\nimport kaggle\\n# Set Kaggle API credentials\\n\\n\\n# Download the dataset using Kaggle API\\nkaggle.api.dataset_download_files('kaggle datasets download -d lava18/google-play-store-apps')\\n\\n# Unzip the downloaded dataset files if necessary\\n\\n# Load the dataset using pandas\\ndf = pd.read_csv('path_to_dataset_file.csv')\\n\"\n\n\n\nclass SigmoidNeuron:\n    \n  def __init__(self):\n    self.W1 = None\n    self.b1 = None\n    self.W2 = None\n    self.b2 = None\n    \n  def perceptron(self, X, W, b):\n    return np.dot(X, W.T) + b\n  \n  def sigmoid(self, X):\n    return 1.0 / (1.0 + np.exp(-X))\n  \n  def grad_w_mse(self, X, Y, Y_pred):\n    m = X.shape[0]\n    return np.dot((Y_pred - Y) * Y_pred * (1 - Y_pred), X) / m\n  \n  def grad_b_mse(self, X, Y, Y_pred):\n    m = X.shape[0]\n    return np.sum((Y_pred - Y) * Y_pred * (1 - Y_pred)) / m\n  \n  def fit(self, X, Y, epochs=1, learning_rate=1, initialise=True, loss_fn=\"mse\", display_loss=False):\n    \n    # Initialise weights and biases\n    if initialise:\n      input_dim = X.shape[1]\n      hidden_dim = 2 * input_dim\n      output_dim = 1\n      self.W1 = np.random.randn(input_dim, hidden_dim)\n      self.b1 = np.zeros(hidden_dim)\n      self.W2 = np.random.randn(hidden_dim, output_dim)\n      self.b2 = np.zeros(output_dim)\n      \n    if display_loss:\n      loss = {}\n    \n    for epoch in range(epochs):\n      # Forward Propagation\n      hidden_output = self.sigmoid(self.perceptron(X, self.W1, self.b1))\n      Y_pred = self.sigmoid(self.perceptron(hidden_output, self.W2, self.b2))\n      \n      # Backpropagation\n      dw2 = self.grad_w_mse(hidden_output, Y, Y_pred)\n      db2 = self.grad_b_mse(hidden_output, Y, Y_pred)\n      \n      dw1 = np.dot((np.dot((Y_pred - Y) * Y_pred * (1 - Y_pred), self.W2.T) * hidden_output * (1 - hidden_output)).T, X)\n      db1 = np.sum((np.dot((Y_pred - Y) * Y_pred * (1 - Y_pred), self.W2.T) * hidden_output * (1 - hidden_output)).T, axis=1)\n      \n      # Update weights and biases\n      self.W2 -= learning_rate * dw2\n      self.b2 -= learning_rate * db2\n      self.W1 -= learning_rate * dw1\n      self.b1 -= learning_rate * db1\n      \n      if display_loss:\n        loss[epoch] = np.mean((Y_pred - Y) ** 2)\n    \n    if display_loss:\n      plt.plot(list(loss.values()))\n      plt.xlabel('Epochs')\n      plt.ylabel('Mean Squared Error')\n      plt.title('Loss vs Epochs')\n      plt.show()\n      \n  def predict(self, X):\n    hidden_output = self.sigmoid(self.perceptron(X, self.W1, self.b1))\n    Y_pred = self.sigmoid(self.perceptron(hidden_output, self.W2, self.b2))\n    return Y_pred"
  },
  {
    "objectID": "posts/log-sum-exp.html",
    "href": "posts/log-sum-exp.html",
    "title": "",
    "section": "",
    "text": "import numpy as np\n\nThe log1p function is a useful tool for calculating the logarithm of 1 + p, particularly when p is a small value. It helps avoid numerical instability issues that can arise when directly computing np.log(1 + p) when p is close to zero. By using log1p, you can achieve a more accurate and stable calculation of the logarithm.\n\nx = np.array([1, 2, 3, 4, 5])\np = 1e-10\nresult = np.log(1 + p)  # Direct computation, can be unstable for small p\nresult_log1p = np.log1p(p)  # More stable computation using log1p\nprint(result)\nprint(result_log1p)\n\n1.000000082690371e-10\n9.999999999500001e-11\n\n\nWhen dealing with small values like 1e-5, using the expression exp(p) - 1 can result in a loss of precision. In such cases, the function expm1(p) is a better alternative as it provides a more accurate result that preserves the precision of the small input value p.\n\nresult1 = np.exp(p) - 1\nresult2 = np.expm1(p)\n\nprint(\"Using exp(p) - 1:\")\nprint(result1)\n\nprint(\"Using expm1(p):\")\nprint(result2)\n\nUsing exp(p) - 1:\n1.000000082740371e-10\nUsing expm1(p):\n1.00000000005e-10\n\n\nUsing np.log1p to compute log(1 + p) provides a numerically stable and accurate result of 1e-10, even for small values of p.\n\nx = 0\ny = 10\n\nresult = np.multiply(x, np.log(y))\n\nprint(result)\n\n0.0\n\n\nTo avoid numerical instability when computing x log(1 + p) with small values of x and p, it is advisable to use np.log1p instead of directly calculating np.log(1 + p). This ensures better accuracy and stability by preserving the precision of the small input p.\n\nfrom scipy.special import xlog1py\nfrom scipy.special import xlogy\n\n\nx = 1\np = 1e-10\n\nresult = xlogy(x, 1 + p)\nresult1 = xlog1py(x, p)\n\nprint(result)\nprint(result1)\n\n1.000000082690371e-10\n9.999999999500001e-11"
  },
  {
    "objectID": "posts/spiking_nn.html",
    "href": "posts/spiking_nn.html",
    "title": "Spiking neural networks (SNNs)",
    "section": "",
    "text": "Spiking neural networks (SNNs) are artificial neural networks that closely resemble natural neural networks. It mimic natural neural networks, incorporating time and thresholds for neuron activation."
  },
  {
    "objectID": "posts/Sampling_distributions.html#some-imports",
    "href": "posts/Sampling_distributions.html#some-imports",
    "title": "Introduction to Univariate sampling",
    "section": "Some imports",
    "text": "Some imports\n\n#Important libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.distributions as dist\nimport math\nfrom IPython.display import Image\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline\n\nNotes\nTUEplots: Extend matplotlib for scientific publications"
  },
  {
    "objectID": "posts/Sampling_distributions.html#a-function-to-make-the-matplotlib-plots-prettier",
    "href": "posts/Sampling_distributions.html#a-function-to-make-the-matplotlib-plots-prettier",
    "title": "Introduction to Univariate sampling",
    "section": "A function to make the Matplotlib plots prettier",
    "text": "A function to make the Matplotlib plots prettier\n\nSPINE_COLOR = 'red'\n\ndef format_axes(ax):\n    for spine in ['top', 'right']:\n        ax.spines[spine].set_visible(False)\n\n    for spine in ['left', 'bottom']:\n        ax.spines[spine].set_color(SPINE_COLOR)\n        ax.spines[spine].set_linewidth(0.5)\n\n    ax.xaxis.set_ticks_position('bottom')\n    ax.yaxis.set_ticks_position('left')\n\n    for axis in [ax.xaxis, ax.yaxis]:\n        axis.set_tick_params(direction='out', color=SPINE_COLOR)\n\n    return ax\n\n\nPre-defined values\n\n\nn_samples=10000\nseed=42\np=0.4"
  },
  {
    "objectID": "posts/Sampling_distributions.html#random-variables",
    "href": "posts/Sampling_distributions.html#random-variables",
    "title": "Introduction to Univariate sampling",
    "section": "Random variables",
    "text": "Random variables\nIf the value of X is unknown and/or could change, we call it a random variable or rv. The set of possible values, denoted X, is known as the sample space.\nDiscrete rv : If the sample space X is finite or countably infinite, then X is called a discrete random variable.\nContinuous rv: If \\(X \\in \\mathbb{R}\\) is a real-valued quantity, it is called a continuous random variable.\nProbability mass function or pmf : Function which computes the probability of events which setting the rv to each possible value: \\(p(x) = \\Pr(X = x)\\).\nThe PMF satisfies the properties \\(0 \\leq p(x) \\leq 1\\) and \\(\\sum_{x \\in X} p(x) = 1\\).\n\nUniform distribution\nStory : A continuous random variable X is said to have a Uniform distribution over the interval [a,b] , shown as X∼Uniform(a,b).\nExample : Anything in which all possibilities are equally likely.\nSupport : The Uniform distribution is supported on the interval \\([\\alpha,\\beta]\\).\nPDF : \\[\nf(x) = \\begin{cases}\n\\frac{1}{b - a} & \\text{for } a \\leq x \\leq b \\\\\n0 & \\text{otherwise}\n\\end{cases}\n\\]\nWe can also plot and visualise the same phenomenon using a histogram shown below.\n\ndistribution = torch.distributions.Uniform(0, 1)\nrandom_numbers = distribution.sample((n_samples,))\nplt.hist(random_numbers.numpy(), bins=20)\nformat_axes(plt.gca())\n\n&lt;Axes: &gt;\n\n\n\n\n\nWe can notice that all outcomes within a given range are equally likely , ploted as a rectangular graph.\n\n\nBernoulli distribution\nStory : Bernoulli Distribution is a discrete probability distribution used for experiments with yes/no outcomes. It represents a single trial with two possible outcomes: success (1) with probability p or failure (0) with probability \\((1 - p)\\).\npmf: \\[\nf(x, p) = \\begin{cases}\np & \\text{if } x = 1 \\\\\n1 - p & \\text{if } x = 0 \\\\\n\\end{cases}\n\\] Example : Flipping a coin.\n\nfrom torch.distributions import Bernoulli\np=torch.tensor(0.4)\nbernoulli=Bernoulli(probs=p)\nbernoulli_samples = bernoulli.sample((n_samples,))\nx=[0,1]\nf=[]\ns=[]\nfor i in bernoulli_samples:\n    if i == 1:\n        s.append(i)\n    else:\n        f.append(i)   \nprint(len(s))   \n\nplt.bar([0,1],[len(s),len(f)])\n#plt.(bernoulli_samples.numpy(), bins=3)\nplt.xticks([0,1], ['0', '1'])\nformat_axes(plt.gca())\n\n4024\n\n\n&lt;Axes: &gt;\n\n\n\n\n\n\n\nCategorical distribution\nStory - In a set of discrete outcomes, each outcome is assigned a probability.\nExample - The student has a \\(p_{a}\\) probability of studying, a \\(p_{b}\\) probability of going out with friends, and a \\(p_{c}\\) probability of watching a movie.\npmf : \\[\nf(x; p_1, p_2, ..., p_k) =\n\\begin{cases}\np_1 & \\text{if } x = 1 \\\\\np_2 & \\text{if } x = 2 \\\\\n\\vdots \\\\\np_k & \\text{if } x = k \\\\\n\\end{cases}\n\\]\n\nimport torch.distributions as dist\nfrom torch.distributions import Categorical\nprobs=torch.tensor([0.20,0.40,0.40])\ncategorical_distribution = Categorical(probs)\ncategorical_numbers = categorical_distribution.sample((n_samples,))\nprint(categorical_numbers)\ncategory_counts = torch.bincount(categorical_numbers)\nprobabilities = category_counts / n_samples\n#print(category_counts)\n#print(probabilities)\ncategories = torch.arange(1,len(probabilities)+1)\n#print(categories)\nplt.bar(categories, probabilities)\nplt.ylabel(\"probabilities\")\nplt.xlabel(\"categories\")\n\n\ntensor([2, 1, 1,  ..., 0, 1, 1])\n\n\nText(0.5, 0, 'categories')\n\n\n\n\n\nSupport - If we index the categories with sequential integers from 1 to N, the distribution is supported for integers 1 to N, inclusive when described using the indices of the categories.\n\ncdf = torch.cumsum((probs),dim=0)\nprint(cdf)\nprint(1+len(probabilities))\ncategories = torch.arange(1,len(probabilities)+1)\nplt.bar(categories,cdf)\n#plt.plot(categories,cdf)\nplt.ylabel(\"cdf\")\nplt.xlabel(\"categories\")\n\ntensor([0.2000, 0.6000, 1.0000])\n4\n\n\nText(0.5, 0, 'categories')\n\n\n\n\n\n\n#Inverse cdf\ncategories=['1','2','3']\ncategorical_dist = dist.Categorical(probs)\nprint(categorical_dist)\nsample=categorical_dist.sample()\nprint(sample.item()) # for value\nplt.bar(categories, probs)\nplt.xlabel('Categories')\nplt.ylabel('Probability')\n\nCategorical(probs: torch.Size([3]))\n1\n\n\nText(0, 0.5, 'Probability')\n\n\n\n\n\n\n\nNormal distribution\nStory - The normal distribution arises when many small factors contribute to a quantity without any extreme variations, resulting in a bell-shaped curve.\nExample - When measuring the heights of a large population, we typically find that the distribution follows a bell-shaped curve, with the majority of individuals clustering around the average height and fewer individuals at the extremes (very tall or very short)\n\\[\nf(x;\\mu, \\sigma) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}\n\\]\nMoments\nMean: \\(\\mu\\) , Variance: \\(\\sigma\\)\n\nfrom torch.distributions import Normal\nmean = torch.tensor([0.0])\nstddev = torch.tensor([1.0])\ndist = Normal(mean, stddev)\nx = np.linspace(-5, 5, 100)\npdf = torch.exp(dist.log_prob(torch.tensor(x))).numpy()\n\n# Plot the normal distribution\nplt.plot(x, pdf)\nplt.ylabel(\"probability density\")\nplt.xlabel(\"x\")\n\nText(0.5, 0, 'x')\n\n\n\n\n\n\n## cdf\nfrom scipy.stats import norm\nsample=np.linspace(-5,5,10000)\n#print(distribution)\ncdf=norm.cdf(sample,loc=0, scale=1)\nplt.plot(sample,cdf)\n#cdf\n\n\n\n\n\ndistribution = np.linspace(0.01, 0.99, 1000)\ninv_cdf = norm.ppf(distribution, loc=0, scale=1)\nplt.plot(distribution, inv_cdf)\nplt.xlabel('Probability')\nplt.ylabel('Inverse CDF')\n\nText(0, 0.5, 'Inverse CDF')\n\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Set the mean and standard deviation of the original normal distribution\nmu = 0\nsigma = 1\n\n# Set the desired mean and standard deviation of the converted normal distribution\na = 5\nb = 2\n\n# Generate random samples from the standard normal distribution\nx = np.random.normal(mu, sigma, 1000)\n\n# Apply the transformation to convert to the desired normal distribution\ny = a + b * x\n\n# Plot the histogram of the converted normal distribution\nplt.hist(y, bins=20, density=True, alpha=0.5)\nplt.xlabel('Value')\nplt.ylabel('Density')\nplt.title(f'Normal Distribution: μ = {a}, σ = {b}')\nplt.show()\n\n\n\n\n\n\nBeta distribution\nStory : Let’s say you have two processes, each consisting of multiple steps. Both processes occur at the same rate, but the first process requires \\(\\alpha\\) step and the second process \\(\\beta\\) ,the fraction of the total waiting time taken by the first process is Beta distributed .\nExample : Include the Click-Through Rate (CTR) of an advertisement, the conversion rate of customers purchasing on your website.\n\\[f(x; \\alpha, \\beta) = \\frac{x^{\\alpha-1} (1-x)^{\\beta-1}}{B(\\alpha, \\beta)}\\]\nwhere\n\\[B(\\alpha, \\beta) = \\int_0^1 x^{\\alpha-1} (1-x)^{\\beta-1} dx\\]\nSupport : The Beta distribution has support on the interval [0, 1].\nMoments :\n\\(\\mu = \\frac{\\alpha}{\\alpha + \\beta}\\)\n\\(\\sigma^2 = \\frac{\\alpha \\beta}{(\\alpha + \\beta)^2 (\\alpha + \\beta + 1)}\\)\n\nalpha = 2\nbeta = 7\n# Create a Beta distribution object\nbeta_dist = torch.distributions.Beta(alpha, beta)\nsamples = beta_dist.sample((n_samples,))\nsamples_np = samples.numpy()\nplt.hist(samples_np, bins=30, density=True)\n\n# Plot the probability density function (PDF)\nx = torch.linspace(0, 1, n_samples)\npdf = beta_dist.log_prob(x).exp()\nplt.plot(x.numpy(), pdf.numpy(), 'r-', linewidth=2)\nformat_axes(plt.gca())\n\n&lt;Axes: &gt;\n\n\n\n\n\n\n\nGamma distrubution\n\nalpha = 2.0\nbeta = 1.0\n# Create a Gamma distribution object\ngamma_dist = torch.distributions.Gamma(alpha, beta)\nsamples = gamma_dist.sample((n_samples,))\nsamples_np = samples.numpy()\nplt.hist(samples_np, bins=30, density=True)\n\n# Plot the probability density function (PDF)\nx = torch.linspace(0, 10, n_samples)\npdf = gamma_dist.log_prob(x).exp()\nplt.plot(x.numpy(), pdf.numpy(), 'r-', linewidth=2)\nformat_axes(plt.gca())\n\n&lt;Axes: &gt;\n\n\n\n\n\n\n\nCumulative Distribution Function (CDF)\nStory : The Cumulative Distribution Function or the CDF is the probability that a real-valued random variable X with a given probability distribution is less than or equal to a quantity x . It is often denoted by \\(F(x)=P(X≤x)\\)\nProperties :\n1.The CDF is a non-decreasing function.\n2.\\(\\lim_{{x \\to \\infty}} F(x) = 1\\) (An upper bound and horizontal asymptote at \\(F(x)=1\\) if x approaches \\(∞\\) .)\n3.\\(\\lim_{{x \\to \\infty}} F(x) = 0\\) (A lower bound and horizontal asymptote at \\(F(x)=0\\) if x approaches \\(-∞\\).)\n$F(x) =\n\\[\\begin{cases}\n\\frac{x - a}{b - a} & \\text{for } a \\leq x \\leq b \\\\\n\\end{cases}\\]\n$\n\n\nThe Inverse CDF Method For Generating Non-Uniform Random Numbers\nStory : We have discovered that the standard uniform random variable takes on values between 0 and 1 inclusive. The CDF of a (continuous) distribution also takes on values between 0 and 1 inclusive. In addition, the inverse CDF \\(F^{-1}(x)\\) is also an increasing function (of \\(x\\) ).\nalgorithm : Obtain or generate a draw \\(u\\) from the standard uniform distribution \\(U \\sim \\text{Unif}(0,1)\\).\nThe draw \\(x\\) from the CDF \\(F(x)\\) is given by \\(x = F^{-1}(u)\\).\nExample : Suppose we only know how to generate or sample \\(Unif(0,1)\\) random variables. We want to generate \\(Unif(a,b)\\) random variables. The Inverse CDF Method follows -\nThe CDF of \\(Unif(a,b)\\) is \\(F(x)= U =\\frac{x - a}{b - a}\\) for any \\(x\\) in the open interval \\((a,b)\\).\nThe resulting inverse CDF : \\(F^{-1}(u) = a + (b - a)u\\)\n\n# range of distribution\na = 2\nb = 5\n\n# uniform distribution\ndistribution = torch.distributions.Uniform(0, 1)\nrandom_numbers = distribution.sample((n_samples,))\nplt.hist(random_numbers.numpy(), bins=20)\nformat_axes(plt.gca())\nuniform_dist = torch.distributions.Uniform(a, b)\n\n# Generate random samples from the uniform distribution\nsamples = uniform_dist.sample((n_samples,))\nplt.hist(samples.numpy(), bins=20)\n\n\nformat_axes(plt.gca())\n\n&lt;Axes: &gt;\n\n\n\n\n\n\nmu = 0\nsigma = 1\n\n# Set the desired mean and standard deviation of the converted normal distribution\na = 5\nb = 2\n\n# Create a normal distribution with the original mean and standard deviation\noriginal_dist = torch.distributions.Normal(mu, sigma)\n\n# Generate random samples from the original normal distribution\nsamples = original_dist.sample((10000,))\n\n# Apply the transformation to convert to the desired normal distribution\nconverted_samples = a + b * samples\n\n# Create a normal distribution with the desired mean and standard deviation\nconverted_dist = torch.distributions.Normal(a, b)\n\n# Plot the histogram of the converted normal distribution\nplt.hist(converted_samples.numpy(), bins=20, density=True, alpha=0.5)\nplt.xlabel('Value')\nplt.ylabel('Density')\nplt.title(f'Normal Distribution: μ = {a}, σ = {b}')\nplt.show()\n\n\n\n\n\n\nImplementing a pseudo-random number generator (PRNG)\nImplementing a pseudo-random number generator (PRNG) - Generates a sequence of numbers that exhibit properties of randomness\nLinear Congruential Generator (LCG) is a simple PRNG algorithm - The LCG algorithm is defined by the recurrence relation:\n\\(X_{n+1} = (a \\cdot X_n + c) \\mod m\\)\n\n\\(X_{n+1}\\) is the Next pseudo-random number.\n\\(X_n\\) is the current pseudo-random number.\n\\(a\\) is the multiplier , determines the period of the generated number.\n\\(c\\) is the increment, shifts the generated sequence.\n\\(m\\) is the modulus, determines the range of values .\n\nInteger Constant\n\\(m,{0&lt;m}\\) — The modulus\n\\(a,0&lt;a&lt;m\\) — The multiplier\n\\(c,0&lt;=c&lt;m\\) — The increment\n\\(X_{0},0&lt;X_{0}&lt;m\\) — The seed / start value\n\n# Function for Linear Congruential Generator\ndef lcg(seed, n_samples):\n    \"\"\"\n    Generates a sequence of pseudo-random numbers using the Linear Congruential Generator (LCG) algorithm.\n\n    Args:\n        seed (int): The seed value for the LCG algorithm.\n        n_samples (int): The number of random numbers to generate.\n\n    Returns:\n        list: A list of pseudo-random numbers normalized to the range [0, 1].\n    \"\"\"\n    a = 1103515245\n    c = 12345\n    m = 2 ** 31\n    random_numbers = []\n\n    for _ in range(n_samples):\n        seed = (a * seed + c) % m\n        random_number = seed / m  # Normalize to range [0, 1]\n        random_numbers.append(random_number)\n\n    return random_numbers\n\nPlot histogram\n\n\n# Example usage:\nrandom_numbers = lcg(seed, n_samples )\n\nplt.hist(random_numbers, bins=20)\nplt.xlabel('Random Number')\nplt.ylabel('Frequency')\nplt.title('Histogram of Pseudo-random Numbers')\nplt.show()\n\n\n\n\n\n\nUniform to Normal sampling\nBox Muller Method\n\ndef uniform_to_normal_boxmuller(n_samples):\n    \"\"\"\n    Generates a sequence of pseudo-random numbers from a standard normal distribution using the Box-Muller method.\n\n    Args:\n        n_samples (int): The number of random numbers to generate.\n\n    Returns:\n        torch.Tensor: A tensor of pseudo-random numbers following the standard normal distribution.\n    \"\"\"\n    uniform_distribution = dist.Uniform(0, 1)\n    random_numbers = []\n\n    for _ in range(n_samples // 2):\n        u1 = uniform_distribution.sample()\n        u2 = uniform_distribution.sample()\n\n        z1 = torch.sqrt(-2 * torch.log(u1)) * torch.cos(2 * math.pi * u2)\n        z2 = torch.sqrt(-2 * torch.log(u1)) * torch.sin(2 * math.pi * u2)\n\n        random_numbers.append(z1)\n        random_numbers.append(z2)\n\n    if n_samples % 2 != 0:\n        u = uniform_distribution.sample()\n        z = torch.sqrt(-2 * torch.log(u)) * torch.cos(2 * math.pi * uniform_distribution.sample())\n        random_numbers.append(z)\n\n    return torch.stack(random_numbers)\n\nIn Normal Distribution Values are symmetrically distributed around a central mean. For example, heights in a population follow a bell-shaped curve, with the most common values near the mean and fewer occurrences as we move away from it. Graphically, it is represented by a bell-shaped curve."
  },
  {
    "objectID": "posts/MLLosses.html",
    "href": "posts/MLLosses.html",
    "title": "Types of Losses and optimisation",
    "section": "",
    "text": "The Loss Function is a method of evaluating how well a machine learning algorithm models a featured data set. If our loss function value is low, our model will provide good results. The loss function we use to evaluate the model performance needs to be minimized to improve its performance.\nBroadly speaking, loss functions can be grouped into two major categories concerning the types of problems we come across in the real world: CLASSIFICATION and REGRESSION. In CLASSIFICATION problems, our task is to predict the respective probabilities of all classes the problem is dealing with. When it comes to REGRESSION, our task is to predict the continuous value concerning a given set of independent features to the learning algorithm."
  },
  {
    "objectID": "posts/MLLosses.html#mean-absolute-error-loss",
    "href": "posts/MLLosses.html#mean-absolute-error-loss",
    "title": "Types of Losses and optimisation",
    "section": "1. Mean Absolute Error Loss",
    "text": "1. Mean Absolute Error Loss\nWe define MAE loss function as the average of absolute differences between the actual and the predicted value. It’s the second most commonly used regression loss function. It measures the average magnitude of errors in a set of predictions, without considering their directions.\n\\[MAE = \\frac{1}{n}\\sum_{i=1}^{n}|y_i - \\hat{y_i}|\\]\nwhere \\(y_i\\) is the actual value and \\(\\hat{y_i}\\) is the predicted value.\nThe corresponding cost function is the mean of these absolute errors (MAE). It is also known as the L1 loss function.\n\nimport numpy as np\nimport plotly.graph_objects as go\nimport torch\n\nfrom sklearn.metrics import mean_squared_error, accuracy_score\n\nnp.random.seed(0)\ntorch.manual_seed(0)\n\n&lt;torch._C.Generator at 0x7f07b72789b0&gt;\n\n\n\n# generate data\nx = np.random.uniform(-1, 1, (500, 1))\ny = 2 * x + 3 + np.random.normal(0, 0.5, (500, 1))\n\n# plot data\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=x.flatten(), y=y.flatten(), mode='markers', name='data'))\nfig.update_layout(title='Data', xaxis_title='x', yaxis_title='y')\nfig.show()\n\n\n                                                \n\n\n\n# MAE loss\ndef mae(y, y_pred):\n    return torch.mean(torch.abs(y - y_pred))\n\n\n# add bias term\nX = np.concatenate([x, np.ones((500, 1))], axis=1)\n\n# convert to tensors\nX = torch.from_numpy(X).float()\nY = torch.from_numpy(y).float()\n\n# initialize weights\nw = torch.randn(2, 1, requires_grad=True)\n\nlr = 0.1\nrmse = []\n\n\n# gradient descent\nfor i in range(100):\n    y_pred = torch.matmul(X, w)\n    loss = mae(Y, y_pred)\n    loss.backward()\n    with torch.no_grad():\n        w -= lr * w.grad\n        w.grad.zero_()\n    rmse.append(mean_squared_error(y, y_pred.detach().numpy(), squared=False))\n    \n    if i % 10 == 0:\n        print(f'Epoch {i}, loss {rmse[-1]:.4f}')\n\nEpoch 0, loss 3.2887\nEpoch 10, loss 2.3101\nEpoch 20, loss 1.3679\nEpoch 30, loss 0.6885\nEpoch 40, loss 0.5224\nEpoch 50, loss 0.4988\nEpoch 60, loss 0.4934\nEpoch 70, loss 0.4924\nEpoch 80, loss 0.4924\nEpoch 90, loss 0.4924\n\n\n\n# plot loss\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=np.arange(len(rmse)), y=rmse, mode='lines', name='loss'))\nfig.update_layout(title='Loss', xaxis_title='epoch', yaxis_title='loss')\nfig.show()\n\n# plot data with regression line\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=x[:, 0], y=y.flatten(), mode='markers', name='data'))\nfig.add_trace(go.Scatter(x=x[:, 0], y=2 * x[:, 0] + 3, mode='lines', name='true line', line=dict(color='green')))\nfig.add_trace(go.Scatter(x=x[:, 0], y=y_pred.detach().numpy().flatten(), mode='lines', name='regression line', line=dict(color='red')))\nfig.show()"
  },
  {
    "objectID": "posts/MLLosses.html#mean-squared-error-loss",
    "href": "posts/MLLosses.html#mean-squared-error-loss",
    "title": "Types of Losses and optimisation",
    "section": "2. Mean Squared Error Loss",
    "text": "2. Mean Squared Error Loss\nWe define MSE loss function as the average of squared differences between the actual and the predicted value. It’s the most commonly used regression loss function.\n\\[MSE = \\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{y_i})^2\\]\nwhere \\(y_i\\) is the actual value and \\(\\hat{y_i}\\) is the predicted value.\nThe corresponding cost function is the mean of these squared errors (MSE). It is also known as the L2 loss function. The MSE loss function penalizes the model for making large errors by squaring them.\n\n# MSE loss\ndef mse(y, y_pred):\n    return torch.mean((y - y_pred) ** 2)\n\n\n# add bias term\nX = np.concatenate([x, np.ones((500, 1))], axis=1)\n\n# convert to tensors\nX = torch.from_numpy(X).float()\nY = torch.from_numpy(y).float()\n\n# initialize weights\nw = torch.randn(2, 1, requires_grad=True)\n\nlr = 0.1\nrmse = []\n\n\n# gradient descent\nfor i in range(100):\n    y_pred = torch.matmul(X, w)\n    loss = mse(Y, y_pred)\n    loss.backward()\n    with torch.no_grad():\n        w -= lr * w.grad\n        w.grad.zero_()\n    rmse.append(mean_squared_error(y, y_pred.detach().numpy(), squared=False))\n    \n    if i % 10 == 0:\n        print(f'Epoch {i}, loss {rmse[-1]:.4f}')\n\nEpoch 0, loss 3.4254\nEpoch 10, loss 1.3340\nEpoch 20, loss 0.7770\nEpoch 30, loss 0.5749\nEpoch 40, loss 0.5136\nEpoch 50, loss 0.4975\nEpoch 60, loss 0.4935\nEpoch 70, loss 0.4925\nEpoch 80, loss 0.4922\nEpoch 90, loss 0.4922\n\n\n\n# plot loss\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=np.arange(len(rmse)), y=rmse, mode='lines', name='loss'))\nfig.update_layout(title='Loss', xaxis_title='epoch', yaxis_title='loss')\nfig.show()\n\n# plot data with regression line\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=x[:, 0], y=y.flatten(), mode='markers', name='data'))\nfig.add_trace(go.Scatter(x=x[:, 0], y=2 * x[:, 0] + 3, mode='lines', name='true line', line=dict(color='green')))\nfig.add_trace(go.Scatter(x=x[:, 0], y=y_pred.detach().numpy().flatten(), mode='lines', name='regression line', line=dict(color='red')))\nfig.update_layout(title='Data', xaxis_title='x', yaxis_title='y')\nfig.show()"
  },
  {
    "objectID": "posts/MLLosses.html#huber-loss",
    "href": "posts/MLLosses.html#huber-loss",
    "title": "Types of Losses and optimisation",
    "section": "3. Huber Loss",
    "text": "3. Huber Loss\nWe define Huber loss function as the combination of MSE and MAE. It’s less sensitive to outliers than the MSE loss function and is differentiable at 0.\n\\[Huber = \\frac{1}{n}\\sum_{i=1}^{n}L_{\\delta}(y_i - \\hat{y_i})\\]\n\\[L_{\\delta}(y_i - \\hat{y_i}) = \\begin{cases} \\frac{1}{2}(y_i - \\hat{y_i})^2 & \\text{for } |y_i - \\hat{y_i}| \\leq \\delta \\\\ \\delta|y_i - \\hat{y_i}| - \\frac{1}{2}\\delta^2 & \\text{otherwise} \\end{cases}\\]\nwhere \\(y_i\\) is the actual value and \\(\\hat{y_i}\\) is the predicted value.\nThe corresponding cost function is the mean of these Huber errors. The Huber loss function is more robust to outliers compared to the MSE loss function.\n\n# Huber loss\ndef huber(y, y_pred, delta=1):\n    abs_diff = torch.abs(y - y_pred)\n    return torch.mean(torch.where(abs_diff &lt; delta, 0.5 * abs_diff ** 2, delta * abs_diff - 0.5 * delta ** 2))\n\n\n# add bias term\nX = np.concatenate([x, np.ones((500, 1))], axis=1)\n\n# convert to tensors\nX = torch.from_numpy(X).float()\nY = torch.from_numpy(y).float()\n\n# initialize weights\nw = torch.randn(2, 1, requires_grad=True)\n\nlr = 0.1\nrmse = []\n\n\n# gradient descent\nfor i in range(100):\n    y_pred = torch.matmul(X, w)\n    loss = huber(Y, y_pred)\n    loss.backward()\n    with torch.no_grad():\n        w -= lr * w.grad\n        w.grad.zero_()\n    rmse.append(mean_squared_error(y, y_pred.detach().numpy(), squared=False))\n    \n    if i % 10 == 0:\n        print(f'Epoch {i}, loss {rmse[-1]:.4f}')\n\nEpoch 0, loss 4.7136\nEpoch 10, loss 3.8319\nEpoch 20, loss 3.0589\nEpoch 30, loss 2.4339\nEpoch 40, loss 1.9426\nEpoch 50, loss 1.5518\nEpoch 60, loss 1.2385\nEpoch 70, loss 0.9916\nEpoch 80, loss 0.8063\nEpoch 90, loss 0.6778\n\n\n\n# plot loss\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=np.arange(len(rmse)), y=rmse, mode='lines', name='loss'))\nfig.update_layout(title='Loss', xaxis_title='epoch', yaxis_title='loss')\nfig.show()\n\n# plot data with regression line\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=x[:, 0], y=y.flatten(), mode='markers', name='data'))\nfig.add_trace(go.Scatter(x=x[:, 0], y=2 * x[:, 0] + 3, mode='lines', name='true line', line=dict(color='green')))\nfig.add_trace(go.Scatter(x=x[:, 0], y=y_pred.detach().numpy().flatten(), mode='lines', name='regression line', line=dict(color='red')))\nfig.show()"
  },
  {
    "objectID": "posts/MLLosses.html#binary-cross-entropy-loss",
    "href": "posts/MLLosses.html#binary-cross-entropy-loss",
    "title": "Types of Losses and optimisation",
    "section": "1. Binary Cross-Entropy Loss",
    "text": "1. Binary Cross-Entropy Loss\nThis is the most common loss function used in classification problems. The binary cross-entropy loss decreases as the predicted probability converges to the actual label. It measures the performance of a classification model whose predicted output is a probability value between 0 and 1.\n\\[L = \\begin{cases} -log(\\hat{y_i}) & \\text{if } y_i = 1 \\\\ -log(1-\\hat{y_i}) & \\text{if } y_i = 0 \\end{cases}\\]\n\\[L = - \\dfrac{1}{m} \\sum_{i=1}^{m} y_i \\log(\\hat{y_i}) + (1-y_i) \\log(1-\\hat{y_i})\\]\nwhere \\(y_i\\) is the actual value and \\(\\hat{y_i}\\) is the predicted value.\n\nfrom sklearn.datasets import make_blobs\n\n\n# generate data blobs\nx, y = make_blobs(n_samples=500, centers=2, cluster_std=2, random_state=42)\n\ncolor = np.where(y == 0.0, 'orange', 'blue')\n\n# plot data\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=x[:, 0], y=x[:, 1], mode='markers', marker=dict(color=color)))\nfig.update_layout(title='Data', xaxis_title='x', yaxis_title='y')\nfig.show()\n\n\n                                                \n\n\n\ndef bce(y, y_pred):\n    ce = -torch.mean(y * torch.log(y_pred) + (1 - y) * torch.log(1 - y_pred))\n    return ce\n\n\n# add bias term\nX = np.concatenate([x, np.ones((500, 1))], axis=1)\n\n# convert to tensors\nX = torch.from_numpy(X).float()\nY = torch.from_numpy(y).float()\n\n# initialize weights\nw = torch.randn(3, 1, requires_grad=True)\n\nlr = 0.01\naccuracy = []\n\n\n# gradient descent\nfor i in range(100):\n    y_pred = torch.matmul(X, w)\n    y_pred = torch.sigmoid(y_pred)\n    loss = bce(Y, y_pred)\n    loss.backward()\n    with torch.no_grad():\n        w -= lr * w.grad\n        w.grad.zero_()\n    \n    y_pred = torch.where(y_pred &gt; 0.5, 1.0, 0.0)\n    accuracy.append(accuracy_score(y, y_pred.detach().numpy()))\n    \n    if i % 10 == 0:\n        print(f'Epoch {i}, loss {loss:.4f}, accuracy {accuracy[-1]:.4f}')\n\nEpoch 0, loss 0.9751, accuracy 0.5820\nEpoch 10, loss 0.7332, accuracy 0.5260\nEpoch 20, loss 0.6994, accuracy 0.5560\nEpoch 30, loss 0.6967, accuracy 0.4740\nEpoch 40, loss 0.6965, accuracy 0.4380\nEpoch 50, loss 0.6964, accuracy 0.4300\nEpoch 60, loss 0.6964, accuracy 0.4300\nEpoch 70, loss 0.6964, accuracy 0.4280\nEpoch 80, loss 0.6964, accuracy 0.4260\nEpoch 90, loss 0.6963, accuracy 0.4260\n\n\n\n# plot loss\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=np.arange(len(accuracy)), y=accuracy, mode='lines', name='accuracy'))\nfig.update_layout(title='Accuracy', xaxis_title='epoch', yaxis_title='accuracy')\nfig.show()\n\n# plot data with regression line\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=x[:, 0], y=x[:, 1], mode='markers', marker=dict(color=color)))\nfig.add_trace(go.Scatter(x=x[:, 0], y=(-(w[0] * X[:, 0] + w[2]) / w[1]).detach().numpy(), mode='lines', name='regression line', line=dict(color='red')))\nfig.show()"
  },
  {
    "objectID": "posts/MLLosses.html#focal-loss",
    "href": "posts/MLLosses.html#focal-loss",
    "title": "Types of Losses and optimisation",
    "section": "2. Focal Loss",
    "text": "2. Focal Loss\nWe define Focal loss function as the combination of Binary Cross-Entropy Loss and a modulating factor. The modulating factor \\(\\gamma\\) is used to reduce the relative loss for well-classified examples and put more focus on hard, misclassified examples. It’s less sensitive to outliers than the Binary Cross-Entropy Loss function and is differentiable at 0.\n\\[FL = \\begin{cases} -(1-\\hat{y_i})^{\\gamma}log(\\hat{y_i}) & \\text{if } y_i = 1 \\\\ -(\\hat{y_i})^{\\gamma}log(1-\\hat{y_i}) & \\text{if } y_i = 0 \\end{cases}\\]\n\\[FL = - \\dfrac{1}{m} \\sum_{i=1}^{m} y_i (1 - \\hat{y_i})^{\\gamma} \\log(\\hat{y_i}) + (1-y_i) (\\hat{y_i})^{\\gamma} \\log(1-\\hat{y_i})\\]\nIn practice, we use an \\(\\alpha\\)-balanced variant of the focal loss that inherits the characteristics of both the weighing factor \\(\\alpha\\) and the focusing parameter \\(\\gamma\\), yielding slightly better accuracy than the non-balanced form.\n\\[ FL = \\begin{cases} -\\alpha(1-\\hat{y_i})^{\\gamma}log(\\hat{y_i}) & \\text{if } y_i = 1 \\\\ -(1-\\alpha)(\\hat{y_i})^{\\gamma}log(1-\\hat{y_i}) & \\text{if } y_i = 0 \\end{cases}\\]\n\\[ FL = - \\dfrac{1}{m} \\sum_{i=1}^{m} y_i \\alpha (1 - \\hat{y_i})^{\\gamma} \\log(\\hat{y_i}) + (1-y_i) (1-\\alpha) (\\hat{y_i})^{\\gamma} \\log(1-\\hat{y_i})\\]\nwhere \\(y_i\\) is the actual label and \\(\\hat{y_i}\\) is the predicted probability of the label.\n\n# Focal Loss\ndef focal_loss(y, y_pred, alpha=1, gamma=2):\n    bce_loss = bce(y, y_pred) #-torch.mean(y * torch.log(y_pred) + (1 - y) * torch.log(1 - y_pred))\n    pt = torch.exp(-bce_loss)\n    return alpha * (1 - pt) ** gamma * bce_loss\n\n\n# add bias term\nX = np.concatenate([x, np.ones((500, 1))], axis=1)\n\n# convert to tensors\nX = torch.from_numpy(X).float()\nY = torch.from_numpy(y).float()\n\n# initialize weights\nw = torch.randn(3, 1, requires_grad=True)\n\nlr = 0.1\naccuracy = []\n\n\n# gradient descent\nfor i in range(100):\n    y_pred = torch.matmul(X, w)\n    loss = focal_loss(Y, torch.sigmoid(y_pred))\n    loss.backward()\n    with torch.no_grad():\n        w -= lr * w.grad\n        w.grad.zero_()\n    accuracy.append(1 - accuracy_score(y, [1 if i &gt; 0.5 else 0 for i in torch.sigmoid(y_pred).detach().numpy()]))\n    \n    if i % 10 == 0:\n        print(f'Epoch {i}, accuracy {accuracy[-1]:.4f}')\n\nEpoch 0, accuracy 0.4980\nEpoch 10, accuracy 0.3460\nEpoch 20, accuracy 0.4220\nEpoch 30, accuracy 0.4260\nEpoch 40, accuracy 0.4280\nEpoch 50, accuracy 0.4280\nEpoch 60, accuracy 0.4280\nEpoch 70, accuracy 0.4280\nEpoch 80, accuracy 0.4280\nEpoch 90, accuracy 0.4280\n\n\n\n# plot loss\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=np.arange(len(accuracy)), y=accuracy, mode='lines', name='loss'))\nfig.update_layout(title='Accuracy', xaxis_title='epoch', yaxis_title='loss')\nfig.show()\n\n# plot data with regression line\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=x[:, 0], y=x[:, 1], mode='markers', marker=dict(color=color)))\nfig.add_trace(go.Scatter(x=x[:, 0], y=(-(w[0] * X[:, 0] + w[2]) / w[1]).detach().numpy(), mode='lines', name='regression line', line=dict(color='red')))\nfig.show()"
  }
]